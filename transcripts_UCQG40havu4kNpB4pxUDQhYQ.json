[
  {
    "video_id": "1L-x_DH3Uvg",
    "title": "I Tried Rendering Millions Of Particles",
    "publish_date": "2024-11-04T13:20:26Z",
    "comment_count": 0,
    "transcript_text": "0.5 we get the average of a and b or the 00 0 the next dispatch will be three 10 dispatches to generate all of those 100 million is just a little much for 100 million particles in real time we 100 million particles rendered in real 100 million squared comparisons and 16 Generations would require a buffer of 2.4 million particles to obtain an 30 million which is a substantial 3x3 so in aine transformation in 3D 4090 do not try this at home if we 4090 what I'm looking for is the 65 million positions as as far as we 65,535 or 2 to the 16th multiplied by 64 Advanced Graphics programming techniques Best But for now that's fine the chaos CPU would crash our game to 0er FPS and Cloud meshes are now unique we can no Cloud that was a lot of effort to obtain Counter-Strike 2 smoke video to get a FPS and we no longer have a game to GPU action that results in many draws GPU to draw it streaming in the newly GPU will draw this blade of grass and GPU with the mesh to be drawn the number Generation by applying the chaos game Generation consider a 1 million particle Generation what if we instead used one Generations in the pursuit of a program Homer's frame rate independent lurp Humble fungus spores from The Last of Us I wanted my first video with the 4090 to I'll be referring to each sequential K is the function count and N is the Let's ignore this red flag for now March it like we did back in my Matrix putting 0.5 along the diagonal Point clouds to meshes exist this has Quiz get the answers right and you just Same there is no need to calculate Seattle the other month I was staring Shader and unveil the path towards Shader just like wood in the formal Shader that is to blame for our poor Shader the source of our poor The Matrix with a one at the end this is Transformations they aren't supposed to World by storm this year with its a cube as well could we stack a bunch of a dubiously unrolled matrix a fancy triangle and even worse our a filled out shape so our memory cost is a point Cloud mesh we could modify its a whole take for instance a forest of about it and Frey's blog post on the about the 100 million goal I sat and absolute bare minimum so I'm going to do absurd amount of memory and actively acce Rola iHeart GPU shirt available in accidentally invented a particle system across space at each iteration as I've actions the GPU must take before the actually possible to subvert the entire advantage of GPU Hardware by updating advantage of every idea in this video so again with each new Point splitting them alarms as gpus are meant to do algorithm for creating it is about as all my current patrons without your all the generations we wanted as you can all the particles at Once In Parallel already been done with stuff like L also the game dreams which is made always desirable because generally amazing website exists with a collection ambient occlusion as a form of lighting amount of them in our system technically amount of times so we are instead going an idea I wanted to explore even further an ideal thread group size is 64 threads an infinite amount of times gives us the and buying a shirt so I can continue and doesn't truly illustrate what a and extensions for this Tech in this and it has a number of limitations the and now when we update our particles we and our 1660 can now draw 100 million and overdraw is just too much for our and so on forever repeating this process and streamed in to take full advantage and the maximum amount of thread groups and the points will Converge All the and we get B when the blend factor is angle completely defeating the point of announce the Channel's First Merch another level higher and blend the anti-alias or some other analytical D anyone has ever seen these shapes before anyways that's all from me I hope you apparel profess your love for the graph applications of stuff I make videos on apply each respective function then we approximation of our shape after all the approximation of the attractor after approximation of the attractor is the approximation of the serinsky triangle approximation we iterate through every are combined into one blending at this are particles because they all behave are rendering points every single one we are three-dimensional but because of the armchair developer on Twitter says some article from 1990 now it's time for as clouds when I was flying home from as far as I'm aware I am the first as possible this brings us to the as the positions travel through the assign probability ilities to each attractor is the formal mathematical attractors exist of differing function attractors perhaps I treated you too attractors remember how the base case of attractors the movement of the particles bad as it could possibly get if we bad topology is the reason the game runs base case and we use GPU instancing to based on generation size the chaos game be applied and the other two have a 25% be divided by two and move towards the be divided by two and moved towards the be honest is rookie numbers so let's see be laughed out of the venue and nobody be quite slow and we want to have at beautifully shaded three-dimensional because this is pretty much only before did you think we were done no before dying tragically in a car crash before so like what actually is a before the next frame is rendered the better Bloom Shader soon as my Unity one between without looking terrible in fact billions of particles with splatting bit closer at one of these X is a two blade of grass and so on and so forth blades you might think the solution to blend Factor making it non-linear so blended attractor should look like blending between them unfortunately this blending the positions directly by blending the positions of two attractors bottlenecking our program as we write to brain for any new ideas any possible buffer of positions cannot be buffer of positions with compute shaders buffer resulting in a point Cloud but over a billion easily the problem is but remember that because our Point but there's still a million ideas left button we are met with a new and buying a shirt or supporting the channel by extension the shape the problem here calculate the sum of 3 to the n and calculating both attractors and then call is then added to the schedule of call something like ghost of sushima can be represented as a single matrix can do that we first need to understand can easily slot in different matrices to can efficiently generate attractors it's can exist for our use case imagine a can handle before it dips below 60 can never grow larger and so it always canceled out and we only get a but when care less about the 10 million sub pixel case of our system is a point at the certainly use iterated function systems chance of being applied but there's no chance this results in even more chaos game is an absolute win it reduces chaos game mesh and an iterated function clearly there is a bottleneck somewhere clouds a point cloud is a collection of color palette techniques from my video color space lastly the noisy nature of colors of our particle system are complexity is a about as bad as it gets component Vector so let's expand each component X and Y are divided by two computational and memory compute shaders and the ability to computer science experience all you need conceptually speaking the lurp smoothing consider a different world where contains nine and if we continued a context can we draw with fractals this controlled CPU side so how can we most converges to the fractal shape never cool smoke like effect if we wanted but coordinates transformation matrices are corresponding position in the compute costly memory fetch in the vertex Shader could be used to generate color pallets count so we can choose any amount of create meshes with vertex counts that creates the shape you can see that all creating free educational resources for data compute shaders can operate on the deep dive into linear algebra and ADV demonstrated by this deep red color on demonstrated this formal method is very dependent on the previous generation we dependent on the previous output in GPU depends on the context of all in which describe what our particle system really details on frame rate Independence and development and push Graphics development as well this one is my did it 100 million particles but I'm different different from the serinsky directly blending a fine transformation dispatch that is a lot of threads but if dispatches needed to create the prior divide up the area into a set number of divided by two and move towards the do the simplest hacki thing ever in the do this because now we are free from the doesn't look that good it's stiff direct done to generate this particular down at the clouds and I saw something down to our artistic preference draw objects purely with iterated drawing 100 million particles admittedly dumbest way possible all we do is duplicate each of those points three duplicate that point three times and duplicate the mesh into the amount of each mesh to be the same with this each one has its own draw call a major each other and the results are Stellar earlier this is known as GPU instancing easings Donnet but since I'm using Unity effect system to make the powers as cool effects in video games such as the efficiently updated from the CPU at run engine the CPU dispatches a draw call to ensure our iterated function system entire buffer can now be updated in one entirely out of particles and my entities that all follow the same or a equation given two values that you want escaping scaling is not the only kind of evaluate the three neighboring pixels even draw all of this and More in even louder now because this is even result in a cool shape looking a even though no shearing transform is even though there's nothing there each eventually blending values of any kind every time I press the generate shape everybody's favorite part of the video everything in parallel not in sequence everything is drawn with this everything is half as small 1 meter is exciting fractal shape that's a bit expansion the chaos experience the alarms should be getting exponential growth the amount of points exponentially decays our attractors exponentially which is really bad as fairly recent technological advancement far I hope you haven't forgotten about favorite thing I've ever rendered I fetching when we inevitably blend the fights against what gpus are good at the find a fine in most cases and how it works for fine transformation and we can have any first dispatch will fill in the first first is that the mesh must be the same first real-time lighting solutions for fit within a single compute dispatch and flat shading it looks 2D from every foliage a a particle system where all of for accurate shading here even the 4090 for all instances this is because to for blending anything you want whether for each attractor and double the memory for our iterated function system now for short and is the common foundation for those of you with computer science formal and Chaos game methods aren't the fourth generation would need 27 points fractal from earlier as a point fractals When I close my eyes now fragment Shader we are going to sample frames per second is it 10 million free by applying the formal technique from Global memory in the vertex Shader from newer games so why is it that novel function system is thus K to the N where function system that operate on strings function systems could be used for voxal function systems in graphics was this function systems it works in almost the function systems just like we can with functions but many more interesting functions in our iterated function functions that operate on the linear future version of our iterated function game is a stochastic method for game it's incomplete it's ugly work at game we can decouple the blending from gaussian splatting is all the rage right generate a list of positions from the generate colors for the system to blend generate new attractors but before we generated it's quite unlikely that generating the attractors of iterated generation fluid simulation path tracing generation method this gives us an extra generation of 3 million particles with generation of our system would be 43 generation thankfully this formal method generations of this iterated function given a desired number of generations we going to be the sum of three to the end going to get extreme just 16 generations good news is that we can easily pack grab the corresponding position and graic processing unit with the exclusive graph Graphics to reiterate the goal we growing set of positions in math terms hand so I went with the kuara filter the handle it's time for a performance Pop happens if we added another position to hardware 20 million positions from the harshly because now we can render not have a great rest of your day and I'll have a set of three functions that we have a shape that can be created from an hello everyone astrobot has taken the here are called translations which here's a few screenshots I took during hiding underneath that flat coloring in hooking up my procedurally generated hopefully there's a better way wait a how could we more cleanly blend between however many more we need for the Next iconic Zelda Wind Waker bomb particles idea I decided to make use of a particle if this was the future maybe we could images look stylized and painterly and implement a lighting solution anything implementation in mind how many implementation of TAA or a d noiser on in fact you can play with the generation in just one dispatch with this in memory we have another problem though in the case of my original grass field increase still I can't stop thinking increase the maximum from 10 million to individual Transformations before they inefficient computationally requires an infinite number of iterations on a set information the GPU needs such as the inspiration of today's project imagine a instance ID to the Shader and use that instance maybe one has a 50% chance to instance the mesh three times and based instances are drawn the second instances at the origin but after we instancing a mesh of just one vertex and instancing a single vertex mesh is quite instancing in place of the simplest instancing now for our compute Shader instancing sounds like a proper solution instancing will affect our particle instantiate a buffer in GPU memory of instead of in sequence of course the instead we're going with the simplest instructions a world of infinite detail instructions for moving from one space interesting attractors as shown here interesting shapes instead of just the interpret our 20 million draw calls as into a single aine transformation matrix into my computer the 4090 can handle 100 into three and doing the same operations involved with the original matrices so is a bit upsetting though as ideally we is a limit of 4.2 million threads in one is a proof of concept it is hardly is an extra matrix multiplication in the is born which had me wondering what is called an aine transformation and it is exactly what's happening to our is far less direct rotating through is known as linear interpolation or lurp is not the only method and a better one is optimized to this degree the only is really an easy way to instantly make is something called sub pixel triangles is that drawing millions of objects can is the compute Shader dispatch is it is the culprit the sub pixel triangles is too expensive the third and final isn't the best around please enjoy 30 it ated function systems ever invented it has a huge effect on our particles it lives in and came before it what it possible that fetching the position it reminds me of moon sand it looks soft it's certainly going to be faster than iterate through our particles and turn iterated function System point cloud iterated function system approximated by iterated function systems ended for now iterating and something called the iteration of the system as a generation just 100 million particles but 205 just Ray trce the particles but even a just by itself lastly some Bloom really just how many particles my GPU can know we just have to bear the burden of known as an augmented Matrix or a fine kuara filter is a PO D noiser so it kuara filter is an advanced land the word iterated should raise some learning how gpus can draw millions of least 60 frames per second if you less robotic I was still less than let's start with that approach when we level gives much better results the lighting possible an ambient occlusion lighting techniques we want we could Ray like our iterated function systems like rotations and so for double like to see a video where I render likelihood of these shapes being limitation that we can't update the limitation we can only create 13 limitations domain line we have yet another problem though linear interpolation the rules of our linear lifts the restriction on particle linear mapping though there's also little different I'm so excited to longer GPU instance as that required longer a restriction on particle count looks like the material is very strange mainly developing on the 1660 again if make GPU instancing possible we actually makes more sense to describe what a making it look good it's hard to making use of both methods of attractor manually controlled one way to improve many real life objects are fractal in mapped to a smaller and smaller World it mapping and derivatives this is almost mappings or in simpler terms the math contexts but in this case its mathematical method for generating ifs matrices gives very poor results Blended matrices look like they do me show you how we can double the memory nearly 120 megabytes in fact is mesh to be drawn and where this draw method I tried that gave the impression method just using a mesh to hold our method that reliably and uniformly middle point between them this equation might win a prize as a quick recap our million draw calls and thus 20 million million our particle system is complete million par particles or 200 million million particles and so we would need million particles is quite a lot of million particles just fine we finally million positions to draw the mesh is at millions of individual draw calls but we milliseconds that's about 9 frames per missing variables to both lines more filled in Neighbors the higher the more interesting shapes such as more particles there are the better the move to what if we divided by some much another potential issue is multiple Generations sequentially the multiplication by adding an extra row to multiplication is not commutative and multiplication this is true of every multiplied by 0.5 these added values multiplied by zero and we have revealed must calculate each one sequentially our my particles for so long that I see nature such as coral mushrooms ferns need for that to be the case we could need some kind of shading to see the need to consider how the limitations of need to visualize all generations to get needing millions of particles GPU neighbors it has that are filled in the never-before seen entertainment this is new information we can rewrite all the next frame is rendered this is totally noiser but I don't have an now 0.5 M the map to this alternate now instead of a draw call we would call now we can finally get to see our now with splatting we could potentially number of particles we need is quickly number other than two to realize this objects many algorithms for converting objects we render occupy more than a obviously can't do something an infinite obviously it is the famous serinsky occlusion value then in our particle of a particle is very Case by case and of alcoholism to cope with our failure a of different easing functions called of form but how could we possibly light of generated particles can be contained of our Transformations has an equal of our chaos game approximations as the of positions in order to render the of the PS5 Hardware to dump as many of the chaos game our shape is of the chaos game we can easily swap of the point Cloud to provide basic of the rendering pipeline anyways and of the system requires 43 million of the volume of our Point cloud with a of times it should draw it 20 million in of what the GPU is built to do chug offset the vertex it shifts over to on patreon as usual a huge thank you to on the instance ID we progress the mesh on the nearest voxel to its position on the subject to also procedurally once keep in mind that matrix one FAL woop to do this we Supply the one iteration forward in the vertex one of our points actually costs four one where I can do actual research and only 1 million in memory and all it cost only 1 million particles though which to only choice would be to turn to a life only methods for generating attractors only one and draw all of the grass in onto you all just in case you want to operate on GPU memory directly enabling operate on GPU memory directly is a optimal and only made possible by the optimally utilize GPU Hardware to or a swarm of bugs the Swarm is the or anything so this means we will be or inFAMOUS Second Sun's novel particle order to see it we're going to need to origin to progress the system we other function too we can generalize the other perhaps iterated function systems our 1660 with this method but we did our fractal is a legitimate concern the outputs and so on until we have created overhead costs when we render to a pixel parameters to mess with for just one a particle count for basically free taking particle is drawn to the screen there's particle system are now complete we can particle system as a collection of particle system is so I would Define a particle system works by updating a particle systems are recent phenomenon particle systems have only been popping particle systems taking full advantage particle systems they think of Point particle this question kind of misses particles 40 million particles 100 particles around at runtime thankfully particles do you think my mid-tier GPU particles every iteration a particle is particles if you answered 10 million particles in just 115 particles it said 100 million in the particles look fluffier and more particles must be the same mesh we could particles on screen as possible there's particles to represent it even worse we particles we need for the Next particles we want and takes full particles what is this Amateur hour let people to see them because of the nature performance I ran a Twitter poll to see performance so let's take a moment to performance the memory fetch is just way person to create a three-dimensional personal favorite particle system The physics simulations or whatever else pick up where I left off it can be pixels many more times than we would pixels to calculate data for some other play if we pause and think a moment we play so thinking about our dilemma of please buy a shirt thank you iterated please consider supporting the channel point .5 .5 the third point will also be point 0 0.36 the second point will also point at the origin that we split into point in space centered at the origin we point5 .5 and then we repeat the process points are the 10 million sub pixel points harshing our Vibe a little too points where the first point is going to points which occupy exactly one pixel points with ease but first something a ponder what those bottlenecks might be poor poor 1660 to handle unfortunately position to our new smaller world this positions colors or even matrices on the positions in one frame is just too slow positions not including all of the positions of the particles from the CPU positions so it would be convenient if possible and I need to clarify that this possible but don't worry I'm still possible on the 4090 once again you're possible that updating 10 million post-processing technique for making present now when we interpolate presented in this video are if you would probably can't handle Ray arching this problem arises with stuff like foliage procedurally generate and blend between programming Tech forward please consider programming topics like terrain projecting and more and the amazing projects like the one in this video propagation for volumetric effects such pulls it together but I need to make a quote horrible this is because the random Matrix from the list why would we randomly apply the functions from the randomly generate each individual real literature I could find on iterated really hard sometimes to conceptualize really matters is the particle system as really push the limits of what's reflect light all these examples are remember from all the way back in my render is only occupying a single Pixel render not just 200 million particles rendering Pipeline with a custom compute rendering pipeline features like M replacement known as splatting in fact replacing the 20 million calls from requires double the memory two buffers resetting the particle system which is restricted chaos game right now each one restricting certain particles from restructuring we have eliminated the result thankfully because of the chaos results in a decent blend but it doesn't results in a quad we can expand it into returning to the real Topic at hand we ridiculous amount of settings and rotation reflection shearing squeezing rules as much as you want to create even satisfied with these easing functions scheduled actions for the GPU to take second let's keep it so that the number second so not very good unfortunately second we can only handle 10 million second what even is this shape called second why does this set of functions seconds of Epic particle system see the thread count also grows see you next time seeing something no one has ever seen sentiment was that the fragment Shader serinsky triangle is also one of the serinsky triangle wait a set of instructions I described earlier set sizes the cost of a formal iterated set to the positions of the particles sets of transformations in and out to several potential issues here the first shape in a game or something we shape is now noisy but there are many shape-shifting action shear from the naive blend is no longer sheer number of scheduled actions will showed up to GPU land with this we would signed distance functions right now the similar set of rules this means we could simple naive Shadow Trace would require simplest attractors requiring only three simply moves the position of the point simply multiply the position with a since color spaces are a space like any single Pixel unfortunately because we single compute dispatch there is no single vertex mesh to instance we draw slot of the buffer with the base case of smoothing which is the only animation so congratulations on being the first so here's a bunch of potential use cases so it should be easily adaptable to this so poorly all 10 million positions are so the comp compute is inconsequential so to make our lives easier let's solution an Nvidia RTX 4 90 slotting it solutions but nothing came to mind so I something called overdraw when we draw space like they should and instead of speaking we are drawing all of these specific iterated function system split this point into three three new stage is the fragment Shader when the stared at my wall for hours racking my stays within a certain bounds we can still disappointed with this particle stochastic which is a really pretentious stood up and went into my kitchen to strict definitions of functions and we subvert the memory fetch in the vertex such as this one that is shearing space supplied to an instancing call in which support I wouldn't be able to stare at system and the trees are the particles system as aine transformation matrices system but all we have is millions of system but that should be good enough system how many particles can my GPU system implementation first all the system is 3 to the nth power where n is system of three Transformations we GPU system so far to be quite Frank it looks system that has freely surpassed its system the bug the particle it then system to model the shapes created by system where the next output is systems all we want for infinite systems go beyond physical entities systems the naive approach would be systems which are a form of iterated tank the performance of our game to 0 tasteful use of age-old PlayStation IPS technical math term is the attractor of technique to simple Point Cloud meshes temporal anti-aliasing could mitigate thankfully there's a way to completely that can be dispatched at once is that can give the 3D Volume some sense that does all of that multiplication at that is heavily limiting our particle that is scalar values vectors angles that no one has ever seen that operate on the previous three that randomly multiply the positions that runs at more than 0 frames per that size since Generations are that splatting is not really compatible that the blend has more character an that you can multiply a whole bunch of that's a little much much for even our that's what made the grass possible so the 3D particle system what if I told the Blended output is 1 - t * a + T * B the GPU this draw call contains the the GPU to get an extra generation for the US and the EU I've been struggling the batch will result in a point Cloud the big stink and we are using GPU the blend factor is 1 a is canceled out the complexity from exponential to the complexity graph describing it as the exact same mesh just at different the first generation contains one point the first stage of our particle system the forest for the trees the definition the formal method for generating the formal method was a single point the fractals were truly growing out of the game features numerous novel the generation if you don't have the humble Matrix transformation the individual grass blades and flowers the iterated function system what we've the majority of objects in in a scene the memory cost we also get a worse the mesh is only one vertex no triangles the next dispatch will be nine threads the noise well I hope you enjoyed this the order order matters for this video I the particle to determine its shading the particles and the shadow color all the points are very cleanly distributed the positions and instead blend the the positions are grabbed automatically the procedural generation would be the rendering pipeline has some implicit the same for the most part particle the second contains three the third the second stage is the vertex Shader 10 the vertex Shader by fetching their the voxal grid based on the position of them in the vertex Shader we're still them together to create a cooler Matrix then this blade of grass and then this then using a crude voxal approximation then you're correct wait a there are many approaches and it comes there is a limit to the number of there was some way that the GPU could these instructions so let's start by these shapes on the topic of blending thing about matrix multiplication is think and this is where my journey into this a batch because it's one scheduled this cost so let's continue onwards the this example and then an array of 20 this in the most Brute Force dumbest way this into a single buffer for our GPU this is called an iterated function this makes me sick only 100 million this problem is GPU instancing because this with something like temporal though and are a driving force of visual though and continue onwards the base though so I decided to implement Freya though where there are lots of entities threads that can be dispatched at once threads that operate on the base case three-dimensional iterated function through millions of vertices we can through space for fun let's add the thumbnail or the title of the video okay time because of data latency between the time it's not the best solution in the time we started generating more times and repeat until we're satisfied to a pixel multiple times wasting the to afford spending more time on videos to another consider our usual normal to approximate that infinite series and to blend a and b and a blend Factor T to create cooler and more interesting to explore so let me dump some ideas to index the buffer of position I which to know is that exponential algorithmic to need a very large number of particles to procedurally generate meshes of these to see videos on deeper Graphics to the form ax plus b where a is a today's video where I explain how I too expensive our GPU actually couldn't top of each other this could also be topic in which she also goes into more topic of blending iterated function towards each other and you can read more traditional solution to this is easing transform to accentuate them for transformation before combining them transformation matrices represent linear transformation matrix and B is a transformation matrix and a translation transformation matrix fun fact when transformation sets for a better result transformed sets of this Cube ifs and translation this combination of a translation this is of course a traveling along a straight traveling through space there should be trees and other foliage you could trees we could say the forest is the triangle but when most people think of triangle given the statistical triangle something that shows up in many triangles keep this in mind next time an true detail of our iterated function two that float around in the air and two you might think this at least unfortunately we need millions of voxal unsorted particle positions to work with until the whole field has been drawn the up in in the past a decade or so because update our particles without completely update their vertices in no time at all updated in about 1 millisecond as well updated positions rather than fetching us to update the particles as much as we use a cube a sphere Leon Kennedy or a using the same amount of memory but now usually starts with a very simple vertex Shader I'm sorry formal vertex Shader memory fetch it is vertex Shader of the mesh we Supply an vertex data each frame and then tell the vertices of meshes directly so if we had very famous serinsky triangle fractal very similar to a fractal ifs shape the very surprisingly from just three simple very ugly it's stiff with no soul the video on drawing Millions of grass video we only subverted the cost of the volumetric almost like a cloud because voxal then each frame we are going to voxal to determine and how many voxelized version of our particle system want this is the main reason why cool want to render an object in a graphics want to repeatedly apply to an Ever want to so is the dastardly fragment way of saying it's noisy we could fix ways to fix such an issue now that we we actually evaluate in a 2x2 grid of we are free to do any sort of volumetric we can just use an animation curve this we can make use of compute shaders to we draw as many single vertex meshes as we like a lighter Shadow color makes the we need these particles are displaced in we need to represent a generation of the we offset the vertex with technically we unfortunately have to take the blend we would be looking at something like 20 we would no longer have a game to we're drawing millions of particles on we've gotten lost in the sauce GPU well time for a different question what makes a particle system a particle what you all thought and the common when the blend factor is zero B is where it's supposed to be secondly the whereas previously particles had to be which is another way of saying which is that linear interpolation is which we then instance copies of with which will give us a rough approximation while still operating on only one buffer why matrices in unity are 4x4 with this will be using scale rotation shear and will uniformly reduce the scale of a with a buffer of positions created and a with a real-time lighting solution that with game development and the methods I with matrices this buffer is then work that was previously done since working with three-dimensional works on any number of particles the world but it's certainly one of the world can be described with a scaling world where 1 meter is 1 meter now would be interesting to see how much would ever listen to us ever again our would like to be able to move the would realize that the GPU is drawing would require a 4X four Matrix this is yet granular we can change the color of yet we still must pay for the overhead you recall from earlier a 16th you that a world of infinite detail was you'd like to see more videos like this you're about to see so if you would like you're all wrong it's the humble vertex your animations more interesting and"
  },
  {
    "video_id": "1bu8ePFm-wQ",
    "title": "Fixing The Graphics Of Pokemon Legends: Arceus",
    "publish_date": "2022-02-05T01:00:00Z",
    "comment_count": 0,
    "transcript_text": "[Music] a considerable memory cost to solve a actually isn't obviously games are not additionally while i dislike the game's all the low quality textures that's an alright time for the part of the game ambient lighting to the leaves so that ambient occlusion additionally a and i'll be sure to make more but until and instead used their other tree assets and thus shinier as demonstrated here animated which is what we see in the animation which is exactly the issue arceus and while they are heavily as demonstrated here the lighting of the as they look much nicer the issue has to at least know why the game looks the way avoid nitpicking so the main focuses of be too difficult for them either as the becomes this method means that shadows before we get into how to solve it we before we get into the nitty-gritty i'd between the top and the bottom of the breath of the wild doing in order to get breath of the wild replaces distant brighter at the bottom of the blades and calculating real-time fluid dynamics calculation is too high resulting in the called a shadow map cast shadows as they are seen by the casters you have the more expensive this casting so it's an engine limitation closely so the distortion trick becomes cold and are no longer rendered in order color of the underlying terrain color comment ace rolla why didn't you mention conserve resources so that the game runs coordinates descend and you get grass could have talked about but i didn't criticisms are justified i'm going to darker at the top which makes no sense depth values of the point in the shadow disappearing shadows as demonstrated discuss why it looks unappealing and how distortion technique if you lower the do with the harsh lighting difference does this landscape feel empty to put it dreaded lake image that is circulating easy solution here is to add some effects to begin with like everything in empty looking hills in the distance as especially on the dirt which should be every light source the more shadow every scene is rendered from the point everyone is ragging on the dreaded exaggerated for the most part we should exist can't cast shadows exponent on the specular highlight exponent value and matte at a lower exponent value i think that if the game faster but comparing this to a for example this grass from world of francisco playing the new pokemon game game and make it look a bit more natural game looks like this is because the game looks that bad additionally it's game looks the exact same but because game looks the way it does anyways let's genesis 8. during that time i came up get to the first item on the list why going over the trick but to sum it up gradient of the grass converge to the graphical fidelity of pokemon legends graphics water animations are another grass feel more natural is having the great but when it is upscaled to a tv greater than the depth of the shadow map greatest looking game on the planet but hardware can clearly handle it so what's have much time to make this video if you hello everyone i spent this past week in here is that this problem isn't solvable here the tree shadows disappear when the i expect the next game in the series to i think this is to give the game a bit i'd prefer they removed them entirely i've discussed in many videos up to this in my hotel room instead of going to in render repair pokemon legends arceus increase the resolution of the texture instead we utilize a technique known as is seen by the light the depth of these issue with the switch hardware itself if it does in order to understand if the it is definitely the best experience it's the downside of this texture it's viewed closely you can't see the jasper has a great one minute video just not being rendered lake verity lake verity image because we are landmarks in the distance the trees cut landscape look so barren why do these leaves so they become much too dark the leaves there's a lack of ambient light source even if they aren't seen by lighting on the bottom side of the like the idea of this series let me know like to clarify that i do not think this little less weird little shiny like it's wet or something location in the game when you consider look as though it is moving by making look much better if you were about to look so bad compared to other trees in look too great there's a lot more i looked down on from high up which is low resolution and it will look even lowered the overall smoothness of the makes the normal vectors of the surface map and if the depth of the point is map and when we render the scene from materials in the game it would look a meaning i can't give any real solution millions of people on the internet who modifying textures the size of the more of a matte texture the reason the more of a tune-shaded style but in my move so the specular highlights are moving on to the first real major notice the pattern this would result in object that is marked as a shadow caster objects is then written to the shadow of objects outside of camera view still of opinions circulating about the of place all of the tall grass is of place why does the ground look so of view of the light sources and each off too quickly and we are left with opinion it just looks tacky or can they in game engines like unity other side when i add to the final other than just fix it out what color is directly beneath it output of the color overall lighting model it's hard to overall pokemon legends arceus isn't the pattern the reality of the situation performance benchmark if pokemon were to piece of art and inform people why the pinpoint any one reason why it doesn't point is in shadow by comparing the point removing distant trees is a way to pokemon has to offer so far probably the best pokemon game ever made problem that is only present in one problem the entire game is riddled with properly place itself on top of the scene is rendered multiple times for screen then the textures look much worse screenshot of breath of the wild where shadows are handled with something shadows are so expensive is because each shadows why does this grass feel so out shiny and lastly what's up with that shiny looking the ground is always a should learn how games animate water simply it's a lack of meaningful foliage since the grass is already sampling the so clearly the distance is the issue so that it's large enough that you can't some problems as objects that don't speaking of terrain why is everything so speaking of trees why do these trees specular highlighting will become too sphere becomes much less harsh on the surfaces of the game looking smoother technique many games employ to make terrain the grass can also sample the terrain this is very easily achieved terrain's displacement map in order to texture has an effect on the overall texture of the terrain in order to find that are not in view of the camera are that blends with any underlying terrain that it's not worth fixing that the game can render hundreds of the actual camera view we check if a the camera the fact that this doesn't the case well in all video games objects the dreaded urban hellscape known as san the first render repair video in which the game and act like it's the worst the game looks pretty decent the game they just look awful personally the grass texture color as the uv the internet all this and more coming up the overall appeal of the grass in the the surface becomes shinier at a higher the tall grass felt very awkward and out the texture all wish you washy this also then i hope you have a great rest of then that point is in shadow the reason there are many trees present the there's something going on when there they don't become too dark thing ever created while having no idea this coloring should be reversed to fake this many trees in view this shading style i think would improve this video is to critique the game as a this video will be why does this this water looks really awful when tile rate of the texture then the to conserve resources this can cause to possibly fix it there's a whole lot too obvious and makes the lake look very trees already exist in the game they are trees are no longer in view why is this trees in particular look so awful what's trees while still maintaining a high trees with images known as imposters so trick of the eye to make you think unfortunate since the water elsewhere in unless of course you consider the unnatural the water elsewhere in the up with these mysterious disappearing using a different technique for shadow utilize this trick as well the landscape uv distortion and blending to make water walking around the world i found that warcraft blends into the underlying we will analyze the graphics of the game why it looks like that to begin with will cherry pick it in order to rag on with a new video series so welcome to with lake verity the texture tiles too with the terrain color you mix it with work in pokemon means that they are worse the only real solution is to would feel much less empty it wouldn't you play on handheld mode the game looks your day and i'll see you next time"
  },
  {
    "video_id": "5EuYKEvugLU",
    "title": "This is the Difference of Gaussians",
    "publish_date": "2022-12-24T13:49:15Z",
    "comment_count": 0,
    "transcript_text": " but what if I told you that we 2012 when Hilger windmiller and their ETF blur to near zero and the swirliness Edge detection we see that we get a Edge lines triple toning charcoal pastel Edge tangent flow of the image to Fantasy 14 the results are as you would Final Fantasy and all the ways we know I don't have much else to show for the I have talked about the Sobel operator I'll be streaming my Challenger climb I'll take a break for now if you have Impact especially when it approaches Improvement we need to make windmuller Rolla proceeded to quit his day job and Signal processing the gaussian function Skybox we could fix this flickering with [Music] [Music] [Music] [Music] a cross-hatched image and lastly we can a lot more accurate to the medium this a mask for the original image the output a meaningful way well one art technique a number greater than one then we can a quick recap The Edge tangent flow of a quite different style perhaps then I a separate gaussian blur with a scalar a smoother gradient this thresholding a style that looks a lot like a rough a week to three viewers on average he accentuate and solidify these lines by achieve my goal of full-time content across the edges the standard deviation adjustment to our image blur and akin to watercolor paint blotches on the allows us to further stylize the first allows us to sharpen the output without alone is not enough to reduce the impact also for the sake of Simplicity I'll be amounts of white space to get there we an image twice take this image as an and all but what about coloring our and multiply them all together to create anti-aliasing we get a more detailed but any change in brightness thus was born any ideas please comment below or at any other effect combinations but I any standard deviation then we have very anything greater than the threshold is applying a threshold to the output where applying the edge aligned blur to our around with in the description stylized as Sigma M and then we shift our UV as our quantized Taylor Swift the as the dog from here on a very high as the dog from here on a very low aspirations go beyond these Petty be areas of high contrast which usually been reading way too much junji Ito with benefits and drawbacks for instance the binary thresholding function from bit dithering to give much more defined blend it onto a paper texture to make it blending methods or even the way we blur but how can we blur along Edge blur of the structure tensor has a Major blurred images where one is more blurred buffer which results in a very but unfortunately the dog is riddled calculate our difference of gaussians as calculate the difference of gaussians can get any number of tones we want can just use our cross hatched output as can sharpen edges more without as much can then use this map when we calculate can't shake off this feeling of regret candy Edge detector is one of the most cartoonish Style with hard shadows and catch me when I'm streaming live Ace change in brightness by making changes charcoal sketch then with only a small close to the camera and the bridge look color and then from the image color to colored pastel or watercolor but my colored pencil side of things which I completion of our difference of considerable impact on the anti-aliasing construct the eigenvector that points in contrary if we multiply the step size by contrast of the render uh unfortunately contrast to be a bit too jarring in this conveniently these frequencies tend to convolution and is a fairly common convolution artifacts but I find the convolution smoothing we can make the cool it's a little too clean we can make coordinates by the vector repeating this corresponding Vector in the flow field corresponds to edges obviously this could get effective aesthetically could have found what's known as that coupled with a modification to the creation I hope you have a great rest of cross hatching colored pencil I'm cross hatching technique looks great in crosshatch uniquely across each layer dark Edge lines but to get a more daunting but I'd like to see just how deeper Shadows to the heavily cross demonstrate that for you because it is dependencies rewrote the difference of depths and normal difference but many derivatives of the image which we then desert gradients while Taylor Swift is detailed of an output we can get also deviations subtracted from each other we difference of gaussian's algorithm but difference of gaussian's algorithm but difference of gaussian's algorithm but difference of gaussian's render where we difference of gaussian's term we get a difference of gaussians that unlocked difference of gaussians using the disappears giving us a very nicely distinctly different and have their own dog is able to preserve and stylize dog output this can be used to further dog through the same quantization dog to this photo with the same settings dogged a few more photos with a similar dogs as a mask we can then rotate the double dog as we say in the industry double dog since like I only have so dramatic and we can also reduce the each one but how could we layer these in each other earlier in which anything below the edge tangent flow of each frame the edges but I can't shake off this feeling effect is quite daunting but I'd like to effect is quite daunting but what effect is visually consistent in motion effective Edge detection is a effectively blurred the image next let's emphasize Edge lines is to increase Tau end up with a band pass filter that only even more ways to use the filter but everything while this is technically all example if we apply a gaussian blur with expect since we are making use of the expecting anything more I should be extended operator from earlier but this extending the thresholding functions the extensively in most of my videos so far favorite if you like my content and favorite use case is as a makeshift tone field if we desire we start by sampling filters being applied with differing fine but we can see that the dog has fine details are discarded which becomes fine details even tiny subtle features flow blur and subsequent line integral for 2022 is 1 000 followers on all for choosing painterly stylization in for the sake of Simplicity I'll be forbidden something unheard of what if foreign frequencies will be suppressed while the front of all of those image parameters function and since we have two gaussian function from my video on pixel art we function instead of being strictly black function is cool and all but we can function we'd like the hyperbolic gaussian's algorithm but how do we get gaussian's operator such that the gaussians gaussians and when compared to Candy gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of gaussians this is the difference of goal over there so I'd really appreciate gradient but what if we want more tones grayscale pastel black and white is cool hair from here the threshold settings happens if we try to simplify the image happy with what I've got but all I know hatch texture and use our thresholded hatched areas as well as a slight smudge hatching if we find ourselves a cross have a map of the edge tangent flow we have surely obtained a quite different have to trust me anyways we can stylize hello everyone this is the difference of higher white point we can make it more highlights contrast if we don't do any hope I've sufficiently demonstrated the how detailed edges charcoal pastel how do we get it to look as cool as how do we get it to look as cool as how do we get it to look as cool as how much the other settings can change how much we blur it we can get different how well the dog is able to Output a idea what's causing this problem other if I had chosen some other path I could if we subtracted these two images from if you drop me a follow over there and image image a first approach might be to just image stylization in front of all of images it becomes very obvious just how images there's still one major impact from noise if we take a look at impossible in g-shade so you'll just improved the difference of gaussians but increase the saturation to make it look increases the average brightness of the individual in my Discord server went information on a single Pixel basis but integral blending of the pastel style as integral convolutions and it's only interpolate from black to the image intersecting lines to add depth and form is introduced we want to gaussian blur is really dull though so we can heavily is that this dog is one very good boy I is what's known as a low pass filter it to look as cool as possible with so it turns out that the step size of our it was painted with a stipple brush I its infinite potential windmuller sought itself I wish I had the time to discover known as a vector flow field where the kuahara filter in which we utilize The larger gaussian this very simple change least tell me which style was your lets select frequencies through convey like the Stellaris Tech Tree anyways like the lower eyelashes we can bring line integral convolution blur and a line integral convolutions can make a lines The Edge tangent flow is what's lines so far we have only used this look a lot nicer while this looks pretty look quite right yet it looks a lot more looks terrible but it does demonstrate lot of Team fight tactics this year and lower frequencies are left alone this major increase in sharpness we can then making it sometimes impossible to bring many parameters the effect is quite mapper since the dog naturally meaning that given a signal high method and Edge detections through methods but it requires fine tuning on a more complex environment applying the more exist all of these methods look more natural now you might be asking more obvious when we increase the more photos with a similar setup and I most interesting to you it's kind of much smoother output than our original much the output is affected by noise much time to test applications but multiply it with the first dog we can multiply the dog with the original color natural once we blend it onto a texture never made it to Challenger never-ending area of research and next all of my patrons get to vote on my next video the way it works is I give noise it turns out that we can apply the of anyways but unfortunately I can't of blending sort of simulates artistic of gaussian blurring the whole image we of our gaussian blur then we do the same of regret for choosing high frequency of the noise what we want to do next is of this gaussian blur will be referred oh my God Edge lines we can further on the first deviation this gives us two one-dimensional blurs we calculate the only get a two-tone result or a slight only need to do a one-dimensional blur operator as was possible starting with a operator is known as the difference of operator is very finicky when Tau operator the true foundation of options but the big one for me is other path I would have surely obtained our Center pixel along with its our thresholded difference of gaussians our two gaussian blurs but now instead out edges without also accentuating the out even more details by increasing the output decreases but the only way to output is a far cry from the visuals I output with a few increasing thresholds over on Twitch my end of the year goal over the place but it turns out we can painterly output we can make use of a parameterized hyperbolic tangent pass if we multiply our step size by 1 4 pencil and well that's pretty easy we per image basis so it's not fit for perfectly stylized image personally I think the three tone looks photo look much better by reducing the platforms and I'm pretty close to my play games instead I've been playing a pleasing Edge detection by just blurring pleasing visuals such as varying line possible outputs already this change was possible well actually I'd rather just possible with so many parameters the possible with so many parameters the present on low quality Final Fantasy 14 problem of the dog quite well an process is known as line integral process until we exceed the kernel size processing for visualizing flow Fields proposed a very simple extension to the quantization pairs very well with one quite a big difference I dogged a few quite a big difference this marks the quite a lot like watercolor especially rather than two dog passes what if we real time and hides the flickering real-time rendering also it looks like reduce the strength of our hyperbolic referred to as Sigma a and it makes referring to the difference of gaussians referring to the difference of gaussians remove some details lastly we want to render so I think reducing it makes requiring us to compensate for this results aren't too great The foliage results in effective Edge detection in same aim Theory from the anisotropic second line integral convolution to see what happens if we Max the blur see what the effect looks like in real settings on all five blurs well that setup and I think it's quite impressive shaders are freely available to play sharpness just as an experiment let's sharpness which really helps Define the sheer number of possible use case for showed at the beginning of the video but similar output but debatably more simple photo how does the dog look on a simple scalar on the second gaussian simple-minded attempts at stylization simplify and remove more details but my smaller gaussian scales along with the smear the image such that it looks like smooth out those Jagged edges the smooth the output with an edge aligned smoother gradient and once we do our smoother style that looks a lot like a solved the sharpness dilemma but there's something I have talked about something like temporal anti-aliasing standard deviation of that blur will be standard deviation of the gaussian standard deviation on the blurring of standard deviation on the blurring of standard deviation that we will refer to starting to think that rather than still one big problem with the effect still so much more that could be done by stream TFT for 18 hours a day seven days strength of the hyperbolic curve to get structure tensor blur will be referred style perhaps then I could have found styles the standard deviation of the stylized image without any line integral such as paper color blending obviously suppression is determined by the take the original image again and apply tangent is fairly Limited in that we can tangent thresholding and we end up with team recognized this potential and technically run the dog through any technique in the world of image texture this isn't all we can do though textures like zoomed in armor and the than I know it has to do with the line than just black and white if we send the than the other now what were to happen that generally takes advantage of large that takes advantage of layered that we approximate the partial that's all from me as usual a big thank the best if unaltered but higher tone the candy Edge detector the inverse hole the difference of gaussians there's the difference of two gaussian blurs the direction of least change and we the extended difference of gaussian's the groundwork is there it wasn't until the image is calculated by convolving the image itself lets us capture very the image itself makes edges wider and the image with the Sobel operator such the output returning back to normal the the structure tensor but depending on then blend it back into itself to add then we can get more compacted gradients these changes have already majorly thing but in the opposite direction this think is quite impressive how well the think looks lovely as usual these this is the fault of our Edge tangent this marks the completion of our this marks the completion of our this marks the completion of our those parameters if I had chosen some those swirly artifacts in the distance thread thresholded the dog multiple threshold is now ran through a thresholding on the second dog and then through the process of perfecting the time applying the effect to Final times if we take a look at our dog to add as much artistic control to the to as Sigma C after blurring we to as Sigma e after doing our two to everything which makes it look much to illustration is known as cross to the other parameters windmuller two-point interpolation color blending two-point interpolation where we unfortunately this version of the unhappy with these interwoven parameter unlocks multitudes more stylization use of the double dog technique here to use of white space and while it doesn't use quantization thresholding for a much use to create a structure tensor this is vectors point in the direction of edge very easily anti-alias this by doing a very nicely selectively increase the very pretty this is ultimately a pretty very slightly blur the crosshatch and vote on the one that you think sounds want to tone back the exaggerated line watercolor color which is one medium watercolor stipple brush tone mapping we already see something that looks we calculate the gaussian with a we can actually travel along the flow we can see lots of yucky aliasing all we need in order to start stylizing we see more and more shading appear in we were to apply a second dog pass a well as increase the image blurring to what happens if we were to do something what's known as the perfectly stylized when we blend it onto a watercolor paper when we increase the sharpness on some where our next parameter of the effect which allows for a much wider range of which is what all modern games make use white and everything else is black this white based on the dog term this method wide variety of painterly Styles without widely used and popular Edge detection width but how is it even possible that will wildly change the output with a with flickering pixels I have no real would like to have a say in what comes you all a list of video titles and you you to all of my patrons helping me your day and I'll see you next time yourself a ace roller what about colored zero if we juxtapose this with a maximum"
  },
  {
    "video_id": "5y1Oin7CcI4",
    "title": "How Game Engines Make Shaders Easy",
    "publish_date": "2025-02-26T12:40:38Z",
    "comment_count": 0,
    "transcript_text": "CPU to GPU memory latency we would CPU to the GPU now everything is in GPU driven tasks like the aformentioned GPU memory and control when shaders Graphics API code functions that unify Graphics API code too they also provide Graphics API feature known as Shader Graphics apis Windows supports directex Graphics tooling please check out the Language by mixing the two now that Output images to your screen this Rola or click the link in the Shader authoring to create cool novel Shader based on variable name rather Shader code they make use of another Shader compilation and abstracting GPU Shader compilation because automation Shader each kernel has a line of code Shader effect like a separable blur we Shader effects I would need 10 plus Shader file because the Shader compiler Shader it is often desirable to have Shader needs the current viewport Shader pipeline instances with now we Shader prepared for compilation I have Shader rather than doing doing that work Shader to work with gd's compiler I Shader wrapper class that interfaces Unity also has a whole list of other Unity completely offis scates the Vulcan code responsible for command a Unity compute Shader differs from a a a compute Shader not confusing at all a compute dispatch and then depending on a tough time but what you might not know about the resources a Shader needs that abstraction and actually dispatch some abstraction is called the rendering abstraction layers heavily simplifying actually execute remember that a Shader all my current patrons without your all up for us so we don't have to care also handle the compilation of your am talking about specific engines today and I am very much missing how easy it and Vulcan but Apple only supports metal and can dispatch its Associated Shader and dispatch it which is great what you and how we can recreate that and requires two separate compilations and runtime recompilation now we just and store the references to the kernel and uses it to instruct the GPU to another feature we all take for granted any reason to compile the same Shader apis allow us to compile shaders to applicable because at its core are in a given thread group in glsl this arise once we begin trying to automate array has changed since last time then as a string to the Constructor on as it involves a lot of linear algebra as possible for you the engine functions as replace the command list with the as they can to make this process as easy as we decided earlier our class will be as well any other generic 2D and 3D data associated with that variable but that assumptions how do we know which automated the separation of one Shader automatically compiles compute shaders automatically ultimately the graphics automatically when changes are made to available in the description please give back in the gdos script we can replace back strip out the thread group because of gdau Shader assumptions this before each kernel we read this file in before it that tells us how many threads behind the scenes for the direct X or best way to learn math data science and bind the texture we want at that bookkeeping with the references and such brilliant.org buffer bound to register zero before we buffers automatic uniform caching is yet built for Learners of any level whether but there is only one line of code caching for you so we need to write an calculus and Beyond brilliant's can run on both platforms you must now can take in a name for the entry point challenge yourself with advanced channel and help me continue making check the contents of each file compare code but in gdau it's considerably more code then we run the files through our a commercial engines make your life easier compilation because # kernel is not compilations in a hash table with the compilations which we create unique compile again unfortunately problems compile it and we have successfully compiler assumes the kernel function is compiler how many kernels there are and compiler will choose a register for you compiling shaders manually it's pretty components we need to recreate in order comprehensive range math courses are compute Shader is a simple one line of compute Shader language it informs the compute Shader quality of life features compute as their file extension and compute dispatch in unity dispatching a compute for short so we would call this compute for yourself the code is compute functionality has four crucial compute interpreter compile each kernel compute kernels as you want all in one compute shaders once again let's compare compute shaders we can't write compute computer science interactively with concepts I personally use brilliant construction of command lists so ideally construction we pass the file name over count of the kernel in the unity compute couple lines of code with unity's apis create a uniform buffer that contains created in GPU memory while the CPU creating an abomination of a Shader custom Shader language that looks like custom pre-processor directives but I data appears in these registers if we decided to name it a Rola compute or a declarations until none are left while declare a a texture uniform variable description thanks so much to brilliant descriptions is known as a uniform set designed around Vulcan and glsl so we desired kernel then dispatch and close desired threads per group on the line development platform since unity and device with the rendering device I can difference between the kernels so it difference is with the Shader uniforms directex Vulcan or metal these Graphics directive because in gdau the Shader directive but this is absent in the Raw directive for ourselves gdau is mainly directly with with a pre-processor dispatch function now the code looks dispatch function we construct a command dispatch the color correction we first do it for us the graphics apis provide do stuff like create a command list for don't have to specify in raw hlsl either don't really care about any of those the don't really know what's going on in don't really like how this line of code due to the need need for maximum easy to have two kernels in the same effect then we can have the compositor effect which is not great there's never effect you learn how to compile a Shader effects ask for a compilation of the effects like fractal rendering be sure engine for hobby s this is engine is fully responsible for what enough to automate but we're still essentially just math a lot of the everything works the same unity's executed when we dispatch the compute executed with our interface complete executes regardless of if we have file into multiple Shader files now that file is based on its file extension so file path as the key now that the file to keep things tidy the next files and compile them we know what a files with one kernel named main each find its way to the exposure and first blur horizontally then vertically for dispatching a compute Shader in gdau for every instance of your compositor for now if you'd like to try out a for sponsoring this video Even though I for you as well as recompiles them from disk and iterate through the kernel from me I hope you have a great rest of function declaration then go one line function so you can just compile once function that takes in an array of functionality so what actually is a functionality yet so we are stuck with functions are the kernels Unity solves gains would be running quite a lot game as I mentioned at the beginning of gdau does not expose Shader reflection gdau tutorial for a simple compositor global Singleton that on Startup will glsl code for thread group information glsl such that we are left with a valid go over the specifics of this later when go to the proper rendering backend goal is to identify and interpret the good do abstractions end while unity and graphics engine a graphic engine is graphics engine but there's just one has changed since the last time it was has changed we recompile the Shader and have the uniform buffer memory access hello everyone if you've ever tried to here a glsl version of our simple two hlsl so we need to identify how this hlsl why is that the case a kernel is holds a pointer to it next we create a hood but they have graciously covered it identify the kernel function names if no register is declared then the hlsl if you recall from earlier Unity compute in GPU memory this uniform set is what in Vulcan is over a th000 lines of code in addition to writing much less code in commercial engines without it our in raw hlsl we specify a memory register in so it's time to create our own Shader in the argument list and holds the include files but this is where it's at inconsequential they can just use information and Associate it with the information we need it's time to compile instead of H LSL like Unity does since instead of specifying registers in interface with the GPU Hardware such as interpret it first we declare the kernel interpreter for it second Unity involved unity and unreal do a lot more is I prefer how hlsl does it so I'll be is absent from the unity version we'll is bound to the Shader such that it can is far more verbose what is hundreds of is just a program that runs on the GPU is named blur. a compute so we pass blur is necessary this is generally fixed is no kernel named Main in order for the is not a valid Shader file because there is that these engines are doing as much it a star if you'd like to support the it easier for you to write shaders they it is this API code that makes up the it that I do again anyways that's all it's a pretty simple concept but in it's two separate kernels it's iterate through the file to find the its thing but what if we want to change itself this Shader compiler will be a itself to avoid all those duplicates if just as simple as the unity script yay just the name of the function that is keeping track of the kernel names and kernel name now that we have all the kernel separable blur from earlier knows what the entry point is insert the language I'm a narcissist so I've language let's begin by identifying how layer to simplify the dispatching of lessons can be directly applied to let's consider a simple multi-pass level as the others in regards to Shader lie on top of gau's rendering device life features to implement like Shader like Shader lab and Shader graph making line of code looks like this instead I lines of code in raw directex is only a lines of our custom wrapper language and list to bind the cach uniform set to the lists so that I as the user do not have lot of work and is also bottlenecked by low-level Graphics API code and are lowlevel as they can reasonably be which machine code the GPU understands manage main thing I want is that kernel make it easier for everyone before we go manages the shaders in a project like manually specifying bind ings imagine many people take for granted in my last math concepts I haven't worked with in a means that for some of my more advanced memory and recreate our uniform buffers memory management making it very easy to memory management so that it only memory there are other types of uniform might not realize at first though is missing something important the thread multiple kernels in one Shader file for multiple kernels in one Shader file this multiple times so clearly we do not want named a compute its Constructor will named main so it is not possible to have names at the top of the file and put the necessary by keeping a local copy of our need member functions to interface with need to give it the data it needs we need to recreate unity's CPU side normal hlsl one the first difference is now all that's left is to write a object attached to the binding provided of the kernel function with main so gdau off an annual plan when you visit offer with a free 30-day trial and 20% often requires making certain on Startup we search all of the gdau on the right we have the same thing in on the very first line in unity we optimized shap memory manager lastly organizational purposes for instance otherwise we'll get a syntax error on our a compute uniform functions as well our compilation attached to the effect our compute Shader abstraction should our desired exposure and saturation our sponsor this video has been our uniform variable declarations with over how it all works though a word from patreon as always a huge thank you to performance these Graphics apis are as place to finish up compute Shader platform but for commercial engines who plenty of stuff to do and quality of point for someone looking to improve pointer to the GPU memory where the pointer to the texture if this pointer practice there's quite a lot of careful pre-processor directive in their custom prefer to do this only when we have to problem not all platforms support all process is not a Divine Act of God but programmers through the use of apis that project files for those that have a proprietary Shader language wrappers proprietary language works and write an provide shaders with the data they need rather carefully crafted by Graphics recreate the GPU side buffers otherwise recreate the uniform buffers in uniform reflection which gives us information register to bind to an array of uniform retrieve the associated kernel ride a Shader for an engine like Unity saturation of our image based on the saturation values and the Shader can do search the gdau project for any Shader separate Shader files so let's get separate files when you're writing set and rebind them because this is a set then we need to update the GPU shaders are compiled each update Loop we shaders automatically which is something shaders do not specify a register for shaders without a language to write them shaders work at a lower level how should look about as simple as unities since Shader programming is also slower while we spend every frame so if you wanted to make a graphics that software that takes in stuff like model some code on the left we have a script specific API code depending on the specific register before the Shader specific registers and can work with specified a register or let the compiler sponsored by brilliant brilliant is the started on recreating this pre-processor stript Shader file code replace the name successfully automated shad compilation support I wouldn't be able to uh what is system for managing Shader compilations system that automatically compiles and take the file name of the compute Shader technically two separate compute shaders technically written in hlsl but rather a texture and a uniform buffer containing texture function that creates a uniform texture lighting information Shader code texture lives and will also know what than just covering up the low-level than memory register as far as I'm aware that modifies the exposure and that this Shader compilation will occur that we have a color correction Shader the GPU does so we cannot just change the GPU memory previously declared the Shader code so we need to write a the Shader memory and uniform caching the amount of code needed to do certain the desired platform that function will the functionality but split to the the games customers develop a solution the gdau compiler already exists our the good news is that we have the list so it goes off to the GPU to be the lower level Graphics API code that the shaders for each kernel we take our the size of the blur we Implement a set the underlying uniform cache our blur the uniform buffer this is also created the uniform variables so why do we need the value directly instead we must free the video though this is about where their file pass as well as the Shader their math skills for game development their names allowing you to have as many them with the cach Shader code and if it then change the entry point name then then on the CPU we must ensure that we then strip off those lines from the file then strip them off or translate them to there but G Do's intermediary third Unity heavily abstracts Shader this is a process that should be easy this is how it works in unity under the this is two separate kernels because this is why you might be surprised when this knowledge is pretty universally this problem with the kernel those values the CPU does not actually threads per group to the kernel names we to do it in raw hlsl technically we to make our lives easier in gdau first to the global Shader compiler to to try out everything brilliant has to to write two different versions of my top of the low-level platform specific topics covering basic algebra to unfortunately means the code is very uniform descriptors they will hold the uniform set that holds the pointer to uniform values change then we can uniforms on the CPU when the desired unity and unreal does if you follow the unity our goal is to implement a compute unity so these past few weeks I've been unity's compute Shader abstractions to unity's compute shaders aren't unreal are effectively closed Source we unreal go much further with even more unreal or game maker you might have had update the references in the hash table updates when necessary there's still us with the ability to do this with valid glsl next we need to attach the values and caches them locally if this values of two uniform variables in a values when this happens the buffer is variables but we don't need them right verbose a simple hello triangle program video I announced I was moving to gdau waiting for that data to move from the want to have multiplatform support for want to use for our new fancy Shader was to write and use compute shaders in way we don't have to bother with we also Implement a set uniform buffer we can ensure we only do it when we can interpret our new compute Shader we decouple the compilation from the we discuss Shader memory management we recreate the uniform buffer in GPU we should decide on the extension we we use the cached existing uniform we want to use in this example our file we've decided how our wrapper language we've made life easier by automating what the compiler chose for us this is whatever API works on their preferred when it's finished our gdos script whenever I need a quick refresher on while and I think it's a great starting while managing all of the uniform data whose abstractions are not yet as high why in unity we bind resources to a will be writing a rapper for glsl will work it's time to write and with an abstraction layer that goes on with the global Shader compiler handles work so today we'll be going over how working on writing my own version of would be quite annoying to have them in would have to split it into two separate wrapper language we need to create a write two versions of your graphics you make use of cover up and Abstract you move to a younger engine like gdau you want to brush up on fundamentals or your day and I'll see you next time"
  },
  {
    "video_id": "8wOUe32Pt-E",
    "title": "Color Quantization and Dithering",
    "publish_date": "2022-05-14T00:00:02Z",
    "comment_count": 0,
    "transcript_text": "[Applause] [Applause] [Music] [Music] [Music] [Music] [Music] accentuating pixels in this context after the dithering which i think looks animations to a sprite sheet to emulate anisotropic filtering point filtering is another neat effect is using sharpness are more detailed than they actually are art as it gets upscaled back to full artists have to gatekeep our mediums as you can see sheik looks much more at least i think they are it's hard to available colors to eight average gray level of the original image average of the four nearest pixels it back down to the same resolution which be able to replicate this appearance become very large as a rule of thumb you behaving like pixel art between edges in an image this increased between the two nearest mipmap levels black or white but if we increase the blurring when there's not enough space but first we need to decide on a dither by 1 add 0.5 and take the floor then we by a sharpness value and negative 1. by now it's common knowledge that dead case since all color channels are the cells despite looking acting and center pixel and this is our new pixel code is in the description if you'd like coincidentally the horizontal uv color count we get an equivalent amount color greater than 0.5 will be 1 meaning color if we first sharpen the image and color palette we first take the number color this results in a strange lattice color value of 0. if we instead passed complete if you want flat color sections compressed our colors to obtain our new contrast tricks us into thinking images control how much the noise spreads the converting grayscale images to black and converts it into the coordinates of the coordinate and when there's too much coordinate for a separate new color coordinate of each color block is dead cells uses a shader to flatten and demonstration of a few different color described in my elden ring video but ace dimension of the threshold map which distributed values from 0 to n squared divide it by 1 which gives us a new does this when space needs to be filled don't really need to do any dithering in effect that increases the contrast enough space for two pixels then it uses environment like my grass field field instead of a giant green blob even filtering are the same as bi-linear filtering except they also interpolate filtering is what we used for our filtering tri-linear filtering and fluid pixel or animations which allows for two pixels then it takes a weighted for us our render is already the same for watching everyone i hope you have a from this we can deduce that any color good on chic but what about in an great rest of your day and i'll see you happens when there's either not enough has now been reduced from sixteen hello everyone every time i make a new here's a montage of larger color i don't know man google it or something i mentioned converting a grayscale image identical to the grayscale value if we in 0.6 we would multiply it by 1 add 0.5 in as well individual pixels so our shader needs to inefficient instead we can pre-compute information on the grass and it turns into a smaller color palette dithering into this big green blob thankfully is an intentionally applied form of isn't actually pixel art because we as it from other art mediums the most its nearest neighbor in the new color just look at those jagged edges so today known as bayer dithering this pattern like dead cells then you can simply set like pixel art when rotated with the loot river in which all the enemies and map value we multiply it by 1 over n map which is a matrix of equally matrix maybe that depends on the texture me means enlarging them but unfortunately million seven hundred and seventy minus 1 where n is the dimension of the mod the position by n where n is the much space the four most common sampler multiplying the uv coordinate by the next time no time to noise which is used to prevent large now downscaling by itself might be now that our color palette is reduced to nowadays with a recent example being number of colors we lose all visual objects in view and remove any depth obvious feature of pixel art is its low of anti-aliasing of colors we want and subtract one then of grayscale values if we visualize of look like color palettes you see on on anti-aliasing on the screen which is obtainable by one this will convert any color value to only want to down scale and upscale by orthographic projection orthographic which will flatten all our grayscale colors on the left we have our grayscale values with any color out of these four options the one we palette as long as our palette has the palette for example let's consider the palette from two colors to 256 here's a palette how can we convert our image palettes palettes pattern across the whole image while pattern to use for my demonstrations i perception pixel art which is a limited color pixel's neighbors and multiplying them pixels is roughly equivalent to the pixels of variable width and height pixels we're not quite finished yet i pixels when they are upscaled or down please let me know what you think thanks point filtering will preserve our pixel powers of 2 which will keep your pixels pretty cool since it accentuates the projection currently our camera is set range then we subtract 0.5 this final reducing the color palette to 2-bit remedies this issue sharpness is an resolution back to our shader if we down resolution which accentuates the rolla wouldn't this blur the whole image same amount of colors as grayscale same value then all pixels become either same way we did for blurring as sampler available when there's not sampler we use when we do the scaling satisfactory for you and your game but scale our render a few times the pixels scale patterns like color banding one of scaled specifically they define what scaling and eight colors per channel if scheme we could theoretically replace see a lot more detail out of our grass several distinct aspects that separate shader like this even work pixel art has shader's control which is the camera sharpening an image involves taking a sharpness value and 4 and add 1. lastly size as the screen if we enlarge it then space for all the pixels or there's too space then it fills in the space with spend years animating each individual square if you don't do this you will get squared to convert it into the 0 to 1 starts by retrieving the threshold map still have one more effect to show to support any n-bit color palette from 2 table to be used by the shader finding take the floor and divide it by 1 which tell sometimes regardless how does a texture samplers control what happens to thankfully the algorithm expands to that objects have depth to them if we that our image is only allowed two the cheapest easiest smallest brain the color of the closest pixel bi-linear the color of the closest pixel to that the dither spread to zero but then you the first place this shader looks pretty the individual pixels our effect is now the most common uses of dithering is the new color of a pixel with dithering the pixels have nowhere to go except the player are actually 3d models the values and store them in a lookup them to support the wide variety of then apply our pixel art filter we can then we multiply the center pixel by a there exists a simple image effect that these colors in a row it begins to sort they fall in line one at a time think wow i should really make a video this conversion could be thought of as this looks neat we still haven't this obviously doesn't look very good so those fancy color websites i wonder if thousand two hundred and sixteen threshold map value with the threshold threshold maps in real time it's really throw me lose to 256 to black and white this is the two color to change the projection mode to to downscale our render first in the to enlarge the dithering and accentuate to our image we multiply it by a to perspective projection mode meaning to play around with it i'm pretty happy tri-linear filtering and anisotropic two color case if we passed in a color types are point filtering by linear upscale a 3d model then it bakes the user-defined spread value which will utilize the same down scaling technique utilizes something called a threshold value add 0.5 and take the floor lastly value and use it as the horizontal uv value is the noise that we'll be adding value less than 0.5 will be 0 and any value of 0.2 then we would multiply it value we take the position of our pixel values per color channel our chic render values we can create any size color video i look at what i've created and i want for pixel art is quite obvious the want to emulate pixel art then we want we add the neighbor's values to the we can do anything with that looking at we divide by the number of colors minus we down scale it all or reduce the we have 0.25 and 0.75 in the middle we have one issue that is outside our we multiply our new color with this we're still missing a crucial aspect of we're talking about the exact opposite weapon this technique is really common weapons in the game without having to well that's about it for me as usual the were to perhaps take this grayscale what are mipmaps you ask whatever we think looks good we can when down scaled where pixels are either white or black which will look really bad unfortunately while it is possible to calculate these while it looks nice without any down white such that the density of black width or height of the screen then we will be using ordered dithering also with how these effects turned out so would give us a new color value of 1. wouldn't accomplish much instead we need you back when i was explaining dithering zero and on the right we have one then"
  },
  {
    "video_id": "9dr-tRQzij4",
    "title": "How Do Games Render Fur?",
    "publish_date": "2023-10-30T22:57:45Z",
    "comment_count": 0,
    "transcript_text": "30-day money back guarantee try out surf Blades of grass for essentially the same CPU can make use of complex State Creations on Twitter with the # a Rola Define a default directional Vector that Discord server for some discussion Fidelity Hair implies a great geometry Fidelity grass but we still get the same GP you know which pixel to draw normally GPU at all costs I certainly have said Grass Grows out of to visualize this as Hair hair is going to get very expensive Hardware has advanced 1,000 years to be Implement shell texturing then I want Jank the camera enough so how do we fix Lambert breaks the laws of physics Mass amounts of Free Labor also I'm live Moss mesh which is what we were trying Parallax mapping billboarding and even Pinata is from 2006 though so let's look RNG hashing functions range from simple Shader extrude the shells outwards from Shader this way the direction the hair Shader to discard its work when certain Shell's fragment Shader will be executed Souls unfortunately CF is where this Square's height instead of zero since VPN service dedicated to keeping your Valley and a sort of perceptual Vector to be defined in the larger scope Vector to the opposite direction and now Viva pinata's style since memory [Music] a lot of objects in the scene if you're a method games have been using for a post-processing effect I don't have to a protagonist that has a beautiful head a sort of stylized Dand Lion at this able to afford this insane geometric able to break the illusion this sounds able to handle hair light interactions about that later the important part is above the ground since the UV accentuate the broken illusion speaking accurate simulated interactions we you actually fix C because the issue there actually talk about one important topic additionally it has extremely high afford decent geometry for good-looking after all hair is a major contri again until we have some arbitrary algorithms as the ones demonstrated in all from me I hope you have a great rest all we need to do now is add this allows us to lower the shell count allows you to get around Geor already looking at a lighting model that also makes it worse for everyone when also moves around so let's look at a also vote on the next next video topic amount of overdraw the outer shell is and also serves as a great reference for and doesn't droop at all in reality and genin impact make use of the last and geometric burden on the GPU as much and it's clearly not good because we and live with the length we've got which and other contributing forces such as and so on and so forth until a pixel is and then we should repeat the process and we'll go over submissions in next and whatever this is supposed to be andrue solution to the geometry dilemma another color to look more like hair the any more work but if the object is in apart this is why Si looks so weird appearances but now when we swap back to arbitrary mesh by extruding the shell are black indicating that the grass in are going to be exactly the same but now are kind of unique in that conceptually are moving we set our hair displacement are still using today just telling you around so much that it results in a artifacts when you look at it the wrong artifacts worse if you play a shell artist authored additions to models that as a middleman between you and your as demonstrated by The Game Dev Guru in as easy as possible when it comes to as possible but I didn't need to do much as simple as making it work with as simple as possible this grass here is as the initial Square the random numbers at a more modern example with genin available and fully annotated in the avoid moving data between the CPU and bad for my ball of 256 shells you can ball looks way cooler and way more bandwith on gpus has increased immensely because hair is composed of hundreds of because it doesn't follow Lambert's because now there won't be any cascading because otherwise it won't feel very because this Square represents the because we as humans are much more becomes very obvious that it's just a been filled in this is called overdraw behind what has already been drawn then believe they are talking to the VPN this best to draw objects front to back to betrays itself and only serves to big deal is with overriding a few pixels big deal what makes hair so difficult to big drawbacks of this Tech shell bit more like hair now when I say hair I blade of grass back in unity we see that blade of grass because the square only bleach this is then complic ated even bottleneck when it comes to making games bristles on a toothbrush I mentioned browsing from in fact you can make use bunch of quads and not actual Blades of burden light interactions that are as but for Unity I have fully annotated my but honestly if you're not going too but now the most pressing matter is that but obviously the majority of values are but this one is going to be a little bit but today we'll be looking at a tried by surf shark surf shark is a popular by the nature of hair itself smoke is by5 and add .5 to translate the range calculations Unity is smart most of the camera data and any other variables that camera if the camera is locked in some camera when shells are viewed at can also somehow render infinite can easily see through the entire grass can you render something that is smaller can't visualize millions of grass blades cat has around a 130,000 strands of hair certain that gench and impact is using challenge I want you to learn and challenge come ask away anyways that's change from frame to frame what we want channels and some beginner resources if character with hair that is visible also clamped dot product which we multiply classic lambers and diffuse as described comes to grazing angles lastly Viva Pata compare the random number to our new complex in one or two aspects and a lot complex which is the first thing you complicated as it gets and physics Tech complicated physics because the way hair conditions are met for example if contributing factor to The Uncanny coordinates of this Square are the same coordinates to operate in the local correct I also like to clamp the dot cosign law but in my opinion it looks could easily conclude that it's probably could just add more shelves to fill in could render millions of grass blades so could simply not increase the distance counts it is ideal for imitating counts on their Moss you can only see coworker Rory's main portfolio project crazy on anything else you might be able created what's actually an incredibly critical flaw of shell texturing if we current day we can actually more than current patrons without your support I currently our hair sticks straight out decades to fake fur grass and other dedicated to just the hair of one person demonstrating the dangers of overdraw so describing something that breaks the description below but if you just want desired destination keeping you private desired thickness and if it is we developer looking to improve your didn't fix it you don't have to either didn't have to worry about complex different outputs and overall the different story when it comes to Shell different this video has been sponsored directional Vector is not going to break directional Vector to our vertex directions instead of instantly snapping discard checks into one by multiplying discard its own work then how does the discard the pixel giving a cylindrical discontinuities but it still looks like discontinuities in the mesh this is how discret segments of Springs and apply displacement Vector each frame but a displaces which is great unfortunately distance between shells makes when it distance this is all it takes to finish distributed random numbers we don't have do this in whatever environment you want don't forget that for a cat it is 200x don't forget to check out surf shark and dot product for shading instead of the drawn first and its pixels are clipped each one of these categories is complex earlier that Viva Pata uses this easy because the transmission of light effect yourself you can also join my encapsulate the full extent of possible enough to allow the player to break the enough to have its own hour-long video entirely driven by texture data we can essentially for something like a sphere every pixel that was rostered and then example solution which is avoiding examples since shell texturing creates excellent beginner graphics project but excited to announce the ace Rolla furry executed and it is rostered to the extensions are endless and it's a extra months on your subscription when extrude from the mesh in order to C the extruded our shells in the vertex Shader familiar with hair and what it looks feel like most topics are only truly fiction and remember that this is all field this is also why I know for filled in or every shell has been drawn filled with beautiful environment art finalize its position and then the finally see the fruits of our labor 16 finish up the lighting by applying some first before trying to be funny as a fix is known as fin meshes which are fluffy and stylized when we erase the for General random number needs with a for data breach alerts antivirus and a for just one instance of hair in the for the other directions only the CPU formless fluffy blob from any other formless midtone Shadows especially when fraction of the cost this technique of fractional part of our multiplied UV fragment Shader we test the distance fragment shaders for one pixel is pretty from Dark Souls we can translate our from Dark Souls where the lighting from negative - 1 to1 to 0 to 1 the half from the CPU to the GPU every frame to from the camera with what is currently from the death destination as they from the ground's perspective then we front of what has already been drawn full head of human hair the average furry Challenge and tell us a bit about further by Common outside influences on further when you consider everyone's game but it shows that this technique game you have to admit genin impact is games today but first something entirely gee this has been a lot of words gench gets away with such few shell general with shell texturing as a generate bin meshes or improving the genuine stepping stone that has real geometric slices is called shell geometrically can't curve so you're get 3 months free with your subscription get a convincing output for just one get some easy lighting we can multiply given my content style you may think I going to have some crazy realistic good instead of what is technically good to you will probably work just fine gradients creating obvious grass blade is horizontally from its grass but the intent is clear Viva grass field into something that looks a grass field on this flat plane then we grass in her are pretty similar if you grass instead of cuboid grass ideally we grass now without any obvious grass we have a few options here we grass would you rather render 20 million gravity should be pulling these long greater than zero so we end up with a green furry ball that we can change to ground and where all the grass is growing out of so we draw another square hair Illuminating the volume underneath hair grease and other General volumetric hair is radically different and the way hair is transparent which immediately hair on people but for Animals it's a hair physics although you'd be hard hair so problematic it's geometrically hair that can be on screen at the same hair that radically change appearance hairy needs of nonhumans for instance a hard to render when even movies are harsh lighting model without any ambient has no mesh in my video about rendering has one seed value possible from the UVS has to move otherwise it's not very hashing function in hand we compute a have effectively wasted computational have their place in the modern era like have to but updating a single have to do subsurface scattering since height increases so we can combine our height is zero at the base of the hair higher density we see a few black pixels his performance analysis of the forest honestly looks more like a rug than how our Shader is even discarding pixels how simple tried andrue techniques still human hair types and the way those hair human head of hair per square inch but hundreds of thousands of objects now if at any point we are allowed to look if each shell is its own object and can if this distance is greater than our if we move the ball around it doesn't illusion the technique also scales imagine a scenario where gpus can handle impact Viva Pata and tons of others impact regardless of your opinion on the important Boon of shell texturing though in fact we are met with a much more in my video on water this is a pretty in order to get more Blades of grass we in order to reduce the triangle count in real time and monitors they now have in the Z buffer and if the object is in the zbuffer when we next tell the GPU includes updating Shader variables we increase this distance too much then it increasing the distance that the shells infinite resolution somehow and games infinite triangles and Ray tracing influences is different too so we're inherent Hardware problems with insignificant since such few pixels are instantly because it takes time for our instead we make use of hashing functions interaction it's actually insanely internet browsing activities private and internet connection as well as obscuring internet from another country this interpret that as the presence of a involves really complex lighting is because shell texturing involves is consistent but hair is not consistent is instantly broken and the effect falls is one and we get a full displacement is that the distance between the shells is too large fin meshes also wouldn't is up over on my patreon where you can is what a Pata does we could increase isn't really a good way to fix it it as their camera does not go low it changes Behavior depending on how old it from genin Impact and Dark Souls it interacts with those outside it's simp Simplicity shell texturing is it's the top layer since nothing got it's versatile is pretty boring though its distance from the camera is stored its vertex Shader is executed to just 16 with 32 shells we can get longer just fine it's not what we want we want kill them for having hair and it plays kind of gets the job done with minimal knows what buttons we are pressing which last reminder this code is freely leads to tons of other discoveries like let's imagine the scenario where you are let's take a closer look at some of the light physics but since it's all done as light so I tried out valves half Lambert lighting model or making the physics not lighting or physics this is what makes lighting problems there are also like a joke but it's really not plenty like hair fur grass rugs Moss hay or like paper strips they also use shell like rudimentary State blending but it like so we are able to spot a like thin strands it's easier to like vampire survivors unfortunately limit the camera in some way in fact local Center by calculating the longer blades this is as easy as look more realistic aside from the look much more convincing than the looking at a few hundred, triangles looking hair we should do what looks looking to innovate on something like machines to produce uniformly magnitude of the trans ated local majority of the square is still green so make just four shells look really good make the f as large as we want and have makes it look entirely solid at this makes use of High Fidelity textures to many times over in lots of games the many years the most iconic example is materials like fur carpet grass moss and maybe even something low scope like the maybe trying to programmatically means 100x 100 Blades of grass with a means it must be even harder for us to means our shell texturing causes immense means we need to have the CPU update our might prefer a post submission but might think every number was greater mileage for its performance cost million times especially if that work millions of grass blades I had to minus the Shell's height different model and how are video games solving moment you look at it slightly wrong and monitors are composed of millions of month for the 100K subscriber special as month's video as an added incentive if more pleasant here and if we aren't more than anything and would prefer you more to make it look like grass so I more villain that few people ever most of the grass isn't freakishly tall most out of as few shells as possible most popular example probably being C mostly green square but this makes sense move left the hair follows behind moves is also dependent on the hair type movies and shows that are available in moving from our Vector each frame and much reading on the subject available we much to Surf shark for sponsoring this multiple segments because otherwise it multiply the UVS by a density value multiplying the displacement by the need to interact with each other at needs an insane amount of parameters to no I value sincere expression of self no performance concerns since it's not noise gives an illusion of complexity nor have I done much physics programming normalize it before passing it into the normalized height of our shells when the now identify how far away a pixel of the number of shells we do have several number of squares like 16 for example at number that feels random ideally seeds object first and then the original object is rostered to the screen and object so we could have skipped that obviously hair isn't very square like obviously this looks ridiculous we want occlusion between strands this also of Sur sharks servers around the world of a visible pattern to how it grows so of each other and then in the vertex of games have fixed camera angles or of hair but gets eite into a universe of more shells our technique has one of rendering extremely high triangle of scenarios where it doesn't work so of shell texture string for moss on of the grass with our low IQ lighting we of the hair which we can do by of worries can be easily discarded or of your day and I'll see you next time on Shader toy so whichever one looks on their head so how would you model only want to update what we absolutely opposite direction this finishes our optimization issues because the smoke or twice but the worst case is every or young it is meaning that it is origin of this space is in the bottom other beginner projects my old Graphics other best solution which is to keep it other countries but not your own surf other shrubs the list goes on you've otherwise they would one tried and- true our game and pretend it's intentional our hair now droops instead of fully our hair responds to our movement our plane is entirely green at first you our shells to make the sphere look like our thickness with the grass height out from the normal of the base vertex out we can get rid of pixels we don't outputs should be as uniform as possible overhead of realistic hair after all we overwrite the pixel that has already parallel angles but this wouldn't parallel to the layers then the illusion per square in of their body which means performance concerns but we'll talk perhaps Viva Pata which used shell person has 80 to 120,000 strands of hair phenomena this is made even worse physical phenomena this all comes pixel This is complicated even further pixel means grass is growing out of that pixels on the top layer indicating that pixels so it would probably be bad to do point of view if you try to have point we have really basic solutions to point you'll have so many thin meshes pointing to the right and the opposite points changes over time instead of poorly because of overdraw so you can't position multiplied by the strength of position now all we have to do is check potentially hundreds of times this is power on what was already drawn there it present grass probably doesn't have much pressed to call this physics it's more preventing your ISP from throttling your price and we can take it to the extreme problem hair and other similar materials problem let me preface this by telling problem of hair but remember that hair product in the half Lambert resulting in promis this was not all aoy to get you provides a number of benefits such as quad if we want to represent a dense questions about the video or the raises tons of red flags because now you random if there's a general Trend to the random number between 0 and 1 and if the range from 0 to 1 from the top left to rays will transmit light through the real geometry like with my higher real-time rates and this is not simple realistic lighting our shell textured realistic lighting without also tanking reality some amount of data is moved really basic solution to the physics rectangular hair from earlier we can reduce overdraw as much as possible referencing it and implementing the regard such as not being a able to regularities much easier and identify related physics while keeping track of relative to Artistic potential shell render hair in video games so what's the rendering for my Counter-Strike video rendering hair because hair is often requires an understanding of complex resolution in real time unfortunately we resources also this finishes our hair in respond to the movement ideally when we rest to represent the pole of gravity restrictions enabling you to watch result of a visually dense field for a right now over on Twitch if you have any right which is kind of awkward so we roller didn't you say that we should rostered and being overwritten but when rotate then the player will never be scene we would need to do this for every screen but now before we execute the search engine that keeps you private but see between the layers at all you can see here how much of a difference the see that it's a formless green blob to see that when it's far from the camera seed from the UV coordinates remember seen this in games like Dark Souls genin shading to the whole body with the shark does everything you've heard about shark hello everyone if you've ever shark today risk-free and get three sheer density of the strands and visual shell clips that pixel and executing 256 shell textured grass from a plane to any shell texturing because we can see shell texturing genin impact makes use shell texturing is an amazing solution shell texturing repo that explains every should think of it like the ground that similar effect on our own shell textured similar materials it's way simpler than simple geometry it's ideal for materials simple non-photorealistic lighting as a simpler lighting to avoid making the simplified for instance the smoke simulation might treat the shells as since I am choosing the topic for next since most pixels are being rendered to since then now I know what you're saying single line of code to make this hurdle so let's go back to grass for a moment so let's take a closer look at some so short that there isn't any room to so that it maintains State over time so this information I'm about to give solution to the geometry problem very solution to the lighting problem and the solution to the physics problem we have something a million times only to throw something more strand-like we take the something out of cube world to get something you should look into none of sometimes it breaks and ruins your day space that our grass blade occupies the span across but it immediately reveals a spatially different as you go along the specifically mean fur because in the sphere and when we look at the grass spot and a black pixel means no grass is squares that stack on top of each other start by rendering a single static electricity random clumping of still have one more major problem hair strand of hair This is complicated strands downward a more sophisticated stream when the next video releases also struggling to get good hair CGI that stylized Graphics then it is absolutely subtractions to result in the complete such as moisture shampoos grease or such as the current frame time the such as this fluffy fur break down that suffers from from major aliasing take the subject matter very seriously technically composed of one really big technique begins to fall apart while technique for the fur on their animals technique that mimics complex geometry terrible or fixing the aliasing problem terrifying opponent hair lighting models texture data let's imagine that a green textured data instead of white noise the texturing and has been used in games for texturing because of all this I'm texturing for the Short Grass which texturing for their entire style okay I texturing fur is probably the number one texturing is an archaic Graphics texturing is an illusion an attempt at texturing is not perfect though and texturing is where it can go it is like texturing question for a flat field of texturing strengths then you will reap texturing unfortunately our clipping than a pixel but don't worry let's than zero but no our plane is that a lot and it's still true but in that all away to do it again another that are close in value will have wildly that each strand has to be composed of that for a square the UV coordinates that got him the job involved shell that less light is reaching the depths that makes up the roofs of some houses that makes use of the full range of the that sort of privilege on the GPU that spot was not tall enough but the that we can have much longer Blades of that you ended up with a high fidelity the Smoke video which is really bad the ball covers the camera our frame the bank on the CPU whichever dire we the best part about surf shark is their the bottom right pushing the seed the color of the grass by the height of the cost of more shells you'll get C the cost of whatever it is for a human the displacement is canceled out but the displacement to only affect the tips the displacement while this is working the distance and call it the style of the effect we now effectively have a the field for example a density of 100 the first thing we'd like to do is have the first upgrade in the tech tree that the gaps in the shells we can see a the gaps when you really try hard to see the geometric level like with the grass the geometry problem and the lighting the hair to transition between these the hair will Point towards while at the illusion of dense geometry from the last big example is CF from Dark the link in the description thank you so the new gaps it's 2023 and not 2006 so the normals based on our desired the performance impact of overdraw is the rewards and if you're an indie the sphere the tapered strands of hair the square which gives the impression the strands are rectangular and look the subject mainly because there isn't the true educational value of shell the unfortunate reality is that there them because other otherwise it's a then isn't shell texturing but the then its fragment Shader is executed for then we execute the fragment Shader and then we subtract the direction we are there are at least 100 submissions I there's no grass then discard the work there's probably more examples in the these aren't amateur Productions if they these empty pixels are blocking our view these strange artifacts on the body are they get very complicated very quickly I they require the expense of one full thicknesses have very different think about it so let's convert our thinner than a pixel on your monitor how this this critical visual bug we don't take this default Vector will Point downwards this gets rid of those pixels but now we this is how Viva Pinata gets away with this matters compared to the most this means a pixel could be checked once this means we have to do similar this point there are barely any green this process again with the new height this so let's try and make it look more this square is a bit taller more pixels this video has been sponsored by surf this would maybe be okay for a game with thought about hair for even a moment you thousands of strands so in order to get thousands of transmissive operations to through the gaps in the Moss when we through the hashing function gives us a time and knows this is bad and tries his time and the cost of that High Fidelity time increases a considerable amount to avoid in the first place the problem to avoid is mass data transfer and that to complex you can find a bunch of them to cover all the discrepancies and at a to create the illusion of a cohesive to draw an object its vertex Shader is to fix this we want our directional to get away with decent shell counts on to play with a furry ball then a build to pretend like you're using the to take a seed number and Shuffle it to watch a fifth video about grass but together to inform us that realtime High together without doing much reading on too many shells you're limited to towards the tip of the hair the height translate it to the center and we can trees and rocks as well as the straw trials and tribulation do not stop at triangles or 32 triangles surely we tricking you into seeing more than there types interact with common natural understand complex GPU coing algorithms update variables that must be updated use case and you've definitely seen it use shell texturing to visualize generic use too many shells since you can't use useful since hair moves that means using simple shells bypassing the cost usual a huge thank you to all of my value is greater than zero let's velocity and acceleration but we're not versatile piece piece of tech that games very few lines of code it makes for an very quickly we are also ignoring the very smart around here so let's just video now let's learn about shell visualize differences on the flat plane visualizing complex volumes with simpler visuals Viva Pinata makes use of the volume of Blades of grass since it's volumetric functions or even something vpns before and more offering services waiting wasting my time with this shell want by just telling all the pixel want the thickness to taper off as want to do our physics after we have way because in reality it's just an we can afford a few more shelves than we can discard the pixel and not waste we can model it easily with white noise we can't see our Grass at all it turns we could reasonably afford fancy hair if we just draw a bunch of spheres on top we really wanted it unfortunately the we remove the fake ambient occlusion on we should draw a third square and repeat we've glossed over this whole time is what does this have to do with our shell what you learned and what you improved what's basically a layer cake of meshes when in reality the mesh is simple when it works it turns out there's a lot when the hair just doesn't look right when we do our grass presence check we when we tell the GPU to draw an object where do you put the fin there's no way where everyone is bald and is trying to which gives the iconic pinata look since which is a non-physically based model which is just random numbers while the which is what Dark Souls does or we which will be most of the pixels since which will be the width and height of why it's absolutely critical to make the will eat these really hot peppers on with only a few squares or can we we with some anti-aliasing or maybe you can with something like 256 shells which work for gench and impacts Moss because work um Mr R I don't really see what the works for more than just hair and fur world industry applications unlike many worry about triangle count or other mesh worst physics you have ever seen as a would have been better to draw this would have to do at least tens of would notice about it probably how could wouldn't be able to enlist viewers to do written to the zbuffer then the next you UPF front I'm not a physics expert you even begin to efficiently render a you is complete that I put you think and it's still being used in you to improve it in some regard you can you try to fix its issues why are you you use promo code Ace Rolla or click you will only ever see in science you're new to shaders post your your data secure a VPN works by acting your deadline is Sunday November 19th your game probably has many people with your personal data such as where you're"
  },
  {
    "video_id": "BJvoaBeqVm0",
    "title": "Game Dev Tutorials Are LYING To You",
    "publish_date": "2022-02-19T01:00:02Z",
    "comment_count": 0,
    "transcript_text": "000 meaning we can only have 65 000 110 fps 2007 60 million noise values each frame which [Music] [Music] a newer game developer or an aspiring actually pretty nice here's a short clip additionally you can create new geometry ahead and cheat to fix the problem and algorithmic optimizations will always all that's left to do is increase the all you have to do is google it the main always contextual and differ from game am i jealous and and they need a cure and we have grass blades animated yet the reason it's so bad is any tutorials that portray the subject anything else and would consume all of appearance with the same color logic as are being created by my gpu every single are written by jasper flick at aren't for a beginner audience generally articles on why geometry shaders are as simple or easy because they are quick assure you the issue is prevalent all at least has something to google i'm at this point you may be saying to bad or be targeted by my audience of two baiting you nothing about game based on the iterator until we have a because geometry shaders are notoriously becomes dude just trust me but like dude being deprecated due to how terrible billboard grass i described in my first bit more than my grass blade 3d model we blade and move it based on the noise blades and we have an average blades of grass rendered in my optimized blades of grass with the knowledge but i mean it's a tutorial that's calculating 23 million 520 000 noise calculating noise per vertex purlin can be learned by doing traditional catlikecoding.com cherry-picked a tutorial off page three coordinates so that the bottom of the creates a blade of grass with 12 cringe detrimental to aspiring game developers developer wants their game to do more development is easy it's one of the development tutorial i read leaves don't have one in your shader code then don't want any of the authors to feel don't want to i only showed off two each grass blade is composed of 30 editor ace rolla here this is incorrect effects like flat shading or explosions executes every frame which means the gpu fails to mention that the default upper far the best game development tutorials faster a lot of optimization techniques field of grass for learning real world rendering for the sake of privacy i won't be forward but until then i hope you have a frame which if you think about it it's gained from this particular tutorial game and yet nearly every game game developer be very wary of the game development tutorials are sick generation that my previous grass videos geometry shader this mesh generation governs the processing of the primitives grass blade the tutorial i'm following grass doesn't move the result is grass i've gone through the trouble of grass rendering utilizes the geometry grass video but in order to truly limit grass video which was in a textbook from grass way which i'm sure will work great great rest of your day and i'll see you hardest programming specializations by hello help you for game development specific highest priorities the faster your stuff hit of calculating noise in real time to how great the tutorial is i forgot that since there is no triangle i found so let me go over how it works i'd also appreciate if you subscribed i'm pretty far from my goal of 1000. i've got some cool stuff planned moving if you're a tutorial author i'm begging implementation starts with creating implementing it according to a tutorial in game development especially in this stage by appending vertices to include how to make what they taught you incrementally increase their height index buffer for the geometry shader intentionally bad implementations for interruption into all of their tutorials and makes it is creating that new geometry throwing is quite a bit more sorry for the issue in early november when i was it away then creating it again then it doesn't work it seems the tutorial jasper puts tons of context and info just trust me i took notice of this knowledge out of the way our new grass lastly i recommend checking out learning resource i don't have many limit of mesh vertices in unity is 65 little bit though instead of these little stiff though so we should get it loop through the vertices and meant how are they supposed to learn millions of triangles at 110 frames per most tutorials you learn from won't moving around my argument a little because my source my coloring and modern foliage rendering naming any specific tutorials because i need to write the logic for creating a newly created triangles to the output next time no noise for every vertex of our grass noise is very computationally expensive noise per vertex for a simple animation noise textures to avoid the performance non-game development programming general number of blades so that we have a dense objects these points make up the of a mesh the shader operates on one of google to prove your point oh no oh well that's anything but tranquil the on a grand scale would leave no room for on the internet for unity specifically only one place did i read about the optimizations optimizations as an exercise for the optimizations i heavily recommend optimizing your systems is one of the or maybe you disagree with me entirely our geometry shader to be applied to we over the place especially youtube i'd people i understand that this undermines performance performance of uh points being different grass blade points for our grass to sprout from possibly optimize whatever you're pretty impressive that my gpu can create pretty much every game uses pre-computed primitive at a time rather than one professionals in the field but they put it into perspective we are reader even worse many tutorials teach really appreciate it if you commented reason this is so slow is because we are reason this is so slow though is because recommendations but for graphics remove the unity vertex limit researching how best to render grass and result with hundreds of comments about runs the more stuff you can fit into the second but i think the average game shader and the fragment shader it shader so i'll call it geometry shader shader stage exists between the vertex shaders are entirely optional so if you shouldn't be an issue lastly geometry slow in fact they are kind of on their so much so that i've met some people so what's to be done about it if you're specifically the gpu gems series of specifics as to why because thankfully srola why don't you write tutorials stream tall rectangle then we append these teaching if you mention some vocabulary teaching me how to do this so clearly it teaching someone to calculate purlin techniques and their applications terms then whoever is learning from you terrible tutorials in this video but i test the geometry shader grass i'll go textbooks as they are a tried and true textbooks is by far the best resource than just that our grass is looking a thankfully i already have code for this thankfully i found a great tutorial on that didn't even know what optimizing that's a bit less than the 8 million that's a lot that's not good the grass isn't even the most important aspect of programming the sake of simplicity the shader code this functionality is the stage is skipped with this prior the triangle output stream defined in the triangles for this field of grass then sprout from with a mesh created for there are actually plenty of good there are no shared vertices that means they are i'm not going to go into they look kind of ugly though so i went this effect is incredibly simple all this field of grass contains two million this misinformation is extremely through the trouble of improving the throwing it away then creating it again to game but there's absolutely no excuse tutorial has almost six hundred thousand tutorial on grass teaches a horribly tutorial practices tutorials that you learn from especially unfortunately not this grass sway unoptimal method a method that if used use we have to change our perception a value multiplied by the vertical uv values to animate this grass each frame vertex at a time like the vertex shader vertices of a mesh that the grass will vertices so we are actually calculating vertices which if you recall from my very clear what is and isn't optimal video on grass optimization is already a views on youtube and is the first search watching gdc talks that are posted to way out of the industry and are slowly we should probably start by learning we're going to do is generate purlin well aware that optimizations are almost what a geometry shader is the geometry what a tranquil vibe but let's check the what allows us to create grass in the what are they lying to you about only what i did find was that nearly every what is right if no one is teaching it which allows you to do some wacky written we can use the same point yeah a little bit you might be saying to yourself hey you to at least just mention how to your game's resources this method of your own feelings about predatory yourself and my answer to that is i yourself asrolla you probably youtube because they are done by real"
  },
  {
    "video_id": "DUBylsnGuLw",
    "title": "How I (Almost) Won My First Game Jam",
    "publish_date": "2021-11-09T01:00:03Z",
    "comment_count": 0,
    "transcript_text": "1-bit style game 10 days plenty of time so what are we 14 hours writing dialogue in the end i 155 submissions the community voting 1960s show by the same name please don't 249 lines of dialogue i ended up using 5 minutes and the game will end at 8 [Music] [Music] [Music] [Music] [Music] a dating simulator a fading game it has to be dating so i a little hard to figure out but a lot of time thinking about a good way a lot of work went into all of this so a question they haven't seen before but ability to choose a dialog option it was about 30 minutes after ludwig announced about dating i asked a friend for help about so that the player knows to watch absolutely no idea what i was going to abstract sense rather than the literal accidentally going too far and revealing accomplishments and vacations there are added to a set of asked questions so additionally i didn't want the player to additionally i made a little custom additionally the font looks so icky and additionally the incorrect talk options aesthetic of the game further but it after a few hours of work after a long day of judging the final after digging around i found this after discussing my game idea with a after implementing the bad questions i after messing around in photoshop for a after play testing for a while i felt after the prototype ui was finished i ago aligned all that's left to do is all the all the dialogue we're gonna design the alright now is the part where i explain also finally cropped out and made images also i normalized the option box fill also whenever a question is asked it is always be what you talked about and the always running regardless of if she is amazing program called bfxr which is an amazing game and it deserves all the an image effect shader we run the shader and every winner deserved it and has compounding failure in the and i thought was a completely unique and judged and five of those ten would and left a comment about whatever and put those into unity the rain and that's because while testing the and the progress the player has made in and then i played the dialogue sounds and we came up with the dating game as a and white noise on top of each other and and you have to interact with her animated at a constant rate but that's animation now plays in the background animations ones that are always antithetical to game design so it's anything so the next task is to hold on anything while the characters are appearing outside of the window and are all there as well as the sound area i've worked a lot with dizzer art assets are in fact paint overs i'm art the girl portrait was a paint over as an index for the array of options as well as what you have talked about as you can see i expanded the options to as you have nothing to talk about and ask the girl questions she responds to asked question we send that question to asked questions are removed from the asked questions or things you've already asking and talking you first ask her asking questions and i realized that at this point the game was finished you attention in the game world when you're automated if you don't know what a game automatically and it moves with the background to the proper screens it's bad with the ui aesthetic basically the options manager holds on basically the portrait moves relative to basis for my new intro for videos which be a question and the second talk will be able to spam click input to mess be deemed winners and given two thousand because it's only wrong if it's already been land yet the master sets are used been talked about but i don't have that before before i talk about the results of the before so i sketched out some different being our color scheme since our belongs to the hobby set and the between two colors those two colors bit my final draft ui ended up looking boundaries to prevent the portrait from boys today we're gonna be participating bugs bunch of bad questions such as how much button the first extra texture was one can continue can talk until 8 o'clock can win you can lose properly the option change the texture of the object to the changing the texture back to normal class dependencies in place i also got a clicks on certain elements as well as color schemes completed we have the bare bones game complicated than i initially thought condition it's time we started making congratulations to super auto pets it's contains most of the really boring correct but how do i know which talking correct option if you try to talk corresponding sentence would be you like could have done more but i spent every could really come up with a strict creator to host my own game jam but credits intro so people can really currently the questions manager has six currently we have rain ambience but we cursor texture so i can say that i did cut content date just as flavor i decided that each date questions as well as avoid asking date questions i created a set of a dating simulator after thinking about it day so i did not get a lot done decided on trying to make a foddy and definition design and then changed the text to design i wanted to finish up the designing the main menu the tentative dialog box to be this big speech bubble dialog boxes and informs the state dialog manager has no job yet so i dialog manager which then fills out the dialogue dialogue getting distorted stuff dialogue option generation but it was dialogue options dialogue options will include slightly dialogue to the dialog manager so that did i ask this question this time or was didn't look stiff so i drew her with her different color schemes that you can different sets because it determines difficult as you remember information disable it there are also evergreen disables itself until the dialog manager displayed displayed to the screen and in that dither patterns and pixel art but this do foddy and games are kind of do you weigh doesn't match up then the player loses dollars don't see that in the game itself drew out what i wanted the ui to look dummy questions that are always used each failure of my game makes later effects before so i'm very familiar with either randomize or choose from manually element is disabled ended up making about 20 different color ended up with this as a final result entirely this night but i got it working essentially finished apart from specific essentially the animator holds onto even have a program to make it with every set of options will only have one every single knowledge keyword belongs every time but obviously i don't want everything up so the state manager eyebrows a bit and opened her mouth to eyes closed and i also raised her eyes disappearing intermittently her fading in nature but i like to think it fail conditions and the overall win failed the creepier the game would get fantasy xiv as well as a funny joke filling at the exact same time finalized i started on animating it so finally time for me to implement the finished up option generation such that finishes its job fix something that was bothering me with flags that you can enable and disable to flow implemented the art and animations foddy well or similar too games like for a good while i thought up a game for a longer period of time on commas for a total of for example if she says she likes music for filtering the keywords when for it i used some code someone else for something i've never made before and for the buttons and positioned them on for the disable texture i had the state for the most part as it is my favorite for the questions if you couldn't tell friend he suggested that the girl also from an existing successful game i from imagination from previous plays did she say she functionality in the same way as the functioning as the tutorial anyways so funny play on words and reference to the game developers come together to make a game for 10 days straight so it's hard game have criticized game jam i wanted to add a section about game last night i realized that the game game music i've never made music i have game over screen so i took the main menu game should end eventually i created a game so i thought having it raining game that i was very proud of in concept game within a set time limit according game works it starts with an asked gameplay games that were made by teams of four games which are games made by bennet generate noise so i layered brown pink generated from one keyword so to fix generating talking points the unknown generation is implemented and there's no get an additional line of dialogue get one of the two colors and nothing girl distorting or glitching out her girl is talking i set the talking flag girl talking and a sound for when the going on forever isn't that great the gonna animate the ui we're gonna make a gonna come up with a good game idea gonna do well it's simple really we're gonna program the game we're gonna write good game design got my game on stream but it was nice gross in between this shader allows us had 41 questions 104 total question had not done anything with the window in half of those things before but i mean hand-picked 10 of the submissions to be happening her blink for example is has been asked before and if it has the has been replaced with a leave button have a great rest of your day and i'll have no rain i went into photoshop and i helps information absorption her what her favorite band is and she here's what the prototype in unity looks here's what the sketch looked like and hobbies attributes media future goals horrific the game got so the more you hover texture how can i prevent the player from doing how do i even generate the first six how do i know when a player is asking or how do i know when a player should be how hard can it be how her right eye is one pixel above her i also made it so that the options i also wanted the girl to ask you i began day 2 by implementing the i didn't really know what to do with the i didn't want to just yoink and twist i edit it together in adobe premiere and i feel like it turned out really great i felt this would have really driven the i finished out the night by coming up i hand wrote custom inquiries for every i hate to break it to you guys but my i hope someday i am a large enough i imported these into unity and then i imported this into unity and now it i intermittently wobble to the base of i learned of the theme and had i like a lot i made a sound for the player talking a i only made in a few minutes the idea i painted over it for several hours i put in a little button in the top i put together the page for the game and i realized that i needed more of a plan i really really like is that it has many i spent the rest of the night reworking i submitted it to ludwig jam i think this improves the readability of i thought for a long time until i i unfortunately had to go to work this i wanted the dialogue animation to pause i wanted the girl to be animated so she i wanted there to be a little opening i wanted to have similar audio to games i wanted to have this in my own game as i was a little late to the party i was an honorable mention i was pretty happy about i went and looked for stock images of i'd really appreciate if you subscribed i'm finished idea how to do sound design ideas on paper and ended up with this if the keyword is making music then it if there is any real life equivalent to if you remember from the start i wanted if you want to play the game or look at implemented for when dialog is being implemented some intro dialogue on game implemented we can now generate six implementing the first fail state which imported it into unity which plays the imported these finished assets into in a living room while it's raining in ludwig jam hosted by ludwig and in my opinion in particular i really wanted the girl in real life we pause on punctuation so in terms of art i wanted there to be in terms of the mechanical framework in the bottom right in the end i'm very proud that my game in the game we're gonna animate that art in the top right we'll have the timer in total there was in which sometimes there are new include 8 instead of 6 since i thought 6 incorrect options and the known sets are incorrect options for example if you ask incorrect version of every single incorrect version of what you talked incorrect versions of what she told you indoors here's a quick clip of it informs the options manager which inspiration and i was about to give up instead of just winging it i sketched interactable we change the mouse cursor intermittently asks for your attention interrogation which many players of my into the game after the fact but i'd introduce the player to the game is added to the pool of potential is talking without any knowledge i spent is the first time i've done any real is used to determine a lot of what it last time it was this aspect of my it was an ambient art piece in which it was at this point that i formalized it was randomized on start but i wanted it's a memory game but with the dating it's audio day everybody it's basically just a bigger version of it's dialogue day everybody the last it's more like 28 successful actions it's more usable and reactive to the it's ui day everybody item which is like a knowledge keyword its luminance value as an interpolator jam is it's this event where a bunch of judging came around and jump king kwop getting over it pogo just like the background i found this just plays automatically when the game keyword is learned its incorrect version keywords the known sets which contain knowledge keyword which means there is knows if the game is waiting for input lastly i made a little frowny face for lastly i wanted a timer to stress the lastly when we hover over an learned from it this learned keyword is learned questions asked and what was learned that audacity has the ability to least until the game runs out of left i imported her into unity and like like and i made some quick assets in like it was obvious that the talking like phoenix wright and papers please like this i referenced world of horror like you're looking to the left and when liked music this run or was it last run likes music little typewriter animation effect looking like so looking out the window here's the code lose lot but the first 8 actions will be luminance is either zero or one we only luxury with the talking points i chose main game ui main menu a victory and a game over makes a game fawdy and or not as no one making music another example is the manager informs the options manager manager object enable and disable game manager that we learned that she likes manager when it is finished marketing i uploaded the game to itch.io mechanic mechanic has been chosen and asks the mechanics separated i plan to combine menu scene twice and switched the mimic talking with interest more horror elements i had this idea mouse just like the portrait so it stays mousing over the dialog options it's movie drive which belongs to the media moving on one aspect of world of horror music and now when we choose the talk must be made in order to win which is a my game's code in order to combine the my own personal taste and experiences name was seed of sacrifice as a needed gameplay variants i wanted each needed to implement the conversational needed to write a system that draws new question before talking about what next i started thinking about potential nice tools for animators and it didn't no idea how to make music and i don't no words just depressing vibes i still noise ambience combined with the sounds noise-based ambient background noise i nonetheless the way this all worked was not confident i could draw an appealing not how a real conversation flow works not skilled enough yet to draw stuff now another 104 lines of dialogue when a now the game can go on forever or at now the problem is that i haven't done number box it was and then that is o'clock objects accordingly to inform the player of mine terminus and i think it fits of questions that i randomly sample from of rain outside but muffled by the of responses to get what she says in on it to do something on our final render before it is on the day the game jam began i woke up on the option box it determines which one correct option i didn't finish it one that i really liked one then i shoved it into photoshop and only known keywords and the unknown sets onmouse exit which we can use for option is correct and if the number option is correct questions are easy option these keywords are separated into option was the correct one option we can talk to her about why she options options but as you know we only have the options manager checks if the question options the talk button and the leave options to talk about what you know with or already talked about one of which is or are you an alcoholic or ask a question or thunder or whatever other stuff like that other than using adobe audition to otherwise you lose i wasn't entirely our assets are black and white out a class diagram which ended up out for that trickery that's what i call outside outside would be perfect combined with a over it when this function is called we passed to the options manager and used people have asked me to add this stuff perfect for creating short and simple period lasted for three days during that periods and other punctuation photoshop to use for the prototype picking what to say or choosing to talk pixel art planning phase if you don't like that played the click sound when you click on player clicks on something player how to actually win the game i player loses now the player can ask player out playthroughs of the same session more playthroughs she will say different please skip ahead to the next day point of the game the girl herself i was points were being automatically pool and added to the already asked pool portrait whatsoever especially in pixel positioned her properly on the screen i presentation my work stood up there with presents them to the player this is pretty lazy but it works pretty simple honestly it's just a set prototype images provides a function called onmouseover put together a two frame rain animation query her response table so that you can question question she also gives you a second question to have multiple possible questions questions and responses and further questions and sometimes there are questions and then you talk to her about questions but it doesn't actually mean questions class or the knowledge class questions herself so it was more of a quite dubious if i do say so myself quite well random questions from a pool and rate so that all the options finish rather begin work on new projects and really hard to come up with a good idea reference to the trial from final reflect victory and game over related to it additionally for much remembered a vision i had a few years respective dialog boxes and informs the respectively then i duplicated the main response response table and out comes her response to the question and what you responses and an additional 104 responses for the girl but that's for responses i proceeded to spend the next responses so that in different responses to those respective keywords restaurant backgrounds and i found this right and when clicked it cycles through save this idea for a future game says always the incorrect version of schemes the last thing i did today was screen and finally we're gonna make sure screen will be taken up by all the scrolling my steam library for see you next time sense separate her eyes from her face and set the categories i initially wrote are set the corresponding sentence would be sets are used for generating random sets which contain all the respective several people didn't think my game was shader we sample the render and we use she looks a little bit like ludwig with show up to confuse the player since it's similar to the ask question set so if simulator aesthetic since the options manager knows the single knowledge keyword which means sixth grade writing class slightly higher pitched version for the slowly fill with each new talk to slowly so i imported a personal favorite font so now that we have a bunch of questions so this game is kind of like an ace roll so with the bare bones knowledge system sold on this idea as a game but it was something special as by this point i was very specialty i've never designed a ui spent the rest of the day implementing splice clips together start where the girl tells you that you starts and loops pretty simple state manager that it is finished and still missing one piece which is bad stock image of a straight-faced girl and streamed stuck you know the vibes successful action will increment time by such as keeping track of knowledge sue me super auto pets supposed to cause information overload take me long at all to learn how it talked about talked about but there's still always talking talking and asking into one big mechanic talking and asking mechanics whenever talking options five of which are random talking or angry this required me to talking points or it could be already talking to each other terms of time and the majority of the text box to visualize the time in the texture is one to visualize that the thankfully it's over now and i can rest that i am very vain that i need to write a whole lot of that is displayed when you hover over that is ever present that it would work with the new ui frame that otto and the other ludwig mods that the dialogue in general felt very that the game actually works that's the portrait parallax i wanted the background art of the girl portrait the characters can converse and the game the classes and then got the overall the code please see the github link in the default windows cursor with the ui the description the dialog as it is being animated and the dialog manager which populates the the dialogue and i think that also made the dialogue currently the dialogue gets the existence of the event on stream so the final game to be like this so i the first option of the game will always the game the game can continue the game is finished for real yay the game look better which is my the game mechanics the game will have the game much harder which is great the game was still lacking a victory and the girl class and query her hash table the girl to have a quick time event but the horror elements would be like the the judging involved four main criteria the main menu design isn't anything the most as i had at least some idea how the most the day i draw the main focal the mouse with some damping and the next thing i did today was learn how the old prototype sketch had four input the option manager hold on to which the options manager sends this info to the options manager tells the knowledge the player talks random number generator the player to have some control over it the problem with that though is the the same question twice the talk the screen as well so i didn't have to the state manager handles user input and the ui complete i also got to work on the ui element and the other extra the very complicated knowledge system the void the way this works is that unity the white noise to simulate heavy wind theme presentation originality and then it does several game state updates then it sends the conversational then the keyword is music then used again later to once again there was a lot of debate over what there was plenty of amazing submissions there's another 104 lines of dialogue in these bad questions will intermittently they have to determine if the question things to the same question this means this dialogue is then added to a set this didn't make it into the final game this had no impact on whether or not i this i ditched my entire system this is a mild success for me but i this is always but with a w this little intro ended up becoming the this means that 36 successful actions this question queries the girl's this was the day i was actually dreading this whole concept is way more three copies of these sets the master time i peaked at number two in most time i wrote dialogue was probably in my time that it gets on ludwig's stream tired and exhausted i imported it into to a category each category is its own to a given theme you may ask yourself to all of the current options and then to color our game any way we want and i to do pixel art but i have absolutely no to do the simple solution which is have to explain how the dialogue system in my to generate options accordingly and then to implement the first system which is to inform the player that you can click to say to true and she starts talking until i to what you learned from the question today i realized i forgot to inform the today started off with being unhappy today was the day that i was dreading tomorrow top right i also added a box for the transition between animations when the twist on the genre the day of the two extra textures for the dialog two main mechanics two now talking and asking which will go two-way conversation and less of an uh oh we've got a disclaimer today ui functionality such as detecting mouse ui we're gonna draw art for everything under the hood that would control how understand that i made this game and unique and i had fun plans for the art i unity and i repositioned everything so unity and implemented the ui unity animation works i won't bog you unity provides another function called unnamed characters are lounging around unnatural and mechanical until i got this together until i saw until then i've got to go and i hope you use these very bad looking talk or ask used for generating the correct talking user's actions this was done by creating verdict and winner of the game gym video on application start visual feature i've been waiting on and voted and number one most popular which waking moment of my life working on the wanted to do something unique i was was was my game was very unforgiving it was was one of a kind in both concept and was really [\u00a0__\u00a0] easy with the two was to capture the vibe of restaurant was too easy waveform sounds we send that question in response to the we start with an empty camera script and we're gonna brainstorm the mechanics we're gonna make sounds and music we're we're gonna prototype the game we're well and it's very easy to do since all were too obvious so i created a custom what is interactable and what is not what she told you what you ask and you need to remember what you like about drive what you've talked about essentially what's the theme well it's foddy and what's the time limit you may ask it's when a player chooses a question the when an option has been chosen the state when asking questions you must avoid bad when talking or asking the state manager when the girl gives her response to a when the player loses when the state manager detects a click when the text was being animated where each failure incremented a counter where you're on a date and you need to which contain everything that hasn't which executes when the mouse hovers which sentence is generated for example which was chosen and validates that the while that looks kind of creepy here you wholeheartedly i can't help but feel i will end the date or not window so i left it black for now i with a name for the game as well as with a plan in place i stubbed out all with her animations finished it was with my color scheme system i liked that with the main mechanic of the game with the specifics but unity has really with this change i was much happier with with this the main game is essentially without knowing something new you lose woohoo works would have liked to be top 10. would have taken way more time written we need to write all of the wrote and modified it to suit my needs you you may also notice that the ask button you mouse to the right it's like you're you talk about the same thing twice you you're presented with which could be a you've learned it could be incorrect your mouse pointer to represent your"
  },
  {
    "video_id": "E9-LRRDVmo8",
    "title": "Making an Inktober Shader",
    "publish_date": "2021-10-30T00:00:02Z",
    "comment_count": 0,
    "transcript_text": "2077 and i think it looks pretty good [Music] a texture i'm a busy boy so i didn't all that's left is to color it i went an edge such as a shift from black to and and a low threshold value if the and five is edge tracking by hysteresis and ink texture i took an off-white and not an implementation of someone and optimal thresholds are kind of and that's it we now have an image with and there's a lot of really complicated and use blue noise dithering blue noise and you're right it's very obvious for any noise anyways i've got something special anyways thank you guys for watching i applying this to our example image makes are really simple we're going to average of its neighbors so that it background this is a simple pass i just basically it's like equally distributed be looking at how i made this picture becomes much lower resolution and in my between two pixels exceeded a given blur the image to smooth it and remove but the next thing i wanted to do with came across one known as the canny edge color for the paper and i applied a combine these two buffers and then the comes out also check out my twitter for comments completely ignore the first pass because complicated face and then erases all of dark warmer color darker edges have thicker lines with detector canny edge detection is a five diagrams but i'm going to keep it simple didn't mention earlier so i'll just do is remove the blur pass and thin the down and makes it look like this which i edge and this didn't work at all or at edge detection is a very difficult task edge pixels from before and it removes edges of an image and separate them so effect turned out it is written as a else's work i kind of needed to have a every weak edge pixel that is not everything except the detected edges finding the image edges finding the intensity gradient of an first pass is edge detection the second fixing the lines is easy all we have to for both video games and as a general fourth pass will color it all frequency components and no concentrated functionally enlarges the noise as it game renders don't have the problem that general idea of how i wanted it to work generating blue noise so i used one of gotta go now and i hope i see you next had every pixel become a weighted have a great rest of your day and i'll heavily with the stippling the lines are here is normal uv coordinates for hey everyone and welcome to a new video high change in intensity there could be high threshold then it is marked as a hysteresis takes the weak and strong i didn't want to blur my images as video i want to modify the line width based on image and this would ideally make the image effect to show you how it would image is a really fancy way of saying image look like an ink drawing that was implementation is a 4 pass effect implementation so i personally used the in the context of computer graphics in the context of image effects and you ink instead is this an edge or not and intensity intensity of a pixel is higher than the intensity of an image where there is a interesting internet into photoshop and i made a simple paper isn't but image effects operate on a per it and then we get a perfect circle it is trying to solve so my it kind of reminds me of that scene from it look like so the white areas are it looks like least not well enough to be actually lines down a bit i actually had a pass little bit of noise to it and i did the look in a video game i applied it to one look into stippling i'm not going to look like this with an inktober inspired looks like the ink is bleeding into the lot of really cool intricate ways to lower resolution this can be achieved by luminance is above that noise value then magnitude compared to its neighbors and magnitude of these two values the maintains the strong edge lines make this very complicated but there's a makes renders now look like this which i makes the lines look much more matrices around a pixel then taking the matrices you use depend on the may ask yourself acerola what do you mean the edge is right there multiplied by 0.5 the stipple effect multiplying the uv coordinates of the need to zoom all the way in next i want to make the stippling a noise and it visually looks like this as non-trivial task now we can combine our two effects drum of my old screenshots from cyberpunk okay just kidding we'll fix the effect once again even looking at just these 6 opinion it looks a bit more organic or a not so new video if you're watching overall i'm pretty happy with how this own little edge detector using contrast pass effect which are as follows one we pass is stippling the third pass will pixel pixel basis so to get a real judgment of pixel by a decimal so that when it pixels the edge is obvious but this is planned for the next video so be sure to please let me know what you think in the post-processing shader in unity post-processing shader so it can be used precisely why edge detection is a project updates but i've gotta go now so rarely what images actually look like refers to any noise with a few low remove that too removed obviously it's not perfect and roll please same thing for the ink but with a really sample the blue noise and then we sample samples the blue noise texture it sampling and here is uv coordinates sampling these textures accordingly see you next time since this effect is of my own creation sketched and then shaded to illustrate slightly blurs the whole image but so so brighter edges have thinner lines and so with a plan figured out let's look at sobel operator which is the industry spikes in energy spongebob where he draws like a really standard stimple images with stuff like voronoi strong edge if the intensity is between subscribe so you know when that video surrounded by at least one strong edge that is parameterized by the programmer that it is calculating the change in that the image looks like a sketch that was thickening the lines that i that's a hard question to answer and the blur i put on the lines contrasts the edges was blur them a bit so that it the final pass which is edge tracking by the image three is magnitude the intensity of a pixel is lower than the largest or equivalent gradient the low threshold it's removed entirely the luminance of the image and if the the luminance of the image at that point the many free blue noise textures on the the next pass is a double thresholding the next pass which is magnitude the plan here was to try and detect the the two values it is a weak edge and if the way the stippling works is that we then i wanted to layer these edges on there's one last change i want to make think actually looks really cool think gives off the vibe of paper and this an individual shader passes the this change to the effect i think it this in the future today we're going to this thins a lot of the potential edges threshold then i would say that's an thresholding essentially if the contrast thresholding four is double thresholding thresholding keeps every pixel that has tiles across the image to demonstrate time to play around with it a bit the way it too dense too thick and the stippling feels way top of a stippled render of the original two we find the intensity gradient of unique to individual images so you have us as humans what is an edge and what useful so i started researching real want to write my own script for we keep it otherwise we discard it and what an edge looks like to a computer we what if the pixels looked like this when applied to the image it looks like when i was starting i tried to make my where there is a high change in which i came up with while i was at work white this works by convolving two with our linebuffer complete we can now with that the effect is complete i think words here but i promise the concepts works is we have a high threshold value world edge detection algorithms and i you"
  },
  {
    "video_id": "EFt_lLVDeRo",
    "title": "Simple Fog In Unity",
    "publish_date": "2022-01-08T01:00:06Z",
    "comment_count": 0,
    "transcript_text": "1999 2 to the negative depth times density [Music] a negative exponent this formula is nice access to it in the camera depth texture achieve a lot more in terms of realism all right all right hold your horses pal and and aesthetic appeal but i unfortunately and approach zero this method of fog and subtracting the world position of and the cube apply the fog image effect and then dividing it by the end minus and then render our grass on top of it another use for fog is to hide poppins application is the exact same it's just at this point it's the same as the atmospheric scattering modern techniques because it has less fog at close range because of it take for instance this become entirely opaque exponential boat that is closer to the camera building in the distance for some reason but it gets stronger much faster and by taking the camera's world position calculation is a bit more realistic than calculation you use we use it as an cannot see a few feet in front of your claustrophobic fog that shrouds the town clipping plane's distance to get the cloud a dense collection of water color of our render and the fog color so compute a fog factor there's a lot of convey distance far away objects become cool it is not feasible computationally cringe density which makes the value start at 1 depth texture if they have a shadow cast depth times density before you use it as distance then we calculate the fog droplets due to its lack of a shadow caster pass due to unfortunate circumstance i am effect only apply to opaque geometry exactly before we try and recreate it exponential squared fog linear fog is face with this new knowledge we can factor all the same and our grass has faded out and actually feel far away focusing on the two most basic fog is something that exists in the real fog now from the camera game object should become more and more gooch shading video unity keeps track of grass manually in its fragment shader grass shader the fps of our project great rest of your day and i'll see you having a foggy scene in your game fog is hey everybody and welcome to a new video how we get depth that is a bit different i could use fog so that you can't see i have mentioned before in my what is iconic aspect of this series other than if you remember from my first grass implement as a post-processing effect as implement there's a lot of different in the next video infer some things about our fog effect instead let's simplify it much more a interpolator between the original pixel isn't actually blocking the fog like it it doesn't work it is to see the fog from silent hill is it's exponential the general formula is know nothing about these techniques so linear fog exponential fog and lot i mean generally three you've got magnitude of this vector to get the view more light gets scattered and the harder most commonly used as an image effect to much grass there is to temporarily solve not wholly unrealistic it is very obscured is dependent on the density of obscured the farther it is from your obviously we are not going to simulate odd angles you can see that the grass of me instead lately i've been playing opaque regardless of what fog factor options here for fog factors and by a or pass in their shader and our grass position we can calculate the our wonderful fog in unity possible for fog to be so dense that you prevent us from seeing clearly through previous formula but you square the proper view distance pyramid head is the suffocating rays even though that would be really reach zero so the fog will become fully reaches zero so the fog will never real water droplets to scatter light remove grass that was too far away from represents the distance of the pixel same as 1 over 2 to the depth times should be fairly easy to implement right should if we visualize our depth texture silent hill since i never had the chance since the exponent is negative it is the so please accept this cardboard cutout so the image effect fog doesn't work for so this means a similar fog effect so what's the point well other than just something called a camera depth texture squared fog is well i think you get it stock photo of a lady pointing at a subtracting it by the depth of the pixel taking the end point of the fog techniques for fog but today we'll be the building is not as clear as this the camera in order to easily hide that the first silent hill game came out in the fog thankfully this is trivial to the good news is that the method of fog the grass shader because we do not have the grass that is no longer there the linear fog but it also never fully the more water droplets there are the the start exponential fog is well the tip of the iceberg when it comes to them then multiply them by the far these water droplets scatter light and this basic fog effect is kind of just this is because unity is extremely this issue we're going to have our image this means we need to apply fog to the to play through the games the most unable to record myself for this video unfortunately if i added that to my unity only writes objects to the camera unity will now render the terrain plane unlike exponential fog does actually until i learn those i hope you have a video to improve performance i would view the rate at which it becomes visually fog is essentially a low-lying we see that the grass is non-existent we take these depth values linearize well it actually does work what doesn't well it's linear you calculate it by where each pixel of that texture with our effect completed we can now see with this view distance we can now work is our grass if you look at it at world so we should learn what it is would quickly approach zero due to how yeah it actually is pretty easy to"
  },
  {
    "video_id": "HMmmBDRy-jE",
    "title": "I Tried Sorting Pixels",
    "publish_date": "2023-03-26T14:38:01Z",
    "comment_count": 0,
    "transcript_text": "14. upon first inspection you can see 16-bit buffer one 32-bit buffer and Bloom softens the image and also makes CPU sorting algorithm might make many Endeavors if you would like to have a GPU which is good and that's what we High number so that it never gets picked I can to bring up the performance of I expect to be laid off shortly after I'll be referring to these uninterrupted I've been wondering what would it look Mask makes it so pixels that are too Niche that no one can say for certain Pixel of the texture which normally Shader optimization to make this more Sorting order to get different visuals Source buffer the sheer amount of memory Target ultimately the single threaded Tonic merge sort does the exact same Tonic merge sort takes around two Tree and how my videos evolve as usual a [Music] a game with this effect on but it sure a number of threads and we as the a random array of 16 numbers well since a stroller we want to sort an image not a time it would be much faster to rent a acting like a mask for our dispatched action is to figure out where the spans actually a second mask since the CPU again here with a very strict palette again we repeat this process for every algorithm is already about as good as it algorithm the parallel by Tonic merge algorithm the result is obviously an algorithm we're gonna have to do algorithms are always designed such that algorithms involve shifting lots of algorithms to image data the technique all so clearly our bottleneck is all sounds really bad so far but don't already puts us off to a bad start gpus amount of work being divided up on the amount of work every time no matter what and I'll see you next time I really did and each horizontal line is an and swapping them if needed for example animate the offsets we apply a dither to anything in real time anymore our pixel anyways the reason I made this effect in apply the kuahara filter to stylize and are and how many threads are in each are created equal the amount of memory are really bad at conversely CPUs are are very very fast but this doesn't mean aren't very good at as well as how around with in the description in the as one of three kinds of bottlenecks you as well right now I am sorting by asendorf which they implemented in at all the reason I'm doing this is at making images very edgy and so I be done this texture will control that bearable to the average viewer please because compute shaders have a secret because it helps animate the pixel sort between the houses to pick up one box at big thank you to all of my current big truck and put all of the boxes in bit black pixel we then store the length of bottlenecks gpus have limited memory and brain is trained such that the moment brainstorming this solution is coming bright or too dark are left alone and brings our absolute worst case by 800 our render currently has a decent by modifying the pixels randomly then we by unity this isn't that much memory at calculate a new value like luminance Hue called group shared memory also referred can be categorized as one of four kinds can do some stylistic HDR color can get so we'll have to look elsewhere can use the color information to can't determine how much work needs to cat Shader performance problems can be categorized as one of two kinds of check out my Twitter chromatic aberration but it's not very color at all just the value we sort by color correct and tone map apply film color palette and the pixel sort really coloring in the span we want the thread colors are made up of three numbers a column of our image as an array of comparing neighboring indices if the completely white mask spans will be the complex decision making two things gpus considered good enough the span length context dependent and we can reverse the contiguous parts of the Mask this sounds contrast mask and then sort the contrast mask lives on the GPU the CPU contrast with fleshy Reds and convert this to a Shader effect to apply converting our thread ID into a color correction and tone map the result cpu's job to tell tell the GPU what to credited to generative artist Kim deduce the start and end points of each deep Rabbit Hole of sorting algorithm desaturated blues makes for an edgy different informed decisions to reduce dispatch is not finished until all the disqualify our effect from being real do and how much to do it but since the do our pixel sort based on Hue I really do work in groups A comput-shader does look cool it's particularly great doesn't look very good as a visual doing single threaded sorting on the GPU down to nearly 90 percent from our drastically decrease our performance so dumbest yet fastest GPU sorting duplicate work of converting the colors each column of the Mask each thread will each frame which ends up looking a effect by randomly offsetting the spans effect fast enough for real time now I effect it has novelty but it turns our efficient real-time pixel sorting Shader efficient solution to this problem element in the span until we have a elsewhere Shader code is often what we end the real-time pixel sorter is a bit enjoy even more clips of my cat Shader enough for games so we're going to have even remotely close to our performance everything in between will get sorted excellent case study for what gpus execution time is gay kept by the time existing pixel sorters doing to fix this exists even though it feels like there expensive but not all texture samples explain the process of intermediate exponential nature of our algorithm even favorite Hue we can easily animate the finished now we can do the fun art part fired from my job after a long period of first White pixel then it takes note of first we apply xcgtao for better Shadows fix this by adding random offset for games doesn't currently exist before for improvements this is usually the for post-processing effects are for sorting that entire span effectively for us we dispatch one thread for every from one house to another but these game is over and you can't render gameplay anyways this has made an generally two milliseconds Max and get to vote on the next video topic if given row of pixels nor does it know good enough for a video game photo mode grain not for aesthetic appeal but graphics programming equivalent of great at these in other words gpus are green blue saturation or my personal group our pixel sorter is dispatching group to finish and so our Shader groups and they all finish at roughly groups complete their work GPU half the number of elements we want to happens to line up with a pixel in the has no idea how many spans are in a hello everyone for the past few months hope you have a great rest of your day horizontal sorting looks better is horizontal sorting sort by Hue and then house is global memory and the big truck houses are on opposite sides of the Town how exciting but let's look at the if I told you that this texture is if we instead shift our perspective and if your Shader is going to cost more image into an unintelligible mush of image is usually referred to as pixel image on my 1660 which isn't great but image with sorted pixels the parallel by immediately drop out and not do any work important memory optimizations are for in a major way if we take a look at our in another Shader pass before the pixel in group troops these groups consist of in the end these steps will always in the pixel it starts at we can easily in this context it's okay because 99.9 increase the image detail with sharpness increases that Graphics programmers have incrementing a counter until it finds a index of the minimum luminance value we individual thread comparing two numbers initial performance in the worst case instructions expand to sort any array as intervals to the spans to reduce the into sort values and we reduce the is making N squared texture samples of is often the first non-trivial problem is sorting a span of 20 pixels no matter is the group shared memory this it looks good it looks really good it so let's switch over to Final Fantasy it takes to sort the longest Span in the it's kind of hard to find images that it's not possible to optimally divide up it's pretty good for GPU sorting I'm iterate over the pixels and find the its overall workload the parallel by itself consider the following set of 16 just get to the point already show us just nuke the building keep walking along the column increase know what you're about to ask Mr Rolla lastly the 64-bit Source buffer provided learn a sorting algorithm sorting data legitimate use case in fact it's so like how dithering looks so I used it like if you applied a sorting algorithm like those cat clips limit is very obvious though so we can lines with white pixels in the mask that little like a VHS effect then we can local memory saves the day we can long as its length is a power of two but look chat and this is my problem with looking set of instructions each lot left to check I'm now going to luminance but we can also sort by red luminance of our pixel is within the made if you want to see more be sure to make this more bearable to the average make use of our parallel sorting mask at this point I've done everything maybe do another post-processing effect memory around as well as requiring memory bandwidth bottleneck memory bandwidth by 87.5 percent this memory our pixel sorter is making N memory than you have budget for then the mentioned earlier that compute shaders metaphor for being born I'm sure this mild increases in resolution will millisecond ideal Target can still be milliseconds to sort a 1024 by 1024 milliseconds which would instantly more impressive if it actually got us my own sorting algorithm for this which need to be sorted as spans ideally we new house making it much faster to noticeable here's a few more examples I now is compromise on visual quality by nuclear bombs number in the greater index is less than numbers and execute our sorting numbers then it becomes much easier to numbers to parallel by Tonic merge sort obtain those boxes again for us the old obviously this isn't even close to fast of a failure I truly believe that no of applying a sorting algorithm to an of bottlenecks compute shaders do work of form now we have to do the Sorting of local memory instead to visualize how of the parallel by Tonic merge sort of this buffer instead we eliminate the of work which also sounds like a on until we find another white pixel one final color correct and sharpen the one group of one thread for every single optimization Shader performance problems optimization gave us a 50 speed increase optimization reduced our render time or saturation then we interpret each order what initially seems like a simple our GPU something we refer to as a our group shared memory before we do the our most expensive extra the unity output to accentuate the dither the high patrons anyways that's all from me I percent of the groups are going to perception makes it difficult to perfect for our GPU that can't think for performance call the fire department we performance problems can be categorized performance to around 8.5 milliseconds pixel in the output buffer and continue pixel of the image and whichever thread pixel of the span that it matched up pixel sort works like so apply a pixels and all form is lost so what are pixels lastly we apply some tasteful point at which most non-gpu programmers pre-calculate our sorting value into it pre-load all of that Global memory into probably think of them like photographs problems would be applied to images but process of basic Shader optimization to processing as a CPU algorithm Kim's programmer control how many groups there programmers but our pixel sorting putting a hard limit on span lengths range of our two thresholds we color it rearranging it such that it's assorted red green and blue value we need to reduce that to a single value for our reduce the color palette and then we can reduce the size of the requested buffer releasing this video I ended up writing required for our algorithm but we can research that some programmers never research to reference because it has no result in a sorted array in the pattern return from sorting algorithms date back right we should have a working pixel same length as the image meaning one same memory over and over again which say in what I do next all of my patrons sells the horror aesthetic allowing for setting the limit to something like 200 should be but I think my solution is since the length of the span is stored since we want to make a real-time pixel since you'd never use this effect for slot in the sorted buffer and we replace slower this leads us to the world's so much and that's a great question I some crazy face renders as you visual some of the first documents on the topic something more glitchy we swapped a something that will probably get me sort by one of the three values or we sort for each Span in The Mask but sort occurs if we do N squared samples sort that way we do N squared requests sort then we follow this very simple sort what makes it so dumb well while a sorted output buffer if everything goes sorter Shader sorter is using one 8-bit buffer one sorting Shader we need to research GPU sorting a span of 100 pixels and another sorting algorithm this means we could sorting algorithms unfortunately this sorting is just too slow and due to the sorting the entire image legalize sorting this concept isn't new but it's sorting we don't actually care about the sounds like a problem this is where span length texture will be responsible span with minimal memory costs but what squared Global memory requests of the start and end we dispatch one thread for start mixing it with other effects we still do more I'm now going to explain still wasn't so bad thankfully we can stop trying to optimize but there's a store that pixel at the first available straight from my brain the first plan of stupid faster while CPUs are smarter superpower that no other Shader has sure you've noticed though that this task quickly turns into an endlessly technically ask the GPU to give the mask texture we are requesting from Global that before driving it back over to the that beginner programmers are presented that there's no way you could ever play that's being requested is heavily taxing that's for 1080p while our render is 800 the GPU this sound plays since we can't the Span in the position of the first the first place was to play a game with the first step involves each thread the following stylized render pipeline the game look kind of foggy lastly we do the most popular use of pixel sorting is the number in the Lesser index we swap the numbers the original value with an arbitrarily the performance of your shaders I hope the pixel sorter the pixel's position the thread will the process of advanced Shader the same time but as I've demonstrated the thread will iterate through each the two can take upwards of 40 the work of our pixel sorter if we have then do our pixel sort if we want to do these are the kinds of performance they're fast at everything most sorting think of first to optimize as think of images as just a bunch of this Shader is freely available to play this array we dispatch threads equal to this guy's videos like he wastes so much this is faster imagine you are moving this way the image maintains some sense those long spans and so all we can do thread per row will be responsible for threads we can easily visualize this by threshold and a high threshold if the throwing a massive mound of at the time in fact every Graphics programmer's time on history that no one cares about to 1951 was Betty holberton authoring to a video game to as local memory when we sample a to optimize I'm now going to explain the to sort the pixels yeah this means we're to the CPU but transferring data between to try when it comes to making the to video games to make a contrast mask tried to take that to the extreme with two pixel sorting groups one group is ultimately we only have one thing left understand how we can apply common unfortunately the number of samples are unfortunately we can't do that it's the uniformity our real-time pixel sorter is unique color along the way this is the used and as far as I'm aware an vertical line is an index of the array very Niche and doesn't have any academic very simple so all we have to do is viewer please enjoy these clips of my visualize how traditional programming walk along the mask until it finds its wall and whatever sticks has to do a lot want but consider the case of a way more than you think our pixel sorter we are requesting matters and it matters we can create a new 8-bit buffer and we can sort pixels though we need to we declare two thresholds a low wet dreams about but it would be a lot what we will have to wait for the first whatever I'll just skip ahead a little when or where the technique was first when you think of computer images you where those spans begin and end we could whether or not vertical sorting or which are pretty much immutable this which while not even close to our 2 which would feel a lot better if it while you could drive back and forth white otherwise we color it black The why why do we care about the worst case will often hear that texture sampling is with filling in each pixel with its with it involves taking data and work is equally divided across the work well with the pixel sorter but when works like so the threat is going to worry it's about to get worse instead of worse for reference performance targets would be an extremely terrible idea but would dispatch a parallel by Tonic merge yeah this is pretty bad and it gets even you all get to control the channel Tech you can apply this knowledge in your own you think about reading data back from you'd like to see me work on water or zoom in to accentuate the glitched"
  },
  {
    "video_id": "HlWDlmeecg8",
    "title": "How Color Blind People See Games",
    "publish_date": "2022-05-28T21:33:59Z",
    "comment_count": 0,
    "transcript_text": "10 and take the floor to get the index a great rest of your day and i'll see a small shift means slight about one day to make this video so if affects the red green color opponent all published their paper a allows colorblind players to allows us to see green and lastly the s and at this point it's still the only and enemies have red health bars if a and is what allows us to see blue the and then we take the security value we anomaly is the malfunction of the s cone as i know there's no real statistic for as you can see the l and m cones are at a practical example in league of bars to bright yellow when enabled this based on the two-stage theory of color be hard for me to visualize it for you i below the shader for color blindness is blends of color such as yellow and blindness blindness and isn't as disabling as the blindness deuter anomaly is the blindness matrix but we make sure that blue and red minus green this second blues being pushed toward green and brightness machado's colorblindness brightness the second type of color but what about color blindness color appears with the l cone making up color blindness then about 10.4 million color blindness they are in the colorblind from this but i hope you have colorblindness but a large shift will colorblindness in their game design so colorblindness is present in about one colorblindness to see why colorblind combined into their color opponents the common present in about seven percent of completely absent completely overlapping with another computed with increasing severity in cone doesn't actually do all that much cone if the l cone is entirely missing cone is sensitive to short wavelengths cones cones that react to these waves of light contributes the most to perceived danganronpa 2. the monitor that you are darker than others since the l cone description as usual thanks for watching details the paper is in the description difference in value making it pretty differentiate allies from enemies based difficult to tell if a player is an disability that affects around 10 of the don't get an index out of bounds error due to genetic mutation so the reds that earlier one step further the output of easily overlook accommodating for ended up using their pre-computed enemy health bars with only a mile enemy or not at a glance now league of everyone sorry if you found out you're exclusively responsible for how bright a eyeballs and let's say hypothetically for the sake of the argument that you for your vision tridenopia results in fractional part to use as the function where we input a wavelength and get the index of the second color given cone and shifting it left or right good paper on the subject their model is have it also see colors as a little bit health bars now look really similar to hello everyone colorblindness is a how much a cone affects a given output i'd like to show off more examples i had if the s cone is missing it's called in this video we'll be simulating in your retina are special cells called interpolation value between the two into our shader shell them into an array is complete color blindness we are is missing it's called deuteronopia this is quite a lot thankfully league of is sensitive to longer wavelengths and is sensitive to medium wavelengths and is what allows us to see red the m cone it because they didn't provide the it tried anomaly is blue yellow color it's called protonopia this form of kind of colorblindness is the most knowing how we see color is cool and all legends allies have green health bars legends averages 130 million monthly legends provides a colorblind mode in less experienced game developers might let's say hypothetically that you had malfunction of the m cone if the m cone matrices for my demonstrations and matrices lastly we multiply this matrix model is pretty simple conceptually at modes are a necessary part of any game much the exact same as protonopia but multiply it by 10 and take the floor to obviously they do a little bit more math of color blindness each matrix is of red green color blindness since it of the first colorblindness matrix then of them have some form of red green on a severity value from zero to one on brightness instead of hue as much as orange one fun fact is that these other two forms of blindness since the s output how sensitive that cone is to outputted combinations are how bright percent of the population and is a form physiologically based model for player had deuteronopia then the game players and if we assume eight percent players will be at a disadvantage which playing on is emitting waves of light population which makes it quite common pretty simple machado's model is based protonomily is the malfunction of the l protonopia is unique in that those who provided with ten matrices for each type research on simulating color blindness result in that cone sensitivity function secondly we multiply our original sensitivities is why we are able to see sensitivities of these cones are modeled sensitivities vary from person to person sensitivity functions they used so it'd severity value by 10 and take the shader if you're interested in the math simulation of color vision deficiency sixty percent of that perceived stage is important because it informs us steps of 0.1 we import these matrices taking the sensitivity function of a than that but i'm not going to explain that enter the retina of your eyeballs that wavelength the overlapping of these the appearance of video games let's look the color appears to us yellow minus the first type of color blindness the ground floor all they are doing is the l m and s cones are linearly the last type of color blindness tried the options which changes ally health the population deuteronopia is pretty the reds that others around you see now there are three types of cones the lcone these values don't exceed 10 so that we tridenopia and it's so rare that as far understand how colorblindness affects vision which takes our model from want for example 0.46 we multiply it by was lacking until 2009 when machado at we add 0.1 to the severity value and were playing your favorite game where zero is no color blindness and one which is the same as if the cone was with deuteronopia still have their l with our color to simulate the color with something called a sensitivity without the dimming effect since those would look something like this ally yellows looking pinkish to better you next time you see might be slightly different from you'd like to use my shaders to see how your own games look as someone with"
  },
  {
    "video_id": "IMiiUEG-sLQ",
    "title": "Remaking ELDEN RING's Eternal City Stars",
    "publish_date": "2022-04-02T00:00:03Z",
    "comment_count": 0,
    "transcript_text": null
  },
  {
    "video_id": "KkOkx0FiHDA",
    "title": "The Secret Behind Photorealistic And Stylized Graphics",
    "publish_date": "2024-05-28T13:33:20Z",
    "comment_count": 0,
    "transcript_text": "45\u00b0 to the left of the normal Vector so AA you said this version doesn't have Beckman and ggx with ggx being most Beckman distribution have a similar Peak Beckman if you recall from earlier the Behavior such as transmission of light Behavior underneath the umbrella term Breaks the Rules and fails to solve the Burley known as the Burly diffuse or the Direction This is the fundamental Direction aligns with the ideal Direction but if we wanted to get the Disney brdf is subsurface scattering but Disney brdf provides a secondary diffuse Disney brdf which gives us some simple Disney chose to use ggx for their Disney diffuse a solution to the Disney diffuse and the subsurface Disney diffuse the Disney diffuse is an Disney's and dreamworks' stylized Disney's brdf such as the guidelines for Disney's shading model is the same math Factor let's start with the distribution Fel only uses the angle between the Fong lighting model of the past is not a Fong reflection model and was one of the Graphics anymore but just remember that Graphics this is what connects it all Helix dusk Lux and after sleeping on it Helix mattress I haven't woken up sweaty I'll do that for consistency across I'm haunted by terrible nightmares and James kajia introduced a general Metals do not diffuse light only reflect Metals this video but unfortunately they Moana and Beyond and the talk going over Pursuits because it's extremely cheap Ralph and Beyond it looks kind of bad Ralph and future movies which is quite Ray are the same this is known as a Ray representing the color white or to Reflections are just half of the Reflections work isn't enough though and Scattered a certain amount of it will be Shader parameters material texture sets Shadow each other preventing rougher Solutions with their own pros and cons Stars light interference which is when Surface how do you determine how much US and a 10-year warranty Helix also Vector points directly up visualizing Vector removing the need to compute the Vector then we can model the roughness Vector to point towards the light source War Ragnarok which ALS also make use of [Music] a little weird when we visualize it on a more perfect reflection alignment to a much smaller range so the direction we a point on a surface is equal to the a specular reflection to make modeling a surface though a certain amount of it a vulnerability stack before I either go about 0.71 and the shininess doesn't about the actual surface normal it looks absolutely no light except a single absorbed earlier like glow-in-the-dark abstract approach and use a placeholder abstract ideas this version is a bit abstraction and construct a more abstractly the Fel term describes how action this already looks pretty good actual direction of the light and if we actually everything in the scene uses actually right does the lambian diffuse addition of each parameter and the additive lobe based on the angle between adjustments to the model to stylize and advanced Theory from physics and Optics after the reflected light enters our again while the diffusely reflected ahead and do that on your own time all it takes is for someone like you to all the fact that light goes in and already model some ideal diffuse already taught you a few brdfs just always mean photorealistic rendering an an isotropic specular response your an indefinite integral because there are an isotropic means that the distribution and Global illumination unfortunately we and I'll see you next time and blue light of that Ray while and enables us to model a very wide and generates more energy than was and illuminate shaded areas like genuine and instead extended the lambers diffuse and lights which you can find over on my and returns one when the angle is zero and returns zero when the angle is 90\u00b0 and some metal even change the color of and the color of that incoming light and thus feels a little bit different and we know from the blind Fong lighting angle between the half vector and angle of incidence decreases and another angle stuff back in 1760 but was he angles of incidence from the light and angles specular reflectance scatters in another restriction is in the brdf it's any distribution function we want so approximation everyone uses was invented approximation of the hanran Krueger approximation we discussed earlier since approximations rather than knowing the are a bit different from diffuse while are and the result of that is how strong are equal to one and any number are extremely complicated so complicated are for a second artistic specular lobe are getting what we asked for though are multiplied with each other and are only a few lever pulls away from article links below the lambers diffuse as much anymore additionally Helix as well as subtle differen this is why as you can get in previous videos I have at a white surface lit by a white light at that scale physics has found it attempt to solve it whether intentional attenuates it as the normals of the attenuation consists of two parts axis which when applied to specular back to sleep or decide I've had enough base reflectance of the Fel based because it's derived from based on physics the fortunate reality be kind of pointless so let's start from be not all specular highlights are be paired with a sufficient light be really on the money here we want a be reflected based on how different the be visible while other more rough bear with me here this one is a lot to beautiful specular highlights of course because a computer doesn't know what becomes the color of a pixel in the bed be sure to check out helix's wide been looking for I was matched with the beginning with the god of Graphics our behavior of light surface interactions behaviors of metallic materials we want behind the scenes it starts at the better idea of how it's working white between the half vector and the normal between the light and half Vector sets between the outgoing vector and light between them as you'd think I often hear between them since our light and normal bidirectional scattering distribution black corresponds to no reflection at a blocking the view coincidentally a brdf Falls underneath while Theory can brdf but who cares just cuz it breaks brdf for short and is the real meat of brdf is known as the blin Fong specular brdf no they use a different model for brdf satisfy the rules of the rendering brdf so most resources are going to be brdf to have the same result if the brightness of the specular to account brings us to 1986 when David IML and but Disney uses the isotropic ggx distri but does Disney also use the lambian but ggx sharply falls off and then but if you take a moment to look around but remember that the brdf is only one but we still have three Shader by Jim blind in 1977 and the resulting by Kristoff schlick in 1994 Which models by adding an exponent variable that by multiplying each component of the calculate the dot product the first is calculates the reflectance at 90\u00b0 from calculating something like the calculations with so how can we model called bidirectional because the output called the clear coat layer essentially can sleep easy Helix makes getting a new can write this as either the dotproduct can't so we need to add more capture all of this it's easier said causing a phenomenon known as offsp certain color just like how diffuse check against when verifying our choose from the two most popular are clear a roughness of one makes the closely match the behavior that was closely with the view direction as coat parameter controls the strength of collide with an Apple the Apple surface color texture and normal map we can comes to light interaction as mentioned committed to keeping fiberglass out of commonly used today due to people saying communicated how math comes together compare the two vectors we're getting completes the microfacet brdf for complicated and deserves its own model complicated the rendering equation is components that need to be solved the composed of microscopic grooves of compute one or two light directions and computer Graphics because it's as cheap computer I can already see at least 10 computers as Graphics programmers we computers were much slower and conceptualize what math actually is math conceptually the geometric attenuation conservation of energy the outgoing constant when we want to model something construct mathematical models that context the direction of incoming light context this means we have to sort of control or we can abide by the rules to control over the shape of the specular control with physical plausibility not controls how wide the specular lobe controls the roughness of the convinced yourself that math has to be corresponds to a full reflection while costly if we take a look at our Vector create a new reality once you get to any created equal though very shiny objects creative adjustments for more artistic creative decisions and lever pulls away definitely don't want to include it demonstrate greater reflectivity when describe a phenomenon in which surfaces described by the frenel equations which description thanks so much to Helix for diagram the normal Vector is also the did not make use of the microfacet model different it's bright as where the different ways even the Plastics are differently enough that you'd think each diffus brdf to see both of them in diffuse Reflections invented by Brent diffuse as it does not rely on the diffuse contribution to zero as well as diffuse reflectance scatters at many diffuse reflection when light is diffuse technically there should be a diffused light and divided by pi I chose diffusely reflecting the remaining red direction as you you can see ggx and direction is 45\u00b0 to the right of the direction of perfect reflection and the direction of the reflection aligns directional light source colored directions which we can visualize as a directly lit sphere looks a bit directly reflected which we refer to as discussed earlier but since it's already discussing the extension of the brdf distinct from each other while we distribution actually reaching zero distribution for Simplicity the clear distribution function describes the distribution of slopes un fortunately it distribution resulting in a wider distribution the diffuse lobe specular distributions shows how much light can divide by pi here but that's usually divided by this denominator why is this do not get to do that because I am do product but Disney uses the cosine so doesn't matter if they're swapped the don't necessarily have to follow the don't need to include it and we dot product with the view Direction due to less light being perfectly each parameter of the Shader and most each point of the sphere is outputting earlier many metals exhibit an isotropic earlier this is part of the diffuse lobe ease if the color of the surface is red easier to think about the roughness of a easier we usually separate diffuse and else happens when a light Ray penetrates emitted light plus the reflected light enabling artists to model as many encapsulate many things at once since energy the second rule requiring the enforces a set of rules on our solution enough to be unique today we'll be entry and and exit point of the light environment I created a few different equal scattering of light in all equally in all directions which is what equation albeit a simple one with a equation but otherwise we can kind of equation if you think this is too simple equation in the case of Disney they get equation is a little too simple but but equation it breaks the laws of physics equation since the diffuse color and equation to describe the expected equation when a light Ray hits a surface equation written in math terms not just equivalence of the two definitions we essentially the geometric attenuation essentially the schlick frel even though Disney's lighting model ever invented back in the day though everyone else is doing to make their exact solution everybody has their own except hair and movies like Wreck-It except hair because hair is just too existing distribution functions to expect a full strength reflection but as extension of the lambian model that eyes this is obviously an fails to accurately portray any surface fake indirect lighting which I did by familiar with math this simple equation fancier like have an emitter that is an fiberglass is bad apparently Helix is figured out all of this cosine of the final image render so it's like the most first models for specular highlights fit your needs conveniently shipped to flattens the diffuse reflectant and flesh Denim and metal foil I put focused on that including this video if focusing on the real-time rendering foliage polarization of Light which is following the link on screen or in the for a few weeks I couldn't be happier for a model this brings us to this for a number of other aspects of light for already but some metals are also for shadowing and masking with a more fraction of micro facets that are frel equations considered harmful the from Ultra photo realistic Graphics to from looking like Disney movies and that from the distribution function but from the light clearly there is a function describes the geometry of the function exists that takes in an angle function is known as the bidirectional function just with different inputs function models how light is more likely function or bsdf for short which our function that describes how much light function there are lots and lots of functionality to our brdf diffuse functions can be anything we want they games and other real-time rendering genuine subsurface scattering as you can geometric attenuation will dim the get a more photorealistic result but at get more interesting stylized Graphics get what we need back to our model we gets darker until the surface faces away giving the Apple its red appearance glacio teex cooling cover which enables glass or water subsurface scattering of go with a simpler approximation the Fel going to penetrate it and then get going to stick around while we develop greater than the incoming light received guiding star the one that points the way half Vector is from the surface normal half of the lighting puzzle and it must halfway Vector between the light and happy and impressed that the mattress hard to explain phosphorescence which is has the expected specular highlights now have no choice but to once again take an have the opposite design philosopy phos have their own unique behavior when it have tiny pinpoint highlights requiring have to compromise on realism based on heavy lifting it ensures that our hello everyone Disney movies are filled highlights results in elliptical his team's process for developing their hope you have a great rest of your day how materials exhibit perfect how the brdf can model very different hypotheticals to obtain good enough ignore the integral lastly we bring back imagine a sphere in a black void with immediately after radiation exposure impactful part as it's mostly important part you might be thinking if in a box and takes no time at all to set in as Disney makes use of the an in order for it to be valid for instance in other words what is the distribution in simple absolutes to talking in in the direction of perfect reflectance in the light Direction which we call the in unreal because you're familiar with incident angle to put into cosine includes a geometric attenuation term incoming directions in real-time incoming light and masking when a incoming light and we're all done to set incoming light equal to one the light incoming light essentially we can't indefinite integral of the rendering indirect diffuse and specular highlights industry earlier I mentioned lambian initially obvious to people less interpolates from the base reflectance intersection lamberson reflectance is into a bsdf to support subsurface invent It Anyways that's all from me I is achieved at a lower angle than is also Satisfied by the lambers and is and math switches gears from talking is going to be absorbed never to be seen is not real it is essentially a cartoon is not square and varies based on the is probably good enough for you clearly is reflected at a specific point this is that light operates and reflects at a is the most common diffuse brdf in is the sheen strength which is an is this specular brdf is known as the isotropic or strobes then we would make isotropic version of ggx in order to it communicates the fundamental idea the it in order to accommodate for the other it looks better when compared with the it looks more physically accurate than it on a plane remember that brighter it's a isotropic counterpart visualized it's derived from microfacet Theory it's not correct to refer to it as a it's not real we can make any amount of it's through that High Fidelity that we just an additional artistic parameter just ignore it since most surfaces are just like other waves can be interfered just looking to the right from my just one shading model to create every just remember that you're the one that keep you cool especially during the known as dialectric which means they known as the helm Holts reciprocity lambers and brdf the difference is quite lambers and diffuse by adding them lambers and diffuse you passed the test last two parameters of the Disney brdf lastly the Doppler effect also applies lastly we have the geometric attenuation least a little light that's reflected let's finally take a look at how Disney let's put it into a new environment to lied earlier when I said Disney uses light Ray collides with a surface it's light and half vector and doesn't care light can't be greater than emitted an light color are constant the only actual light equally in all directions shiny light goes out so if we want a general light has bounced off the floor and onto light is going out in a specific light is usually just an additive light observed in surfaces like Jade or light remains for instance if a light light should no longer be able to reach light source but there's one problem our light vectors and taking the dot product lighting is backwards this is because lighting model across every engine is an lights in a Sky Box helps quite a bit like Horizon forbidden West and God of like a light bulb or anything else that like little Legos to produce grander like mobile where performance matters linen all these materials behave little different this video has been little microscopic surfaces are called lobe and clear coat lobe come together lobe for artists that is an longer limited to just diffuse look Complicated by the end of this look at the specular portion which is look like a flat plane at the look like and if a solution exists it looking at Disney's solution to the looking like Wreck-It Ralph looks like in a black void with a low roughness value it means we have a makes it look more uniform across the making personal observations of real making use of a linear algebra operation many other mattress companies that make matches what we need essentially a model materials and substance to demonstrate materials as they want with just one materials like gold and silver foil our matter because one to any power is one mattress Easy by shipping straight to mattresses are fiberglass free unlike mattresses in their own facility so you mattresses or 25% off sitewide by mean from Theory we know that when a means we have three individual measured or observed with a proper model microfacet Theory I hope this has microfacet Theory remember that this microfacet blocks reflected light microfacet distribution function the Fel microfacet theory are just a few microfacets and they average out to the microfacets can block each other microfacets themselves and the main microscopic level but a very rough microscopic level so if we want to be microscopic surfaces to do lighting mirrorlike towards the distance as the mirrors do not diffuse any light at all model as it turns out Disney derived model combining blin Fong with the model denominator and we get our model for that is the Smith model which model model is the frel equations which model that can do it all then we need to model that can output many kinds of model that the direction of perfect model thus far it's these microfacets modeled as well as provide more creative modeling how microfacets can block and modifications to that portion of the more artistic control the next parameter more sophisticated models that can more than anything this lighting model most common lighting model in video most important part of it all is the most people are never taught or come to most recent literature agre G on this mostly bouncing into our eyes rather movies they use it for every surface much light is reflected based off the multiplied by one is the same number multiplying the magnitudes of the my patrons without your support I need a new variable which is the vector new brdf model in his sigraph 2012 talk next parameter of the Disney brdf comes normal below a 90\u00b0 angle clearly the normal vector and the view direction is not all of it will be absorbed and not emissive anyways without emission notably how they fiercely debated the nothing else if we try to model now the next term of the microfacet number greater than one so it is not numerous health issues since breathing objects have a wider range of specular observed in translucent surfaces like observed on materials like claw cloth of of Reality by taking measurements and of brdfs the lambers and of math possible we Define a few of microfacets with a micro normal equal of our surface as the probability that of surface exhibits to the maximum of the surface if you remember from of the surface normal and then using of the two vectors or as the cosine of offers a 100 night sleep trial to make omitted in most game engine software if on the foundation for today burle's on the sphere we can see where the once even though it's already really hot one for now lastly the microfacet model one for now these three abstract terms one is programmed individually but one this is obviously quite limiting and one unfortunately the PowerHouse blind ophy the end model has 11 parameters opposite effect because a smoother or not I say attempt because there is no orientation of the microfacets so this oriented in the direction of perfect other materials from shiny to matte no otherwise predicted by the frel term our emissive light term from earlier and our incoming light direction is the our metallic parameter to reduce the our simple assumptions of how specular our specular model specular highlights our specular reflection should outdated though as it doesn't account outgoing directions are swapped this is outgoing light being equal to the output and input directions are swapped output and input directions at all so it output is the same congratulations outside Jokes Aside I'm actually really overhead the normal then we should oversimplification of how light own hair being an example as well as paper concludes that it's a waste of parameter allows for more surfaces to be parameter of the Disney brdf is the parameter of the Disney brdf surface parameter that tints the sheen towards parameters left of the Disney brdf with part we mostly care about is the patreon as usual a huge thank you to all pattern you're familiar with many phosphorescence but the glow ceases photorealism the next parameter of the physically accurate now it's time to physically accurate with our light physically based rendering and what physically based rendering doesn't physically based rendering is rendering physically based shading at Disney for physically plausable our smooth plastic piece the first parameter is the color pixels means a stronger reflection plastic or polished wood we clearly point we would need to check every point whereas a game made in a polished and we could model numerous popular example is the ocean specular possible for this equation to ever possible which is funny to me because I predictions we're going to have to think preferences and body type and Helix will premium match mattresses customized to present in the rendering equation we presentation discusses the initial primary specular lobe and once we principle which I explained in my last principled brdf you can already see how problem of computer Graphics as the problem though computers can't exactly problems of substance though you begin produce more energy than was given as produce more than what was put in which produces light if we wanted to make that proper solution to the rendering proprietary engine has its own approach pursuit of having as few settings as questions based on your sleep quick review of those and determine if range of complex behaviors here that we read about Atomic physics you can go real world it just has to follow the reality to predict future outcomes or in really see specular highlights when the received it's also not by directional so recommend you the mattress that you've reduced to zero per the multiplication reducing the chance of a reflection and reflect tins colors lastly polished reflectance a surface exhibits based on reflectance at grazing angles the reflectance but what does that actually reflectance distribution function or reflectance is the halfway Vector reflectance when viewed at or under 90\u00b0 reflected at that point this means we reflected incoming light and now we have reflected into our eyes this is when the reflected light portion because emissive reflection Vector was actually a bit reflection and this is dependent on the reflection as the surface itself is reflection this optimization was derived reflection vectors so we can optimize reflectors but is it a solution to the reflectors such as plaster or unfinished regard to anything else if we look at regularly wake up in pools of sweat with regulation problems and I don't wake up relationship between the direction the relies on a specific function derived remember that the goal is creative remember that the half Vector is the rendering contexts and the only benefit rendering equation Solutions so let's rendering equation and how they used rendering equation does it follow the rendering equation does it follow the rendering equation it's still physically rendering equation while it may not be rendering though we're just going to replacing the red with a very variable research and design philosophy behind resources the cosine is is Multiplied response and the geometric attenuation responsible for driving the shape of the resulting in tighter but brighter resulting light Ray from this process risk-free if you're looking for a new rough surfaces this can be any function roughness frel reflectance in physics is roughness of the surface as well as the roughness value flattens out the rules for Simplicity let's take a look rules no it fails to conserve energy sale with 30% off Lux and Elite sampling the Skybox from the direction satisfies the law of conservation of scattered all around from the point of scattered at many angles for scattering angles so we can model this scattering approximation allowing for scattering range and a dimmed specular scattering that is beyond the scope of see that the diffuse does not blend into see what it's capable of adding a few selection of 20 unique mattresses and sentence it must not be that complicated set the outgoing light equal to the shading models more physically accurate shadowing when a microfacet blocks should be the same if the incoming and shown it with the dot product we simplicity's sake we assume that the simulate a near infinite amount of since that makes our diffuse brdf and single distinct surface in Wreck-It single possible incoming Direction in singular directional light source we'd sitting in this black void though so slowly Fades while Beckman behaves in smooth surface like a mirror is going to smoother surface and so light is going so we usually generalize all of this soft shadows as observed here where the solution does not break the law of solution we model what a solution should solved the rendering equation Okay I some things to add though for instance something is physically based that means something shiny though like Smooth something that can't actually be modeled sophisticated Solution on top of it this specular Peak where the peak reflectance specular brdfs so our lambers diffuse is specular highlights but we still need specular highlights when we say specular highlights while a high specular rather than the circular specular strength which describes the specular which our model accommodates sphere begin to point away from the sphere look brighter on grazing angles sphere with perfect luran reflectance sponsored by Helix Helix provides sponsoring this start at the highest level of start with the simplest brdf in the still there's enough versatility and stops nonlinear light effects such as straight editing this video in the end stuff like brushed Metals so this subsurface brdf which effectively subsurface parameter Blends between the subsurface scattering it doesn't the subsurface scattering wood the summer months since sleeping on the support an isotropic specular highlights sure the mattress is right for you so surface but it is not a replacement for surface but listing them all out would surface can see the light and slowly surface currently our model assumes an surface faces and the amount of light surface like a concrete is going to be surface normal is the average surface normal this graph of the surface normal we've been using for our surface rather than the shininess metric surface we have derived the most basic surface we haven't really talked about surface will diffuse less light is the surfaces from demonstrating high surfaces from sparkly snow to skin to surfaces have pinpoint highlights surfaces in the real world demonstrate surfaces such as dry mud wet mud wood surfaces that all behave in very surfaces though if not every kind of take advantage of their Memorial Day take in the amount of outgoing light at takes into account frel reflectance technically an infinite amount of term counteracts the frenel for very term which counteracts the Fel by than done because we're limited by our than somewhere else so if we calculate than there was with the basic lamb thankfully heal offers an option for the thankfully the two parts are the same thankfully we already have solutions for thankfully we can skip that entirely by that Natty Hoffman wrote a paper called that achieves the described Behavior that as the lighting input for the that control the appearance of the that describes the base color of the that drives every modern shading model that is not a perfect light diffuser as that light actually reflects off of not that point and there should be no that points orthogonal to the surface that the outputed light is 1.42 which is that was in 2015 by Brent Burley again that way our DOT product trick actually that we've been using so far a perfectly that would break the laws of physics that's when the reflected light would be the Fel and geometric atten uation term the Fong reflection model by calculating the High Fidelity photorealistic the Unreal Engine lighting model at this the almost opposite way with the the average of the microfacets as that the base color now we can model metallic the base diffuse reflectance to Max and the case of computer Graphics visualize the color of the light source without the color of the surface this completes the common distributions like ggx and the cooler part while the diffuse lobe the cosine of the incident angle is the denominator because it's what the the diffused portion of Disney's the direction of outgoing light which is the direction towards the camera in this the distribution term is the most the dot product there are two ways to the end of the day High Fidelity games the equality operator is doing a lot of the equation reduces to just the the exact same mathematical model the halfway Vector between the view and the hallway floor becomes more the holy mother of graphics and every the incident angle it depends on who's the incident angle the Disney diffuse the light Vector here if it's directly the light Vector moves away from the the light and half Vector such that when the light and view vectors this could be the light direction we should only the light hits a micr faet that points the light is at very grazing angles the lobe and the gloss parameter the mattress to better diffuse heat and the next being the metallic of the the normal Vector for a flat plane this the polished wood actually looks the powerful tool but first something a the problem can be described in one the real world though we can see that a the reflection Vector we could take the the rendering equation we still have the rendering equation while it might the results or make intentional the roughness parameter and the angle the rules though doesn't mean it isn't the scene for our amazing new model the sentiment that people don't care for the spec lobe does derive from the sphere in math we model this using the sphere it's easier when we look at the surrounding hemisphere which is how the top and build the model piece by the topic the RGB color model allows us the wave of light is interfered with the wrong angle so in order to simplify their brdf from microfacet Theory so their highlights there's such a wide then calculates the Fel based on the then multiplying it against white gives then to solve the rendering equation we there is a slight sheen to the surface there is no physical basis for this it's there is one thing that connects them there isn't as much of a difference there's way more creative control here these microfacets are perfect mirrors these together divide by the microfacet these words mean using the least amount they're actually solutions to the this finally brings us to modern-day this function is called cosine so what this is the rendering this reduces pretty simply and we see this they modeled every single surface this to model every surface in their this video though so we'll put our focus though because remember that these time to use these Fel equations in most tint the color of our specular towards tint the specular Reflections towards a to be reflected when the average to convert this abstract idea into math to do path tracing for indirect lighting to finish the reflections the next to form Disney's principled brdf with to get a more physically correct output to include the pi this time cuz I think to just the cosine of the angle so if we to light but only when objects are to make the sphere fit in more with the to more perfectly reflect off of it to represent this mathematically with to that of the halfway Vector between to understand just how diverse to your ideal mattress just answer a few together a little material editor where together gives us what used to be the totally model each surface individually translates to color for a deeper transparency this is not the most recent transport algorithm to solve the traveling close to the speed of light so treats the micr faets as a randomized true amount of incoming light out of trying something new is totally twice it's named after Johan Lambert who two Photon absorption if you want to ultra realistic Graphics like God of War understanding refer to my other video on uniform dimming at higher roughness unpredictable and chaotic the real world up along with free shipping inside the us red as the green and blue were use of fiberglass as a flame retardant use this first Formula then through the useful if you're targeting platforms value here that Brent Burley presented values now finally we multiply each of variable is the angle of incidence and variables such as the position in Space variety of materials in a way that feels variety the rougher the surface these varying slope and height the greater the vector are normalized their magnitudes vectors and adding them up or by vectors by the cosine of the angle verion diffuse even if it's not exactly version of their shading model the one very powerful tool the math that drives video These two rules are what we'll video looked decent even though all I video okay you're right maybe the video you'll understand how games with video's problem given a point on a view angle which can be any function we view directions this is then multiplied view the object from actually matters viewed at grazing angles for instance visualize it on our sphere we get a want so we'll declare it as a generic was able to solve my temperature was using was this simple brdf and we can probably just ignore this one as we can see most surfaces do not scatter we can use it as a replacement for we do all of that specular stuff again we have derived the actual rendering we have to add the result result to the we know that cosine cannot output a we need is the angle between the normal we want our incoming light Direction we want so we'll declare it as a generic we would get Global illumination and we'll declare it as a generic one for we'll have a perfect specular reflection we're about to discuss was extended for we're going to need to turn to some more we're modeling right now as our brdf we're only taking into account one light what we can efficiently compute and the when a surface slowly releases light it when it comes to seeing these as well as when the surface diffusely reflects which counts for the scenario in which which ggx never does there is always at which is accompanied by another which is dependent on the second which is still equal to one something which means that the entire Disney brdf which means the dotproduct will be equal which studies have shown can lead to which tells us how close together they which we aren't doing so instead we will while a roughness of zero has the white well that's obviously not right we will absorb a large portion of the green will not follow the rules but who cares with fluoresence which is like with statistics of course if we assume with the base surface color since it's with the incoming light color which with tons of distinctly different without calling them that so let's do a wood which is why the game I made last works if we wanted to model what a white world phenomena we do our best to would be seen in spectral rendering wouldn't be able to spend 10 days wouldn't make sense we have a bit of a writing the equation Wikipedia uses the you are a solution to the rendering you can immediately prove yourself wrong you can play around with all of the you can see light is pretty complicated you can usually tell if a game is made you care about why you can read this you've seen my previous videos I've your door helix's sleep quiz matches you your door the mattress comes rolled up your lungs by manufacturing their"
  },
  {
    "video_id": "LDhN-JK3U9g",
    "title": "This is the Kuwahara Filter",
    "publish_date": "2022-11-04T15:49:09Z",
    "comment_count": 0,
    "transcript_text": "14 we can stack our fog Shader multiple Box blur every pixel contributes the Center a square over our pixel for each I think it looks really nice just on its I've decided to start a patreon Masterpiece using the kuahara filter now Shader the sick thing is that I already Strokes in paintings this makes sense as YouTube video [Music] [Music] a larger kernel size which is necessary a new weight if we divide one by one a square over our pixel then we divide a very difficult problem since we want about a lot lately is Edge detection about how an image effect made for advanced and so the images he captured afford to make patreon exclusive content after much thought and some requests aisotropic kernel that contorts to image all patreon proceeds will go to a dragon alright let's press play to see our new also has this cool depth of field effect am left awake at night wondering what and I'll see you next time and a lot of the texture issues of the and affects the output considerably this and it looks great in motion as our Chic and preserve Edge lines much better the and this was all I really needed to do and we end up with a neat ink drawing angle itself and stretch itself to angle of the pixel's position is within angle range of the sector so if the angle wow it's the part of the video angles on highly detailed areas such as anisotropic filter manages to smoothly anisotropic kuwahara filter and as anti-aliasing the only game in the world apparently they did a presentation on applying a sharpness filter after the applying the kuahara filter to the game approach would be applying a box blur approximate the weight with polynomials are pretty obvious the square kernel is area of your painting is whether by hand areas it has this really neat areas of the image where the filter around 1995. on 4 fortunately for you artifacts or real-time Ray tracing in artifacts should go away the last change artifacts that look like this if we as if you were using the same brush size at large kernel sizes causing strange at you with another sick Unity tutorial average color if we blur enough to average color of that sector thus was back to the past sometime in the 70s a becomes unintelligible if we want to better fit image details and edges but blur but instead we use a gaussian blur we retain form a little bit more born the kuahara filter one of the brush size to adapt to how detailed the buffer one problem I've been thinking but for us Indie peasants we have to but gpus are fast nowadays so I'm sure but in most cases the anisotropic filter but it's still not even close to good but to fix it we need to get a bit more by comparing the three kuahara filters calculating 800 gaussian weights per calculating the average with a gaussian can't express how much I appreciate that case it did eventually find a home I'm cases like this we want to denoise the change the original kuahara filter changed from denoising to replicating check if we are inside the circle that choose one of the sectors which causes close to zero but sectors with low closer to the center pixel when color and the standard deviation lastly colors this is a major Improvement since complex problem space they had to invent computers how to draw images to make up considerably but what else about the considering the entire point is to get controls how much the sectors overlap at convolving the syllable operator with crucial flaw when you're painting or data or smooth out the image to make it demonstrations instead we're going back denoising images invented sometime denoising medical imagery in the 1970s denoising smoothing effect the filter denoising which are extremely effective derivative of the RGB values with these derivatives next we calculate the described earlier and we're done done described in this article from the first detail a more sophisticated approach determine this pixel's contribution to deviation but what happens if two did all the work for you so like you different Shader combinations and the dithering if we dither before we kuahara do is follow my link in the description do much and kind of just makes it look do simple Edge detection by comparing don't even need to know how it works drag it onto the camera and then you put drawing generally you will change your each one has its own aesthetic appeal edge ensuring that we blur largely edition of GPU Pro the namesake of the eigenvalues of the structure tensor and eight sectors the filter could identify enough fortunately in the modern era we enough to sufficiently preserve Edge essentially these two numbers are the even in the context of stylized eventual real-time rendering use case except our performance has has improved failing miserably at its original use falls short the artifacts are just too familiar with cell shading half toning far removed from what manifold Garden features as you can see the results are figuring out what direction a pixel filter can we improve since our goal has filter come comes from the new filter effect pipeline which I think filter for homogeneous regions of the filter how could we go about restoring filter instead we're going to go back filter is most effective when used on filter not much interesting happens but filter the most common solution for filter why is it generalized I have no filter would lie dormant for nearly 30 filters get tripped up but the final color output previously we would first off the filter is actually really fit for use or presentation denoising is fits inside the square since we are now flickering when the effect is used in for a basic decent looking kuahara for each pixel we Center a square around for example consider this image that I for free as objects in the distance get for my image was 10 by 10 so that adds for my own lack of artistic talent this for sufficient stylization the kuahara for your entire painting leading to what formulation of this function the paper function if you're interested in the function similar to the gaussian function to give more weight to pixels functions are extremely expensive game into a stylized oil painting game sort of disappear due to the gaussian function entirely and instead generalized filter does quite well but going to need to calculate some more gradient into the distance then we can has become the driving force behind a have companies like Nvidia developing have destroyed in Photoshop with a noise have to do is calculate eight gaussian heart muscles obviously 50 years ago our hello everyone I am a graphics here I've got a game scene set up but high contrast visual since the desert high frequency details like Edge lines his own denoising technique similar to homogeneous areas while still hope you have a great rest of your day horde that my steel plushie will sit on hundreds of hours I put into each one of idea either way the results speak for if we did there after we kuahara filter if you'd like to support me and the image look like it was drawn with one of image processing algorithms The Edge image processing and computer Graphics image this new filter is called the imagery has transformed into an amazing improvements are incredible and all we in other use cases beyond the color in the description goes quite in depth indeterminate the GPU will randomly information about the image specifically information the filter kernel can now instead use gaussian weights these intentionally generate noise to add interesting topic do you know it doesn't involving the kuahara filter such as is all you have to do it's so easy is manifold Garden a game with such a it and then average all the pixels in it removes the indeterminate behavior of it with the average color of the sector it's perfectly fine to present in a it's the performance police it turns out its sector to figure out what sector the job actually thankfully we can use the juxtaposition of painterly and pixel art kernel the four sectors end up not being kernel with a circular kernel the square kuahara filter but what exactly did they kuahara filter could help when we apply kuahara filter for something else kuahara filter helps to bring out the kuahara filter was how it determines the kuahara filter will freak out at extreme kuahara filtered noisy image we can see lastly we divide the end result by the like hair the basic and generalized lines as we miss out on a lot of looks like but it was a neat experiment looks pretty much exactly the same lost pretty much all sense of form and machine learning algorithms for made with the effect main focus of a game's rendering maintaining details like Edge lines if make sure to like comment and subscribe making these videos so I can't really man named Michi Yoshi kuahara was means that the kuahara filter really medical Machinery was not nearly as minimum rate of change this all sounds model looks cohesive regardless of the modern post-processing effect that more realistic detailed renders if we most of the time we are trying to mostly to blame for this making the moving on from static images the kuahara my shaders on social media and words my videos I'd appreciate it very much need to wait for the next video though neighboring depths and normal values new amazing visuals new effect the generalized kuahara next change has to do with waiting the no one knows the outcome is noise is at the core of many Concepts in nonetheless I have lots of other ideas notice is that the artifacts the filter of how an image effect meant for medical okay so the filter has some problems on my GPU which is extremely slow the one I found most interesting was with one we take this new weight and multiply or dithering but today we're gonna talk or with pressure sensitivity currently original image and compare it with the original kuahara Filter Works like the original noisy image we'll see that oh our generalized kuahara filter operates our image to approximate the partial our new polynomial weights the image our polynomial function looks like so overlap at the filter origin and Ada own my character looks a lot more anime pack so if you want to play around with painterly look by further accentuating painterly stylized visuals the papari's team made to the original parameters the result is a weighting partial derivatives we calculate the patterns are only noticeable on dark pessimism is most applicable to stylized pipeline these new shaders have been pixel is a little outside of an edge pixel is borderline illegal our frame pixel is in we use this equation pixel is on the edge then the quadrant pixel of the kernel we first want to plus the standard deviation then sectors points in using the eigenvector possible angles papari found that with preservation works like like so if the preserved the Box artifacts are gone and pretty cool unfortunately this is very produces are similar to that of brush programmer which means that I tell proposed an extension to the basic proves its potential use case as the quality tools or we cut corners on real time obviously this is unacceptable realistic and more abstract you may be reason it's so bad is because gaussian released as part of my g-shade Shader remedy this they replaced the square remove the noise we can see that we've removes all conditional logic that's all rendering in which we use Shader rendering the original kuahara filter rewards right now because I work full rid of it if we apply the filter to the rotating Chic around the generalized said technique but I can't find it so I same amount to the final calculations sector unfortunately this means we need sector we will calculate the average sectors have the same standard deviation set the pixel to the average color of settle with something like the bilateral several people have posted pictures with shaded visuals here's a few images I shape isn't the only issue with the simple papari and his team dubbed this simplifies image features unfortunately simulate a dynamic brush size then we're simulations for the sake of speed we end since I think it will be a very long and so thank you moving on I was interested sometimes when data is gathered with low somewhere thanks for watching everyone I sophisticated for each sector we will sort of aesthetic which I think looks spectacular no more clustering artifacts still isn't sophisticated enough for our strong and the image loses all detail at structure cancer a matrix that describes stuff I did with the filter let's start stylistic paintings stylize both the face and the hair stylized piece of art it isn't going to stylized rendering effect despite substituting the gaussian weights with sucks at denoising but what people did suffers from box-shaped artifacts which sum of the weights to average the sector sure there's a metaphor in there susceptible to noise which is funny techniques to make our games less terrible this is where I thought the texture space kuahara filtering but that thankfully very simple we start by thankfully we can just ditch the that has done Edge detection perfectly that points in the direction of the that range then we know we're on its that square setting the pixel to the that the noise is still very noticeable that's right ace rolla's patreon plug the box and gaussian blur we will Center the changes papari made so let's go over the directional information which is the distribution of said partial the edges between the blocks of color the effect in motion if we start the face and the hands this is because the filter the edges get smoothed out the first thing you're going to want to the generalized filter still has one the grass field for real-time the image is still very stylized these the kuahara filter effectively the new effect in its entirety first we the original image a simple first the original kuahara filter and it the sector with the lowest standard the square into four sectors for each their boundaries with the proper their own anti-aliasing technique their secrets are back to Final Fantasy them the link is in the description themselves Edge lines are much more then add it to the total color sum then the quadrant with the lowest then we can get some really interesting this Shader here in the field and then this naive waiting confuses the filter this video is not about the bilateral those weird square-shaped markers to time and all my time at home is spent time is currently about 13 milliseconds times in a row to create a nice color to check each pixel 8 times after this to download the kuahara script and to our good friend Final Fantasy XIV to smooth out the data but also maintain today I'm teaching you how to turn your top of anyways this concludes the story transforms images and games into try and apply the filter to an already turned into painterly blobs I found that unfortunately there's not a lot of up to 800 weights calculated per pixel up with noticeably inaccurate data which use its standard deviation to calculate use them to calculate the eigenvectors using a circular kernel next we need to variance and set the center pixel to the variance will have a weight closer to variance won't be the edge but if the variants stochasticism Randomness or variety to assets and effects but very complicated but all we're doing is we also refer to as noise some examples we apply the kuahara filter to our we calculate the pixel output as I we pick the sector with the lowest we will call clustering artifacts those weights per pixel of our kernel which well it seems like it does a pretty bad what's up YouTube Ace roller come back where I get to show you all the cool where Zeta controls how much the sectors which becomes apparent when we look at which is logically the same as a box which is where our problem arises the will have to wait for another video will still work like the generalized wins out this is most obvious with stuff with high variance will have a weight with the lowest variance will be the without issue I experimented a lot with without returning to the psych ward but work with realizing this kuahara devised working on the early medical imaging of world's first Edge preserving denoising worse because of this I won't be using would be to gaussian blur the image would come out very noisy and hard to years until Giuseppe Ari and his team you don't need to worry about that all you gotta do is take this script and you may be familiar with are jpeg you up the kernel size a little bit this yucky aliasing on the edges just looks"
  },
  {
    "video_id": "McbCLuWpGWk",
    "title": "Procedurally Generated Fractals 2",
    "publish_date": "2024-11-30T15:02:14Z",
    "comment_count": 0,
    "transcript_text": null
  },
  {
    "video_id": "O-2viBhLTqI",
    "title": "What Is A Graphics Programmer?",
    "publish_date": "2023-11-30T22:16:49Z",
    "comment_count": 0,
    "transcript_text": "2 weeks after accepting the Sony offer 20% off in annual plan when you visit 2ear degree you would also have a high Advanced parallel algorithms implemented August 2021 my first video was released CPU Graphics programming also struggles Casual viewers just how much work goes College I personally use brilliant for a Community College at 14 years old Concepts I have proposed throughout my Detective Conan and I had aspirations of Direction but honestly I did not use Drafting and considered it as a life Dreamcast proving its efficiency and Early College were rendered pointless Fantasy and began trying as hard as I GPU gems series of books these are Game Dev industry do not have degrees Google it and write down what it means Graphics API is incredibly Graphics API work with the roster Tech Graphics I wondered if maybe I could Graphics as the math of post-processing Graphics programmer but despite saying Graphics programmers have a bit more Graphics programmers have far less Graphics programmers so what's the Graphics programming every problem is Graphics programming is a specialization Graphics programming is conceptually Graphics programming shows itself the Graphics programming was and I felt Holy Grail real-time rendering fourth I could solve this I finally realized Graphics programmer I had it turned out I I got insanely I started making my videos the reality I strongly recommend learning the I was aware of when I was trying to I was in eighth grade I was quite sickly I would also have to skip High School Internship Gambit the plan was simple I Internship experience in June of 2022 I Jasper's rendering series I would Jasper's tutorials and the roster Tech Mentor me a little bit and gave me some Minecraft shaders while I was riding the Minecraft video Final Fantasy 14 video Newfound motivation I have always loved OSU Cascades but there was one major PRX and so the two years I gained from Rola or click the link in the Shader authoring has largely been Shader effects I listed earlier either Shader graph I feel like it would be Studios writing engine code is going to Technical artists are the ones working [Music] a computer Graphics course offered isn't a computer science degree will keep your a few months later in November I landed a full-time offer from Intel I also a game development school because those a graphics programmer the year was 2012 a lot of my colleagues I've met in the a professional so let's start by a programming class this High barrier of a test driven approach to developing a able to answer but I'll do my best about how much I love Graphics through about programming I had no idea what about the world around me and whenever I absolute best resource on the internet academically gatekeep disciplines as accomplished band kid and I also did actually do since many people seem to be afterwards December 2020 came around and ahead of me and I a reasonable human all I have to say is that Graphics all advocate for more workers rights for all have their own specialist knowledge all just simple math I feel like I all that's left is to write the shaders also Co happened and I put 2,000 hours also fell in love with Calculus at the amount of fundamental knowledge amount of learning you should always try an arch Ure class and really enjoyed an interview for a graphics intern and Global illumination techniques and I was absolutely Blown Away by the and commit to self-learning with and create just like me playing and creative coding were over I was and ended up playing wow classic and and had around 150 submissions in total and how a GPU Works to begin with what and how a mesh turns into pixels on the and less interesting it went from cool and long list of videos demonstrating my and numerous other subsets of this and set pieces cyber Punk's photo mode and spent all of my time seeing what and then become a specialist what I'm and then read the paper again then you and they got in purely by just having a and understand them all the research answered in more but first something a answering the answering the question how did I become anymore especially not as a portfolio anyone can read the papers anyone can anyways that's all from me I hope you anywhere as long as you get there appeared in my town OSU Cascades its are an implementation of a related are more roles at Studios that involve are often far more complicated than are the highest form of Art and I love are usually the ones working with the around 2 years to fully get over myself around and I enrolled in Central Oregon artistic concept of shading I have the artists and not engineers and as we all artists at Studios these artists work in artists but it is something to keep in artists even though they usually do lots as I said at the beginning of the video as a child and middle school was no as get access to some builds of my ask the question what the hell is that asking a college professor to make a associate Graphics programming position at a studio and then be mentored in atmospherics many people did exactly attached to solving them I specialize in authoring plugins for modeling software average viewer which unfortunately bachelor's in order to pursue my dream back end being the graphics engine work back you aren't giving Unity any money based on shadowing to create stylized be the main task of Graphics programmers beautiful art with Endless Possibilities became my first graphics project ever because from that moment forward my because of the unity drama a few months because the field changes so often that become a graphics programmer do you need becoming a detective my myself but becoming one I remember submitting one beginner resources that quickly become beginners either it is a very very young being a subset of computer science it is being wanted to graduate at the same best way to learn math data science and between technical art and Graphics bridge the gap from beginner to expert bridge the gap from novice to expert bridge this Canyon something I have been brightness exposure saturation contrast brilliant is a wonderful option for brilliant.org but all you have to do is just just read but that's cuz I wanted to catch up I but to demonstrate that you could learn by learning stuff with their engine in calculus and applied differential calling graphics. blit or compute Shader campus had just finished construction campus since my best friends were doing can be used to modify and manipulate case shell textured God rays that clip challenge I'll be eating a ghost pepper chemistry this sounds impressive but in choose an algorithm and do a circle on the screen was like seeing clarify what a Shader actually is it's classes with outside Graphics resources clearly when my professor demonstrated code instead they are using Shader graph code that is executed on the GPU and the code to make their lives easier they ask coding.com I had followed most of his coincidentally a new University had colleague you can play the video now collections of Articles written by college student and the program would college students and since I myself am a color data to your whims whether that's combinations are endlessly entertaining come after me while also informing the compared to Unity since most competence to apply it it's important to competition and are far more in demand complete lack of intermediate resources completely skipped high school as all of complicated stuff such as Ray tracing computer science and maybe minoring in computer science assignments became less computer science class my professor was computer science interactively brilliant computer science skills these are very confused about consider all Graphics programmers to be consider all technical artists to be considerably more math intensive contents I also heavily recommend the contractors and thus are not given the convert college credits into high school cool art I could make with p5js with copy of to at least skim the table of could take the classes again and could to learn Graphics programming country for University I complacently course already a mountain of work and coursework to graduate with my friends crazy computer science stuff too there create those visuals but I still didn't creative process so much that I decided creative projects to boring lame web creatively inclined I've drawn and credentials are for specifically gamedev credits by the time you finished your currently but that's changing and in a customizes its content to fit what you cyberpunk 2077 is what sparked my death stranding reveal trailer came on decided to apply everything I had demonstration of your knowledge and department there just isn't that much depending on your experience in the end describing the kahara filter and the description thanks so much to brilliant designs and I also discovered my love development assignments and I could not did I recommend school because the didn't have the proper support to do difference it's a very blurred line difference of gaussians and there's different and some tech art problems different my target audience is mainly difficult because parallel algorithms difficult it requires expertise in two diploma and my associates degree in direction and Clarity ultimately all directx11 tutorials having Graphics API disciplines and complex algorithmic discover and explore I believe I have discovered our goat Sebastian l I saw dispatching shaders is as easy as dispersed and went our separate ways do dispatch whereas in gdau it is much do let me start there Graphics do my best in school coincidentally I do you do then unfortunately this is does not interest you at all but you doing all this nerd like reading doing unless of course you're interested dollars on a related math class at don't really recommend gdau for don't really recommend unreal because doomed to a life of misery in webdev it during that oneyear filler Arch I took during the wait until next spring so I dx11 app that rendered a Terrain hype each term to ensure we were taking the edition this book is 4 years old so it's editting Graphics videos on YouTube I efficacy of shell texturing and its ease end that you don't like game development engine it is heavily lacking in the engineer after all I certainly do not engines so that art is possible and enrolled in their computer science entire field of physics boxal rendering entire life and worldview changed entirely to which they were reasonably entry and everchanging lands an ocean of equations the computer science is esoteric knowledge are often considered especially not graphics I became even even qualified to be telling you any of eventually but for the people like like eventually it'll all make sense but ever hope to get a real job in the everything I was ever interested in or exact reason I do not recommend going to exception I had a mysterious illness existing tools lastly if programming experience fall 2020 came around and I explicit per permission to let me take extremely resentful and upset during fact it's kind of like you're stealing fail pretty miserably at it while Unity fall 2017 is when I took my first few of the tutorials I learned what a few years this statement will most fill in the gaps of my knowledge the finally got a foot in the door of fine I'll make my own photo mode and finishing University by the time I for Ace Rolla Studios and I'm here today for chemistry and ultimately decided for fun unfortunately over time the for getting started with Graphics let's for graphics the math ranges from simple for sponsoring this video let's start formal graphics knowledge how could I foundational math and CS skills required from getting my diploma and Associates 2 from learning the basics of game physics from them after you've ran through from writing Graphics engine code frustrated I was that I felt doomed to fundamentals in unity before furry challenge ran for about 20 days game development that has decent game studios are usually hired as gatekeep itself so how does anyone ever general game developer first get a job general material artist I only recommend get a job anytime soon certainly not by get their foot in the door how did I getting introduced to complicated topics getting to spend my time telling you all give slight breaks between self-studying gives way to a field that effectively go outside I notice and appreciate so goat Jasper flick exists and his long going to be for them but if you're in going to be outdated in some aspects but going to make you feel stupid sometimes going to seal the deal you're going to golden path a maneuver I named The good at combined at once especially when good at problem solving so seeing this good portfolio of projects they learned graduate I would continue spending 100% graduated high school so I begged my graduated with my bachelor and received graph Graphics programming problems it graphics API end of things as much graphics API to make the rendering graphics by your colleagues now let's graphics department and it is especially graphics engine this ultimately means graphics programmer how would you do it graphics programming is effectively a grinding self-study Beyond The guy even talking about vertex Shader had suffered greatly at this point had to do one year of high school first hard we're getting ahead of ourselves hate to say but it's just the reality have a great rest of your day and I'll have regardless I was a piece of have the physique to become a hardened have to do a lot of work on your own have to learn how to program a device have yet to read and implement but if haven't worked with in a long time be having us learn the fundamentals of he provided me with a book that detailed heavily gatekeep by Academia most hello everyone many Ace Rolla viewers high school that knew how to use the high school wondering what you want to higher level tooling work such as hired on as full-time employees this can his video on marching cubes and it hit the goal for the shell texture hopefully and read the paper again if you didn't know all the patrons get imagine you are currently a computer implement the technique the ace Rolla implementation such as blind Fong implemented on the PS1 the Wii and the implementing and experimenting to prove important if not necessary this is of impossible fall rolled around and it was in fact this is one of the main reasons in general it contains a substantial in grad school in which case feel free in high school informed me of this in terms of difficulty and B the industry professionals and a lot of industry so I devised a plan my own interest in post-processing while I interest in school at all my grades were interesting so I became motivated to intermediate resources to HUB Learners internships are only available to internships for the next academic year interviewed and received an offer for an intimidating but learning to read and into Final Fantasy 14 to cope with the into Graphics I'll be very honest taking into the pixels on their screen in invent the technology that needs to be involved looking at job listings we is it even worth it all of this will be is obviously very unfair and we should is often delegated to grad school if is simply a different set of is that you will have to go from these is useful even if you decide in the end isn't too hard to understand but the it again if you don't understand a word it all if needed on your journey you it if I wanted to go to school with them it is certainly an option to become a it is probably one of the only jobs in it isn't explicitly related to the it to do if you work in an engine like it was spring 2021 now and unfortunately it's also so Niche and specialized that it's what I enjoy but in the real world it's what most of the industry uses and its Effectiveness I proposed a challenge just a program that executes on the GPU knew anything I had been rejected from know artists are treated very very very know exactly what that was regardless I know including myself has to read know that despite Graphics programming know what I'm talking about I wonder how knowledge and perspective to find a knowledge it's of the utmost importance knowledge to even get started which I lacking in the learning resources landed on his rendering series I did a laser engraver to engrave AutoCAD last video on shell texturing is the lastly probably the most interesting use later E3 was happening and I was learn the fundamentals of blacksmithing learned so far by writing my own learned the basics I came across papers learning or web development this is the learning the basics from the resources less Advanced computer science and math level of expertise when it comes to life I wanted I would have to start lighting and GPU instancing to try and lighting and all of its sub problems like Maya or blender to help artists like solar flares this one shell texture like the graphics programmer will this like web development you could say that likely not be true anymore this is why I line and unfortunately everyone's linear algebra to multi-dimensional list of tutorials for Unity are the little different this video has been looked like so much fun I chose it for low production value and amateurish in lucky pivoting to computer science on a lying to you if I said these three made sense to me and became extremely majoring in chemistry I was so young make it a little easier for those that make it look cooler see what works and make shaders the ladder in a studio make the lives of artists easier they're making it more directly accessible to map by following the roster Tech DX marching Cube script in unity which math meets Advanced Computer Science math or taking math as electives like I matters is if you can apply the may not get benefits or paid holidays maybe some other area of computer me and I'd never catch up they would be me relevant work experience and more me who wanted to get there as fast as mean that depending on the studio you meant to be used like unreal and they meets art this is what makes it so messing around with unity tutorials might get you started with openg but might not be the best company around mild interest in the topic but very mind when you consider your path mine trying to use my existing knowledge months to do these things it took me more convoluted and annoying the other more frustrated because all I knew how more you will learn then after some most of which were firsttime Shader much Shader authoring today as they used much exclusively on writing shaders much math do you really need to know and much more than I used to as usual a huge murder detective the summer of 2014 came my employment status in multiple videos my grass series started getting some my presentation I spent an entire my professor asked us how we could nature to be a bit more relatable to the necessary sacrifices I quit Final need just take a quick quiz when you needed to go off and become me I'm not news is that if you want to work with next regardless I was finally a real normal map is then sort of got busy with not the starting line but the finish nothing I say here is absolute and there nothing the structure and guidance a of Graphics I created a little Unity of classes about game development and of computer science in which advanced of implementation so I certainly of my classes maintaining my status as a of my time on graphics and so I went of pretty much everything you'd need and of programming and require a lot of of those assignments and discussing how offers thousands of lessons from basic offloaded to the artists at Studios olola I do the graphics program pring on stream right now if you have any on your linear algebra for graphics on your own time is what I recommend opengl isn't really that valuable optimize High shell counts so I'm glad option open it's important to know that order to learn as much math as I could other engines and in my opinion gdau other videos to improve the basic otherwise they'd end up 6 years ahead of otherworldly I knew for certain that I our program had required assignments out as a cool weapon Smith you first out there for beginners compared to the outdated and a major lack of painted and sculpted I was an papers I link in the descriptions of my parents to let me skip High School part is pretty much all done for you and particle systems offline rendering the passed and I obtained my high school path I became the only person in the paths I'm laying out for you that patronizing and disrespectful to say people specifically beginners to try and people still don't see me as a people were able to apply what has been perfect initial limit test for perhaps the most valuable skill of all perusing the web for or even hundreds of phenomena in which internships are piece supplementing your University pipeline not urp or hdrp as those are pixel sorting video and Counterstrike 2 playing games I was in love with please okay so we're going to start off point I knew I was not good enough to poor and I never did homework I was poorly by the corporations artists at position at Intel working on their GPU position usually is not writing Shader positions are treated equally though possible applications for you to possible which resources do I recommend post-processing but you also have presentation on it around this time I privilege of focusing entirely on problem hello everyone my name is problem these are the portfolio pieces problem they didn't offer a chemistry professional AAA industry game developer professional and treat me as if I don't professionally one of these assignments professionals just aren't using gdau professionals that are able to produce profiler which I got the offer for and program I've always been competent with program yet so I did what every programmer and a technical artist both programmers at Intel who was willing to programmers more time to work on the programmers some of my favorite programming brilliant has something for programming is hard it requires a lot of programming is often left for grad programming requires strong math and programming so I want to clarify that programming with p5js the JavaScript programs are not going to really teach programs to create particle effects projects if you're too lazy to compile projects to keep me motivated as well as proper path that contained what I loved proper steps to develop ourselves proposed earlier in the video If shell proposed in another video of mine but proprietary engine working inside putting in the work and make the question what is Graphics programming questions on the video I might not be quick refresher on math concepts I rather than making your own tools if you ray tracing engine and encouraged me to reading through myself this past year to reality I wasn't that driven of a person reality is that it's insanely difficult realized that if I wanted to have the really looking forward to high school reason I recommend Unity is because the received a response from my application recent graduate a lot of my advice is recommend Unity to get started with recommend dipping your toes into recommend it as a beginner project after redoing all of Jasper's rendering regarding real-time Graphics programming released I took a bit of a break to play relevant Graphics class is like asking require differing levels of computer required skills it was at this time that research paper that I present on but my research papers like myself are really research papers many times over to try research papers research papers can be resources but let's imagine a world responded by telling me to stop being responsibilities that generally contains responsibility unfortunately at most results in most people assuming I'm not same benefits as Engineers that are same time it was like when math finally satisfy the needs of the artists and saying is is that Graphics programmer is saying you have to use Unity forever but school 2 years ahead of me the end of school and forgot about it a few months school curriculums can't really keep up school diploma this essentially school is very valuable for these school onwards as an undergrad degree science is such as robotics machine science math and art skills but all work science student and would like to get screen how a CPU interfaces with the GPU security because replacing you is really see you next time okay are there uh are self- teing and initial research self-study Graphics it finally paid off self-teaching Graphics I would fail all sentence without an internship to give set my sites on game development but shaders I realized the critical lack of shaders but don't want to do all of this shaders for my video content because shaders now that you can look at such as sharpness color blending whatever it's should go to sleep wake up the next day sign up and Brilliant will match you significantly I've always been simple Unity tutorials to reading simple you enrolled in Community College simulate physics to get a bouncy ball I simulation this one that is using noise simulations and of course my favorite since I always had older friends and since that stuff is not possible in skeptical of and ultimately told me no I skills but requires more competence with smart or something but no everyone I so today my birthday I'll finally be solutions that come together to produce solving nature was perfect for me for some kind of moral hold up over this specialization of computer science and specific specifically the built-in specifically Ty Al Jasper at catlike split between a front end and backend sponsored by brilliant brilliant is the stand web development I realized that I start that's no problem brilliant start with the age-old engine debate started a few months later in February I started learning math or are brushing up starting line is going to be very starting place for beginners their stayed home often binging anime and stayed in the same place and enrolled at stereotypically don't have because of still an absolutely massive field with still numerous other related papers I still programmers but it's different still want to work with shaders then straightforward and easy to use streamline the creative process this is streamlined the Shader process process strongly recommend going to college for student so I could continue applying to students as a requirement for applying subject that landed me the job after subjects and a computer science degree submissions include this one that is subset no one expects you to know it all substance designer and other similar succeeded in demonstrating both the such a in the nicest way possible sucks it sucks so much that I thought supposed to graduate but I still barely sure I had taken a lot of extra sure to try out everything brilliant has take every math class as electives in take notes on the books but what really taking pictures of beautiful graphics taught in other videos the purpose of teach myself Graphics he also got me in technical artists also do a lot of technical artists but I would not technical artists personally I would technical artists usually are not going technique has an immense amount of techniques discussed are still used terms in order to graduate along with terrain generator and in June 2021 textures and general materials used in texturing seems cringe and boring to you thank you to all of my current patrons that Graphics programmers don't do as that Graphics programming wasn't for you that I had to ask the professors for that I wanted to become a chemical that Shader graph cannot do which is that every computer science student has that functions very differently from the that it felt so hopeless my professor that matters is the skills asked for on that no doctor could diagnose and so I that one might be considered that resource nearly as much as I should that stand out to employers a that taught me pretty much everything I that technical art is easier than that you play around with whatever it is that you'd otherwise have to spend hours that you've made try to break it try to that's all under your absolute control the GPU only does things the CPU tells the artists and giving Graphics the blind phenomena the most even the code Yourself by the way since we the course load for a majority of my the first time ever I was motivated to the first time in my life I went home the front end being Shader authoring or the game but they aren't writing any the high school English teacher to make the job offer while a graphics the long awaited cyberpunk 2077 finally the main difference Graphics programmers the only position here that is seen as the proper skills that the industry the spring and focus 100% on the sum of signs fluid simulation the tech artists and Graphics brog gmers the technique is accessible to beginners the thought of learning it myself seemed the time I graduated there's a strange the year was approaching and my friends theater but I'm also very analytical and their classes my friends were still very their engine is in my opinion the best their sequential counterparts and you them by adding extra electives that then the other project I recommend is there any questions there are also material surfacing or VFX there for the game to work visually there is one resource I absolutely wish there was one major issue my University there's one last thing that I recommend these high requirements Graphics these school terms I lacked the they had all graduated from middle things were coming to a head I was this challenge was to prove that that a this fragment Shader that math from all this life of web development that I this my videos are intense intentionally this practice I have learned so much this uh next slide though if you wanted to become a though so I ended up focusing pretty thought of yourself most of my videos through it and came out with some time as them so I took on three times time for the big bad algorithms class time just like I did in order to gain times it's going to be frustrating it's to Advanced so if you're just getting to Great reception and I enjoyed the to be making those incredibly complex to be taught in an undergraduate setting to continue making videos on each of my to create an effect that kind of looks to create something I want or solve a to do that these are the three example to do was learn in a classroom setting to go to school to do any of this how to his entire rendering tutorial series to limit test and solve a problem you've to make themselves it's not impossible to manage the GPU because as we all know to me graduating seems like a death to offer with a free 30-day trial and to self- te programming and math from to speak generally to give a sense of to take our final project required us to to take your time and enjoy your to talk about what Graphics programmers to teach yourself how to do all of this to the local Sony game Studio to us how to draw a circle on the screen to viewers in the last video encouraging to vote on the next video topic as well to what shaders we do write are the ones today also it's free lastly aside from tons and tons of different problems that tons of Graphics internships at this took college classes like any normal tools like Shader graph have majorly topic Advanced postprocessing the good touch with one of the lead Graphics transitioning to gdau or trying to write trying to learn the basics and Beyond of tutorial and then I created a simple tutorials I really didn't like the tutorials for fun until I inevitably tutorials suffer from the blind leading ultim just went with the flow of ultimately I didn't have much drive or ultimately it was my extensive portfolio undergrad this isn't a race after all understand them is a necessary skill understanding and competency of the unfortunately Graphics programming is unfortunately I had to do 2 years of Cs unfortunately once we graduated we all unfortunately the really really uninspired male teenager does and unity I soon learned just how much math unity's scriptable render pipelines to unreal because it is a complete package unreal is all about using their tools unreal or Unity then the graphics engine unreal's source code or extending valuable by the industry technical version of processing I remember quite very academic subjects and I would very few articles and videos exist to video are all personal limit tests of video game photography To Me video games videos I have read probably over a 100 views and well we all know what happened visualizing a mantle convection visuals the terrain was beautiful and want to be a technical artist or a wanted and comparing our skills to the wanted to do whatever it is that could wanted to work in games though so I kept wants the university Graphics course wants you to know how to use I also was around spring 2019 when I was was effectively on the path to become a was even a thing and just how far away I was from ever achieving the goal of was seeing math applied creatively for was so small that there wasn't any kinds watching it live with my best friend the web developer and the fun times of p5js weekend implementing the world's worst well as a skill that nerds were all taking part in the concept was what I wanted to do at the school and what I wanted which was to apply what doesn't the more you experiment the what little math and programming skills whatever my friends were doing and where the true Terror and frustration of where you have finished these things where you write code with a graphics API whether or not it's worth it is up to whether that is building on a which I recommend everyone procures a which engine is best to start with if which is what I do for my videos Also to while going to school fulltime and while my friends spread across the whim because its creative problem will be exceptions everywhere I'm trying will be immensely more complex than some will discover things you want to learn with a computer and I did have at least with a video put together by my with compute shaders complex GPU with lessons that fit your interests and with shaders in some way I would be with something pretty important am I with the engines at a higher level to wonderful new early college program they work on your portfolio is incredibly working to pay for school I started with would be spent on building those would completely neglect my schooling in would cover more diploma credits 2 years years early to super senior in my years of sacrificing all my free time to you but for me I could not be happier you can take as long as you want to get you do anyone can do the tutorials you even if you don't know where to you graphics and if you decide in the you might think people who can read you shouldn't feel bad if it takes you you want an example beginner project my you want to be a graphics programmer I you're playing an RPG you don't start you're screwed because all of your you've absorbed the basics of shaders you've learned the rendering Pipeline your own Graphics engine if you have your time was spent on the college"
  },
  {
    "video_id": "PDd5GQnjR44",
    "title": "How Do Computers Produce Random Numbers?",
    "publish_date": "2021-10-08T17:00:27Z",
    "comment_count": 0,
    "transcript_text": "1000 squaring that we get uh 2 gets put into the lcg as x of 0 32 bits and a little over 2 million for 64 bits and that sounds like a lot of [Music] [Music] [Music] [Music] a shirt as well which is it's pretty a signed copy of a times x of n plus c mod m a very big inspiration for me tech art additionally i like my random numbers in additionally lcgs aren't very suitable again i'd play it for you but you know and check out my other social media as and get the result uh [\u00a0__\u00a0] seventy three and if you care about generating random and if you'd like to see the code for and now you can realize why this method and the art of death stranding which is another in between video anything more this is known as anyways anyways let's take a look at a prng anyways that's all folks i hope this applicable in the real world you may be aren't without their weaknesses lcgs as another example we can use the seed as we can see there is a relatively as well as um as white noise and this relation will as you can see lcgs are very nice and bakumanagatari basketball or watch it for that matter i because of how color works become more obvious in future videos in becomes obvious when we visualize the before we return the number to be used begin to crumble once they are used on a bookstore both the random number and the new seed but anyways i'm here staying in the uh but anyways thanks for watching this but first let's establish some aspects but having this random number generator but i actually just got back from the but i'm headed back tomorrow so but this one ain't it but you know how youtube is by the lcg with little to no bias by utilizing a discontinuous piecewise c is a constant incrementer and m is a call it you then square this number and care to keep developing prngs as the colors and in the case of the television comes a random result completely deterministic complicated but it just means a line computers are stupid they do only constant that modulates the resulting cool looking i think curry do delve into large scale monte carlo depending on implementation but they despite everything uh it's actually deterministic because of the seed the deterministic behavior a system in which digits so we prepend a zero to this and direction hence why we could refer to it do was make a video enter equal distribution of numbers produced essentially no memory as all they need ever used or looked at electronically exactly what we tell them to do and only excuse me first prng was invented by the man five hundred and eighty we square that for about a thousand random numbers and for example take the seed eight thousand for generating fake random numbers which for generating random numbers [\u00a0__\u00a0] for on gpu random number generating as for short are deterministic algorithms for the next iteration of the lcg and for the next prng output also for us if they did anything else or foundation for a lot of amazing four hundred and eleven and modulated by four hundred and fifty six frequencies at once frequencies on its screen from the concert i got gave me generated systems can be completely generator it is generating the full generator or lcg for short the lcg works get our random number and the next seed goal is for the most part hash functions personally i use the the have a great rest of your day thanks for he knew this of course he just didn't he proposed the use of the middle square here in this hotel room here's a quick list of applications for hey everyone and welcome to a new video hey everyone uh himself john von neumann in 1949 his needs history hopefully how can you do that when computers are how deterministic machines can fake how youtube is hundred and taking the middle digits we hundred thousand generated numbers and i also got some i also went to a uh blazers game i did most of the work for this video i don't really know what this is i guess i got uh the first volume of the i guess i'll figure out what to do for i hope it's there i was locked in a room and all i could i'll play some uh some clips that i i'm here for a concert i'm seeing tennis if the squared number has an odd number if you haven't already subscribe below if you need me to explain to you why in this first video we'll be looking at incremented by twenty eight thousand integer or seed as the tech bros like to interesting results of procedurally introduce to you in later videos it it is a very it is visualizing the combination of all it was pretty good it was uh blazers versus golden state it it's in the description below it's pretty cool i'd play the song for it's pretty good you should listen to it just got invited to the show known as the linear congruential lcg we created earlier as a texture like most computer science concepts the linear function which sounds really little like blog section i'm just bored lyrics to this song are like painted on make sense in a little bit manga which is pretty cool many derivatives as well as how it is matter of semantics and context mcminnamon's hotel in portland method it starts by taking an initial middle square method middle square method was sufficient for million six hundred and sixteen thousand modern pseudo-random number generator modern woman modern women multiplied by 8121 my my main project is in the mail no randomness or variance is involved noise is used to refer to variance and non-deterministic outcomes not all prngs are the same but their not the pride of your friend group but now you might be thinking why is this number number a is a multiplier constant of the number generators and that's a great number into a given period numbers on the gpu you should look into of digits you can just prepend a zero to of prngs that we went over with the of the their newest final because i oh okay okay with a little history out of the on my laptop so one hundred and thirty four thousand one million which has an odd number of one of every vinyl one range without any patterns or or a not so new video if you're watching or white noise is a very important otherwise our random number and next seed which is pickups stayed in powell's which is like a really famous pretty cool this is the room that the previous random number or initial seed prngs taken a seed to set the stage for pseudo-random number generators or prngs quality of the lcg so i stole the values question honestly i don't really know random number generator random numbers are impressive or range range of random numbers in the zero to recorded my favorite song by then recreated with the same seed recursive relation x of n plus 1 equals regardless of what you think of the game rest of your day and i'll see you next same seed will have the same result samples but it's really not when you silver sun simple they are extremely fast and use simulations so so hopefully it's as good as my other so i'll be going over one prng in this so you can see when i post new videos some like art books and stuff at some sense of randomness in our system some things i don't know i don't play sounds really weird at first but it'll spent so much money that she felt bad it start of a new series on noise and its state which isn't possible on the gpu stochasticism in the graphics world as sucks suitably random i have plotted one techniques and graphics that i will television without a signal is tennis concert that as it would be rather inconvenient that fortran and matlab use for their that is not continuous that's a the the art of the last of us too the art of the the first first game the exact answer other than it's just a the generator is defined by the the hardware for the lady at the merch stand she actually the lcg kind of requires you to maintain the pop band the pseudo-random number generator the quality is really bad the range of 0 to 1 so we can divide the resulting random numbers the prng is the series the uh the values you decide to use for each of the walls then we take the middle digits to get these parameters will wildly change the they played the song lazy eye so all of this this entire result by m to get that this image looks like a television this in the future today's video is the this is actually very useful behavior as this is like a blog i'm recording this this is referred to as white noise this poses a problem when we do want this result isn't actually random at all this result then becomes the new seed this would be it though of course it's entirely time to demonstrate that this lcg is in fact to illustrate how the lcg works let's to maintain state is 32 or 64 bits tying this back to our random number uh uh she also um use the middle digits of the result as use the seed 2 since it's the coolest used in pretty much everything you have very impressive game visually i also got very large scale they are only suitable video and series is as interesting to video and then you can pretend they all video called noise and not pseudo random videos i don't know i guess it's like if visualizing the full range of von neumann got a lot of things right was pretty cool got to see uh steph was really cool watching way we can move on to an actual real we divide it into the zero to one range well as data collection this association well but i gotta go now so have a great well she didn't give me this i bought what operates on this seed and then out where x of n plus 1 is the next random which um which would be 6165. white light is the combination of all wise without a signal and that's because a work that way but first a little bit of you you as it is to me you uh zero zor shift algorithm"
  },
  {
    "video_id": "PH9q0HNBjT4",
    "title": "How Games Fake Water",
    "publish_date": "2023-07-24T22:50:06Z",
    "comment_count": 0,
    "transcript_text": "0.82 then on the next iteration of our 1 of the first edition of GPU gems 1977 in fact the combination of the Baseline it's perfect for small bodies Box off the internet to get a better Brilliance math lessons to Brownian motion Brownian motion is the Brownian motion allows us to easily Calculus our normals are now exact not Channel I'm building a Lego typewriter GPU to do our displacement for us in the Gamers love to complain about Bloom Graphics programmer I dreamed of Graphics we have three General options I forgot the reflections the appearance I guess that works I love water 23 years ago I was born in I'll be making use of a much simpler Lambert and his book photometria hence Lambert's cosine law this concept was Legends Arceus and even Elden ring we Loop we use the new frequency and Ray tracing gives perfect Reflections Reflections can only reflect what is Reflections on the Water by calculating Reflections wait what is a cube map a Reflections where we make use of cube Shader is responsible for outputting the Taco Bell 21 times a week also I'm Vector which points at the pixel we want Vector with the surface normal we'll be [Music] about 3D over in unity I have a simple account fresnel describes the accumulation from falling rain and accuracy of our normals is limited by accurate rain splash physics then I add it to a different sum just like adding more waves leads to some very aesthetic of rainy weather and flooding ago so I've been taking advantage of algorithms in graphics fractional all hate to see in games like Pokemon all of the work for us and it's very all sorts of directions after hitting a all together there's infinitely many almost entirely composed of Reflections almost like the waves are pushing each always look good normally I'd say this amplitude and frequency of one and a amplitude by a number less than one like amplitude for the next wave that has a amplitude of a basic wave is 1 we can an approximation and we're doing half an impact at higher wave counts in order and Brilliant will match you with and the answer is usually no anyways the and the binormal is the tangent line on and z axes but why would we estimate the angle between them and if that angle is angle this means that if we take the dot animated with the vertex Shader doing animation The Horizon cutoff on the animation we get with just four waves we another video if you would like to any given point on the surface of our any modification we make to our sine anything better Central difference has a appreciate that a lot be sure to try out are reflections then intuitively the are using the camera's view direction to are viewing the water from since these aren't pre-computing our sum of signs as calculating normals through Central as easily like I have so expertly done as many waves as we want but eventually as the blinfong specular proposed in as you can see we have sharper Peaks and ask you to draw in the shading then it asking myself the question if I saw it asset is finished now it's time to make avoid the use of the word partial basic sum of signs but at higher wave be sent to the next stages of the render beautiful environment Reflections the beautiful environment Reflections wait a because most of the time you can't do because there's no sun to go with them because we aren't taking fresnel into because we still need to implement the been approximating the partial been decided you'll be able to vote on behind the water rendering of most of being entirely random there's some best way to learn math data science and better but it's not quite correct yet better then they look convincing so I'm between 0 and 1 that describes how between its Peaks the peak value of the between the view and light vectors if we between two different values this is between zero and one and if we consider binormal the tangent Vector is the blue wow look at that beautiful water bright but it doesn't feel bright so bright the point on the surface of the brilliant has something for you don't brilliant hello everyone well I'm all but I'm personally not a fan of them as but Mr what about the normal vectors for but if fluid simulation is too expensive but it makes a huge difference our water but it's extremely expensive and I'm but my last math class was four years but now unlike before we are going to but people are very bad at identifying calculate a normal Vector we need two calculate how the light interacts with calculate our Central difference we need calculate the sum of signs on each calculated the lamp version diffuse calculating the slopes with the usual calculation that is the core of every calculus there are lesson plans let you can already see some convincing can remedy the repetition by adding more can use calculus to find the exact case by calculating a halfway Vector cheap and effective you might ask the check out my patreon all my patrons get cinematic tone mapper to bring our clamp the cosine value to zero because color of the Water by multiplying the commonly used in most games today screen complete the scene with some calming completely ruins the visuals instead complicate our derivative a bit more but computer science interactively brilliant construct our tangent and binormal contrast at the same time we finish up control how detailed we want our water control the size of the Peaks without convincingly realistic looking surface coordinate with a wavelength of one our cosine of the angle between the two cosine to get the partial derivative we counts we have very fine details with create a bunch of them and then add them create our Pixel Perfect normal vectors creating my own real-time fluid crucial component the phase at the cube map is a combination of six currently on screen so if something that customizes content to fit what you need derivative but that's exactly what we've derivatives of our Point since the details but will have less and less of developer you should start learning to difference it's a very common technique different textures projected onto the diffuse term with any color we want like direction of the light source and the direction of the surface also known as distance fog post process we attenuate do this the old-fashioned way by do wonders for our water because of the does this work if you recall from doesn't look like water at all that's domain warping while we're summing our dot product of our view Vector with the drawback is that it's expensive if we each other for simplicity's sake we each time these higher frequencies are earlier the dot product of two easily change it to whatever we want by educational Journey brilliant is the effectively white noise that happens to enough to have a formal math education equation that the secrets of water equation the sharper Peaks are equations I could show on the screen equations really do have hands and that eventually this means that you should every frame but for a plan with this every pixel of our water resulting in everything brilliant has to offer with a exact function for once this means we example and multiply the current executed on every single vertex of its exponent on our DOT product this model extra times to get our neighboring fairly self-explanatory it's a it's a far I have been using the word slope to far the worst image effect that is fast too especially when you compare it fear of it accidentally ruining the finicky meaning it's easy to create a first programmable stage of the fluid-like movements in 2D but what for Reflections the first is Ray tracing for finalizing per vertex data that will for games then how is everyone rendering for specular highlights is the most forward slash Ace roller or click the fractional Brownian motion is the secret fractional Brownian motion on the other free 30-day trial and 20 off an annual free and easy way to get started on your frequency and speed we begin to see some frequency but with a smaller amplitude frequency by taking the quotient of 2 frequency it is with this basic wave fresnel which looks like this I'm not from Final Fantasy 16 which came out from earlier is take the dot product of from the cube map our Skybox is a cube from the dreaded tiling patterns that we from this that we could Intuit that functionality we're interested in for games used for a very very long time getting somewhere the sum of signs is given our specular highlights but why go at your own pace and I'm the kind of going to be the source of our finer going to explain the math but basically grazing angle the reflectance is very great here but if we want to model waves great rest of your day and I'll see you hand is very similar but instead of have any Ray tracing Hardware so clearly have our CPU iterate through every held back by our lighting instead we high this phenomenon also applies to hits a surface some of it reflects light idea you could possibly have instead if you are looking at something at a if you have any questions about the if you're looking down on something then immediately makes our water look much immediately pretty obvious and add some in a game what I think it's realistic in motion since we are summing up bunch in my demonstration other games like sea in order to create the illusion of in order to move our wave forward in the end the sum of signs or a in the third grade this method is known in the x and z directions we can easily incidence and the strength of the increase the size of our water we set interesting happens but if we add a wave into a texture then in order to into your eyes are not just annoying introduced back in 1760 by Johann introductory lighting model for inversion diffuse imagine we have a is also equal to 2 over the wavelength is being reflected moves out of view the is boring but many waves now we're is completely random at the moment our is it actually realistic no not at all is screen space Reflections this is by is the best we can do but for once is why I'm excited to tell you about a is zero and will give us negative one if issue if we want more detailed water it exhibits very little reflectance but it immediately destroys the visuals of it look cool a large body of water it look more like atmospheric scattering it to a sum calculate the derivative and it turns out that the derivative of a it's a total win-win we can change the iteratively adding a wave of higher just a few weeks ago just calculate the derivative of each just one piece of the lighting puzzle it just take a quick quiz when you sign up kind of wave we could use cosine if we know what your skill level is brilliant known as Portland Oregon Portland lambertian diffuse and the blinfong last thing we can do to improve our learn to program a graphics you've got lessons that fit your interests and let's add a bloom pass the bloom pass level of expertise I was privileged light value is the most basic and like I said earlier a normal Vector is a like water the lambertian diffuse is like water when it comes to real-time link in the description thanks so much lit and the points that point opposite looking Sky the Skybox is going to do love the sine wave thankfully they're making use of a technique called the sum many vertices that's perhaps the worst map composed of these six textures we maps to store environment data which we matter what point in time we sample our memory to the process it's kind of hard mesh the vertex Shader is responsible models the light that is scattered in modern era the sum of science method modifications to the sine wave the sum moment we can't animate anything with more interesting patterns the more waves more stylized look that's similar to the most familiar with is the gersner wave motion blur and other effects but what moving clouds the sun is supposed to be much higher reflectance when viewed at much more sophisticated fluid simulation multiply the cosine by the direction of multiply the current frequency by a multiplying The Wave by the maximum multiplying it with our positional multiplying your speculars by fresnel near grazing angles this is something need to bring our water animation to the need to convert it to frequency which is negative light doesn't exist but how do new random direction we can do this for next time nice detail to the water but our sum of normal sum of signs the fractional normal textures we use a directional normalized vectors is the cosine of the now all we have to do if you remember now let's make the water actually look now when you see it you can point and number greater than one like 1.18 for number of drawbacks though for one the object the object's vertex Shader is ocean ambiance of 1 when the angle between the vectors of Thieves have remedied this issue with of extra work to get a normal Vector of fresnel for real time is the Slick of our wave function we can then control of random signals to create what is of signs GPU gems tells us that one wave of signs in reality is just a sum of any of sine's height map and then of the previous wave that way it's of the vectors magnitudes times the of them and if you're an aspiring game of this technique is that It suffers of water especially still water is of water or Coastal views where the of water that are not that turbulent of you will go oh the unfortunate truth offers thousands of lessons from basic okay where was I the Skybox is going to on our water we know it's normal Vector one step closer to looking like actual only use this approach for small bodies option is screen space Reflections order to fix this we're going to make order to get a desired wavelength we orthogonal to the surface we can see other around it's a very simple change other vectors the tangent and the our desired speed by 2 over the our effects with a subtle and yet and our normal Vector with the direction of our sun and we have successfully our wave because it's not going anywhere out of video ideas so let's consult the over the desired wavelength and oxymoron unfortunately for me I'll parameters of the gersner wave are very partial derivatives of our water for a peaks of a wave is known as its people lack an intuitive understanding person that has to read something 20 physically based Shader the lamb physically based rendering which video pipeline as you can see our mesh is now pipeline the pixel Shader the pixel pipeline which includes finalizing the pixel Shader is returning white for pixel color on the screen right now our pixel perfect normals by making use of plan when you visit brilliant.org plane composed of many vertices in order player is unable to see the repetition points that point somewhat away are less position of our vertices this is the precise normals that makes for a presented in GPU gems is a great probably die before large-scale product of our light Direction and product of two vectors we can see that product output of 1 meaning a full programmer pushes our render into HDR we can use a question how can you say something like question how do I become a graphics question where are the normal vectors random direction we sample our wave add random light interactions around me and rays from a source that reflect directly re-familiarize myself with the basics of reaches for most often when trying to real-life waves we need to make some real-time fluid simulation is possible real-time fluid simulator is a bit of an realism myself included which is why I realized that partial differential receives lots of rainfall so the reducing the amplitudes of every wave in reflection Vector from the light source reflection Vector of the light Direction reflection disappears here's an example reflection essentially surfaces exhibit relationship between the angle of rendering are revealed to us in chapter rendering pipeline the vertex Shader repeats every second this is our core requires a large plane so let's heavily right now but let's start with the basic rise over run formula that you learned same wave together nothing that sample it we can then very easily render samples so basically we're doing a lot sampling neighboring points in our sum sampling our wave at by the derivative say wow fresnel a decent approximation scattered off the surface conveniently second second major stage of the rendering second thankfully we can get our waves second variable and add it to the inside send it off to the rest of the render sharper Peaks the one you are probably sides of a cube instead of using signs is suffering from one other major simulator with legitimate fluid single wave the derivative of sine is slope when we could just calculate it so so adding more waves won't do much so all that's left is the cosine of the sorry for ruining it for all of you the source and we also know the direction we space Reflections are a complete and specular Reflections so how would we add specular Reflections so make sure you're specular along with a constant ambient specular highlight should be strongest specular highlights to appealing colors speed as a phase constant we multiply spend 75 percent of my time staring at sphere should be and we have sphere with a light shining on it if I start with a big wave and we are started learning math or brushing up on static Skybox looks weird we can animate still working on a 1660 which doesn't streaming right now over on my twitch streets is something my daydreaming mind strength reflection we can then control successfully derived what's known as sum is the sum of the derivatives so we sum of signs could be considered brownie sum of sine waves if we add two of the sun Direction and additively blending it support me and keep the channel going surface at any given point in order to surface but there's one more important surface normal are normalized vectors surface normal we are given a value surface of our water is defined by an tangent line of the point on the x-axis techniques let's for another time in term we use to describe a movement that that the greater the angle between these that with such certainty well if I lift that's all from me I hope you have a that's an approximation and doesn't that's not the case in fact we can get that's precisely the point though we that's to be expected with our new wave the UVS and blend the Skybox with itself the Z axis the cross product of these the ambient light diffused light and the amplitude is going to approach zero the camera up above the water then all the cosine function will give us a value the distance fog based on height to make the distance of our samples another the dot product is equal to the product the dregs of the United States also the easiest way to do this would be to the faster the signal will repeat in the game this is because screen space the games that you play because it's the next one as always a huge thank you the only reason they are used is because the patterns will always repeat the points on the sphere that point the power of calculus as a quick recap the rate at which a wave repeats every the reflected Vector from the camera and the size of our highlights by putting an the speed of our Wave by expressing the sum of signs what a great question the surface normal a vector that is the vectors are pointing opposite from the water we have our vertex Shader the wave and the axis we want then we the work so we are using less resources the x-axis to be time then our wave their magnitudes are both equal to one their water if you went to school then them and it's really easy to break them them to our watersheder imagine a point then our speed parameter is in terms of then sample from to determine our then take the dot product of the halfway then their halfway Vector will be equal then we need to add more waves but then we spend the next hour fiddling there is a relationship between the these specular highlights look unnatural they are also referred to formally as they are really hard to work with they repeatedly move back and forth they should really be complaining about they're overly complicated and the they're the cheapest option by a very thing that happens when the light Ray third and final option is image based this formless white blob to give our this option is not valid the second this video has been sponsored by though because if we go back to our three years ago when I was a fledgling through Central difference which means through time we need to add time as a time variable since the waves frequency times over to understand it so I to Advanced so if you're just getting to a wave with different amplitude to all of my existing patrons without to be at lower wave counts we have a to brilliant for sponsoring this video to explain so let's just get into how it to get our partial derivatives with to get our tangent and binormal vectors to learn how to program in general which to prevent complete chaos like with our to recalculate the sum of signs four to see our waves we need to displace the to the light are fully in Shadow it's to the surface normal giving us a DOT to us game developers without one more to vote on the next video topic and tones total sham they are extremely towards the light are fully lit the two vectors produces the normal Vector two vectors the less the light is two-dimensional UV coordinates like ugly visuals without compensating by unnatural the basic sine wave works unrealistic and if you know how to break use of one of the most important useful since we know for sure that no using that to sample our Skybox this vaguely look like fluid movement value we desire the distance between two values back down to get some beautiful variation of the sine wave where the variations of the sine wave to give it vector that points orthogonal to the vectors and take the cross product to vectors since our light Direction and vertex displace it accordingly and then vertex of the mesh updating its position vertices according to the sum of signs very simple sine waves are oscillators video come hang out and chat anyways view direction is the same as the visually construct an interesting scene visuals like gerstner waves this does wanted to it really doesn't matter so water animation is something called water but at this point we're no longer water everyone loves water especially me water form and detail we need to water looks ugly we fix it by applying a water there are many intimidating water wave to have and we can easily water you might start asking the wave and add it to a sum as we go along wave equation but it's not very useful wave is known as its amplitude since the wave is the exponent on Euler's number wave it will always be somewhere in wave now completes a full repetition in wave that curls in on on itself which wave the behavior Remains the Same we wavelength and then multiply it with our wavelength the shorter the wavelength waves but because waves are oscillators waves we can push the position we are we add together the more detailed of an we are creating our normal vectors we are estimating the slope along the x we can create a fake Sun by taking the we can very easily tell if this is the we get the angle between the vectors if we know the direction of our light we look at the equation for the dot we need to find the slope of our point we'll Leverage The immense power of the we've already gotten ahead of ourselves we've been doing for our sum of signs well hold your horses partner before you well-known and most common method known when our view Vector aligns with the when the CPU tells the GPU to draw an where too much detail would look while the next video topic has already why we call it the lambertian diffuse wide margin and if you don't know any wider troughs like you would expect a with sharper Peaks like that of with specular highlights our water is with the CPU approach but Ace roller it with the source then we can find a Sky with the water parameters to get a nice without them our water won't really look wonders for our water because of the works we start with a wave with an would probably look something like this you know many Ace roller viewers ask the you know what a sine wave is but many you observe every day of your life but your linear algebra for shaders your support I would not be able to eat zero then cosine outputs a one if the"
  },
  {
    "video_id": "PNvlqsXdQic",
    "title": "What I Did To Optimize My Game's Grass",
    "publish_date": "2022-01-22T01:00:14Z",
    "comment_count": 0,
    "transcript_text": "256 b 300 meters squared the same as our 408 megabytes of ram which is nearly [Music] [Music] a complete field but what if we had a look at this square with an area of a total of 25 we are now able to expand accordingly amount of culling we would need to do an average of about 64 fps at full and i'll see you next time and then both of those buffers would as i mentioned in nearly all my videos be that easy in order to get the same being highly performant but as it stands blade costs us 28 bytes that's not a buffer of grass cover this up it would but for now i'll be putting the project calculation and some tinkering on the certain distance from the camera this of chunking a concept mostly everyone chunks in this case it is 5 per axis for chunks then we would need to have two code to keep track of multiple buffers coincidentally i went over how to cover colored all of the low detail grass pure compacted visible grass blades end up so consumed by the grass this doesn't seem cooling only works on up to 262 000 copy of this buffer which is where our course looks really ugly but it reduces covering a 32 by 32 meter plane so how creating a full video game decent increase the last optimization i definitely more i could do to optimize density did you really believe it would did you do it difference here is a picture of the distance is greater than an arbitrary divide up this square evenly and have do we fix this well each blade of grass holds its position either way there are actually 7.3 enabled to prove it's working i have everything has a cost every line of code for high detail and one for low detail for your program to execute and every game of the year 2017 the legend of gigs of that so around eight percent of grass blades which is not nearly enough grass far away is barely visible but grass positions that is contiguous in grass with no level of detail and here half a gig this wouldn't be a huge deal has like 16 gigs of ram nowadays but have to do any work at all to get this hello everyone and welcome back to a new here to show you that there's no visual higher detail model i reduced the total hope you have a great rest of your day hundred and seventy six or a d none of i also took the time to optimize the i went into maya and i put together a if this was on the cpu since everyone if we visualize the chunks of grass in if you picked answer d you're correct or image texture covering up space we need in reality you'd probably never need in total this field of grass costs us in view and updates the buffers in view this process executes every is a picture with the level of detail is four bytes of memory so each grass it dense enough we can just up our it further its world space uv coordinates and its large converting that number to let's start with a multiple choice like a whole lot but when it comes to little grass blade model without the made was cutting off the grass at a massive success of minecraft a game in megabytes but wait we actually have a megabytes our grass buffer costs us 204 memory and only includes grass that is million blades of grass in the field missing grass in the distance our final model instead if we didn't have the multiple buffers of grass we could my total gpu's resources are being need a lower poly grass blade model i need to be cold which is twice the need to do is check the distance between not be nearly dense enough to look like number by 7.3 million it gets quite object you instantiate will take up some of 82 fps which isn't as much as i of around 100 running on my 1660. of course the result is a buffer of of grass as large as we could ever want of memory of these problems at the same time take of your finite memory i've already shown on each buffer and the result is an area on the position of the camera there's on this topic our goal today is getting on to implementing level of detail in one buffer of grass positions for each one million forty eight thousand five order for level of detail to work we original billboard grass and we find our field contain is it a our grass field now looks like so our grass field to the area of the our performance increases to an average our shader we can see that the field is per frame so the chunks really saved us performance increase anyways we don't performance lands us at an average fps performance this new grass is only piece we then run our culling algorithm point numbers per grass blade each float previously on the grass diaries ace properly divided into any number of question how many blades of grass does red regardless of view distance even the render but what about the memory cost resolution but this fluctuates depending rolla this looks absolutely nothing like separate position buffers of grass one should be familiar with due to the should probably definitely go watch single frame to calculate which grass is something to consider lest you run out still a lot more we can do so let's move target area while we could have a single thank you with fog applied to hide the that it actually works quite well i get that it was reasonably possible to cover that you can't call me a fraud there's the above the amount of grass being rendered the area in my first grass video such the camera and a given chunk and if that the grass we created in the last video the memory cost of your assets is this data exists on the gpu so it's this means that there are seven floating this method of data division is known as this much grass this was merely to prove this up with my last video which you thought it would be but it's still a three hundred and eighty four c threshold then we draw the low poly to cover any area we want additionally to cover any area we want while still to draw a lot more grass blades to make to rest thanks for watching everyone i using up vram and my gpu only has six values though and we achieve the desired vertical displacement from the ground vertices by 6 to get an additional video and what i hope is the last video we have two main problems our gpu we use the same grass blade model well it's the exact same which is great went into maya and modified the model we were using to be just a single triangle what did it cost what if i told you we could solve both which the chunks are extremely obvious whole lot but when you multiply that with doctorate thesis level algorithms with some changes to position with the level of detail optimization working because of the chunks all we yes you saw my twitter thread you the time it takes for the grass to you write increases the time it takes zelda breath of the wild you lied to us"
  },
  {
    "video_id": "QfMcsvuXdyU",
    "title": "I Stopped Twitch Backseaters",
    "publish_date": "2021-08-26T23:53:41Z",
    "comment_count": 0,
    "transcript_text": "[Music] [Music] [Music] a good runner-up since a more complicated example is this a move is denoted by the name of the a regular expression is a sequence of a saturday night the hour before he actually be used or help with anything actually please subscribe even if you do advertising hardcore gambling to all right boys i'm done i'm not gonna all right unscripted acerola here giving alright so now that we can detect a also i did notice that her mods do time and and another that detects common backseat and before an uppercase letter and i would show you in action but and preventing a situation like this and so on and the question mark means it'll still and to show it off in action the bot and to show this in action my bot is and understand if you didn't write the and usually terrible moves suggested by and when checking a message for and with this our bot knows whenever a and x if it captured a piece on that anytime the twitch bot would find a are an absolute sack of [\u00a0__\u00a0] whenever i are better at the game in this video as chess move notation has many as i stream every monday at 5 pm pst backseat messages follow certain backseat messages that were flagged backseater and at that exact moment you backseaters in his chat that think they backseating i have arbitrarily decided backseating keywords the second list is backseating the streamer or not because i've been waiting for ludwig to being recorded on a camera boot this game up bot i'm pretty happy with it bot on his chat but unfortunately he bot when a moderator times out their but but anyways these are the results of the but how do we get the bot to see what but i've gotta go now so thank you for but it was a fun side project that i but it'll ignore anything else but only if they occur directly after a but unfortunately her chat is much nicer but unfortunately the average chessback but was it fun can easily articulate with a regular characters that specifies a search chat chat chat that says ping and it will respond check out the stream if you want to find chess notation or algebraic notation is children viewers can interact with the cinderella's chat who i thought would be coming weeks counter-intuitive current project which you'll have to currently looking for any message in my cutie decided to practice chess on his twitch defines a word boundary the brackets describing moves in a game of chess detect any chest move in a string but detecting messages with bad words and different variations but it still divided by two is what like 146 do look like actual chess move don't know twitch is a website where during like a three hour chess stream by eight but this must be present in the explaining what back seating is expression expression for matching algebraic expressions are perfect for this problem first follows a specific set of rules that we for capturing so that it'll still match from backseating chess streamers but from happening again game in the chat which seems kind of going to be trendy for a bit in the good luck cutie and e4 that's not how handler that will trigger whenever a have played knight b6 bro no one asked her name is spelled here is a chess notation if it's present here than there would be in ludwig's hey everyone and welcome back to a new i i forgot why i quit and it's because i mean scrolling through a lot of them i think the bot is identifying which messages are if the message has been determined to be if there's an x there if there's like two a's in a row then it if you do watch twitch you can check out if you don't watch twitch please in a streamer room in the late hours of in his demeanor in specific twitch channel chats in three seconds from now he will read instead i'll show you some results since is a backseating message is a line actually it's not a line is automatic moderation of chat by is not a match and this pattern will now it onto the expression it would say who the user was it's super easy to read and understand just hasn't streamed chess in like two keywords such as these know it is what it is ludwig is aware that his actions are made a twitch bot that prevents people match if nothing is there which covers means one of anything in the list message appears message from appearing in chat message i'm not sure what's going on message is message is sent in chat it knows what message it would output it to this file messages are actually being sent in the messages themselves if programmed to mostly anything from softcore porn to my twitch channel at twitch.tv forward no notation notation notation this looks like so when we tack now we need to match the chest tile of messages that would be flagged for one piece name and one backseat keyword one thing that was really funny is that or more of those shorthand piece names or not etc out for this which is unintended but you out people who are backseating so a lot out what it is pattern pattern that i stole from wikipedia pattern yourself but a simple example is patterns and a method for matching patterns and strings is known as a people can stream themselves doing people really like backseating women period piece names and their plural component piece names and then this list right piece the square it moved to pieces play any more chess on stream you guys pogchamps 4. prevents any and all discussion of the provided by twitch the username of your quite the success here r or nothing if it's a pawn reaction to the ignorant unintelligent really cool looking at the same time regular expression or regex for short regular expressions one that detects responding to certain chat commands so right now i'm streaming progress on my scrolling down to the bottom here 292 seeder isn't actually smart enough to sent by a backseater the bot will then sent in our chat we can work on sent that message if they're a moderator slash acerola underscore t so so in regex speak we want to match zero so instead i used the bot on cutie so now that we know what messages are so on that one boys it would come as no so the bot would have timed the person so there's fewer backseater messages so this arrow jurican guy said knight e4 so this is why i've added two other some reason don't get picked up by the square stream chess again so i could run the stream for the upcoming chess tournament streamer by typing in the chat and a streamer yet string in order for it to be proper string that contains the word pain subscribe down below so you can know suggestions surprise that ludwig had a negative that any message that contains algebraic that this regex does that but regular that's easier to do as i'm not a large the bot flagged this message from a user the contents of the message is and what the context is the context being who the most common use for a twitch bot the one inside the curly brace means it the one word pattern that looks like the pawn case next we can tack on the x the shorthand for each piece is n b k q the standard method for recording and the words typed in chat by a chess there but either way these chat messages and also send they are notoriously difficult to read they want this is really cool and all this this is 26 year old ludwig ogren sitting this pattern will match any two spaces this pattern will return a match on any this requires an authentication token this video probably isn't that exciting tiles are in the range a to h and one to timeout the user and prevent their timing the user out as well as to begin constructing a regular to conclude do i think this bot will to connect to the twitch irc network took a long time to make this video traditional chess move in chat we can twitch account and the channels in which twitch allows bots running on a server twitch bot is a program that can monitor twitch shed is annoying twitch then provides us with an event two or more backseat keyword matches or understand algebraic notation video today i'll be talking about how i viewers can interact with the bot if wanted to make a video on since chess is watch twitch watching and have a great day we can start with the names of the we'll be solving the backseating problem weeks what is a twitch bot if you somehow what their message was and then what was flagged by the bot so the first when i release another video and whenever i send a chess move in the chat which is a bonus which lets us send and receive messages while it does stop backseaters it also will ignore anything else and it is also will only match one instance of this so will see a noticeably remarkable switch will throw a flag in my terminal with a little more confidence she could with pong within a word boundary the backslash b work on actually stopping backseaters yeah a little bit you you nobody asked bro you the results of the twitch bot you want to monitor"
  },
  {
    "video_id": "RnwPPHGMowI",
    "title": "Making A Vignette Shader",
    "publish_date": "2023-02-15T17:07:14Z",
    "comment_count": 0,
    "transcript_text": "applications as well if you're because the magnitude approaches 1 as it center it is if we multiply the coordinates and subtract 0.5 giving us a darken pixels on the edge of the screen desired effect vignetting is mainly used different ways a camera can cause a frame but it has many other artistic from the center we take the pixel's UV gets farther away from the center so if hello everyone vignetting is the how cameras work be sure to check out my interested in learning a bit more about magnitude of this Vector with our pixel not a real camera we have to fake it reduction of an image's brightness the image to the pixel the magnitude of this Vector tells us how far from the to direct attention to the center of the towards the peripheral there are many vector that points from the center of video on simulating depth of field vignette but since our game camera is we invert the magnitude then we get our we need to determine how far a pixel is we will get a reverse vignette this is with a Shader since we only want to"
  },
  {
    "video_id": "TIQsyZfdxUc",
    "title": "Making A Zoom Shader",
    "publish_date": "2022-11-19T22:14:44Z",
    "comment_count": 0,
    "transcript_text": "Transformations such as translating [Music] and allow you to zoom in and out and pan around the image you're editing anything greater than one will zoom out are the means by which we sample but how can we replicate this functionality in a Shader UV coordinates hello everyone editors like Photoshop image then it becomes obvious how any in the range 0 to 1 will zoom in while our image is sampled for zooming we want sampler State though as it will affect scaling or rotating what affects the way simple translation be mindful of your space as a rectangle that covers the textures if we imagine this coordinate then we can pan around by performing a to scale the coordinate space a scalar watching your output considerably thanks for"
  },
  {
    "video_id": "Y0Ko0kvwfgA",
    "title": "How Do Games Render So Much Grass?",
    "publish_date": "2021-12-11T01:00:16Z",
    "comment_count": 0,
    "transcript_text": "0 to 300 for both axes then we subtract 150 so it centers it over the origin and 2 million 160 000 triangles every frame [Music] [Music] a grass texture a problem a problem though and that's that this a square space of whatever size we'd acerola well stay tuned to find out across such a large area anyways so the actually just an image actually place it all over the plane so all the object mesh data that exists and all the work so you need a good grass along with the terrain our grass looks alright alright cool we have grass it all looks also calculate a new value that will amount of instructions in our vertex and amplitude even further amplitude in this amplitude then subtract from it based on an animation that looks like so an average frame rate of 500 fps this and forth with it and i think it already improves the and it's perfect for stuff like grass as and now our grass properly displaces and sixty thousand triangles which is and so on like in real life and video games grass is pretty animation grass is long and thin thus it animation in this context is going to animation we can improve the performance another optimization involves reducing appearance of the grass could also be appearance of this grass and remove this are rendering two million one hundred are what determines what our grass model artist as an asset but i had one last idea the as we've discussed in previous videos as well as allowing custom distance at 500 frames per second and now you may at twitch.tv forward slash acerola based level of detail cooling as basic idea here is that we're going to be asking yourself what's the technique become very yellow before we do any gpu instancing though believe me right now but this is 1.2 billboarding and billboard grass is the but anyways this is a problem that but i've never made a texture before but it has one major problem and that's case it's closer to the default color of cause only the tips of the grass to checking if a grass vertex is outside clumped together meaning that higher color of our grass is uncomfortably comes together in terms of visuals so communicating data is really costly we complexity of our vertex shader computationally than a full-on physics conclusion uh oh disclaimer i'm about to confidently talk about is reducing the context refers to the distance that the control how yellow the grass turns coordinates of our grass to uv coordinates such that they can sample cosine value and then we reduce the cpu day and i'll see you next time deal when we are looking away from all decided to use three demonstrated here dense enough so let's double the amount depth in my previous video dynamic description and if you liked this video detail in video games please go watch it directly into the gpu buffer and the cpu distance from the camera doesn't need to be tessellated at all doesn't need to do any copying at all don't even have four to work with since each grass object is three quads which earlier by 1 over whatever density we every single frame example expense of performance in my next video far as the cpu is aware feel right the catch here though is that fellas welcome to a new video or not a final fantasy 14 specifically the grass finalizes vertex positions so i can have first it's going to take a lot of grass foliage there's a reason it shows up forward to videos on that as well four million three hundred and twenty fragment shaders when we are frame our fragment shader executes even functions so by using a mess of trig funnel is going to clog it up further localized variants and also the future today we're talking about grass game has a fixed camera angle like age games render so much grass while still generated we can tell the gpu to gets copied from the cpu to the gpu gets processed by the gpu this mesh data got to go now have a great rest of your gpu instancing gpu itself doesn't technically exist as graphics programming because grass doesn't move with it yet which is grass in the vertex shader in the same grass is commonly composed of multiple grass is old or not grass model only has four vertices to grass model there's not much else to do grass object and there's 300 meters grass object every meter which is great grass object to get a random number grass object will sway from its original grass objects so obviously pushing grass positions and then ask the gpu to grass than the cpu can actually handle grass we made earlier is composed of grass will be grouped with higher grass grass would be even faster in that real happen in the vertex shader this is the happening on our terrain in fact it has its vertices displaced by a height having more than one frame per second height variance of the grass since here now if you look closely if you homogeneous it's boring to look at i how cool and calming i'm quite proud of i came up with several different ideas i'd appreciate if you subscribed and i'll be trying my hand at 3d modeling if you look down on the grass from above if you look for it you'll see it in if you recall from the beginning this if you'd like to check out the code for image texture i decided to paint my own important when it's present in a scene in cost using numbers from earlier we in particular though has been tried and instancing anything instantiated by the instantiate our grass our billboard instantiating this many meshes even just intersecting quads for my project i into a dense field of grass you may not involve level of detail we can cull is 12 vertices and six triangles per is susceptible to wind and it flows back is to just put more grass in isn't even realistically possible since isn't perfect but it is much cheaper issue that my billboard grass has the it it already is it doesn't need to exist on the cpu side it looks like it okay well here's a quick recap it wait what's that you actually want to it's hard to see but it removes the just as weird and the grass stands out just for the grass and currently we have keep that data on the gpu so we don't know how the animation works left a comment it means a lot but i've like for example 300 for our 300 by 300 like this so please don't laugh at me it link in the description streams on literally everywhere and i promise that little cube that functions as a player look back at our plane there's now one look like it's being blown around looks like this and when we apply it to luckily math provides us with map this is the plane that we'll be meter plane method called million animated grass meshes rendered millions of vertices into that gpu model however i please we have a bit of model reference modern foliage rendering techniques seek monday at 5 pm pst more natural now and is largely complete more than that by reducing the most of which i streamed live on twitch multiplying that position we calculated nearly every game that you play need grass to render the different grass need to copy it over every single frame new video if you're watching this in the none of this grass data exists on the normally in a given scene the cpu takes not present the environment just doesn't now before continuing now comes the hard part and that's now with this technique the texture does obvious in order to render grass you obviously we aren't going to simulate of empires 4 that's a recent example of grass objects this is attainable by of the grass little by little okay older grass is more yellow while the one instruction can scale considerably only the top two are gonna move the oscillators in the form of trig otherwise we compute the default cosine our billboard grass model the grass our texture how do we know though if overall billboard grass is an incredibly performance of our video game so how do performant and fast option for rendering pixels increase in height which will placing our grass on i also have a plane that we're rendering the grass on please let me know what you think about position each frame rather than having position finally we add this value to position over positions we are going to calculate the positions with a compute shader so that post-processing effects so please look pretty good and in the real world you project it's hard to find a good quite expensive and heavily affect the really comes together really really analyze it you may notice remind everyone that i am a technical rendering several of which we can just rendering techniques i mentioned earlier rendering two grass objects per meter shader executes that many times per shader in that level of detail video by shader thread which will be in the range shorter grass this animation obviously shoves it into this big old funnel that significantly improved with simple silly little 300 by 300 meter plane that simplex noise so that height variance is simulation of wind also that simulation since taller grass would realistically since the grass completely obscures it skew the grass back and forth to make it so we can use our height modifier we so we're going to use a very handy dandy some foliage to improve the overall squared this means that we are drawing stage of the rendering pipeline that starting point but with this it's pretty strength of this value as the grass take a look at this screenshot from take longer to swing back and forth next talk about something i've explained in taller grass is older than younger grass taller grass will sway further than the technique i'll be going over billboard that hash value is above a certain that it's not a 3d model at all and is that uses this technique i'm pretty sure that's about all for variants of the that's about it with these positions that's right this grass is in fact two the amount of tessellation that is the bottom two remain stationary and the cpu copy each individual grass's the dilemma though is that i wanted to the easiest optimizations to be made the first thing i did was add some the gpu modify vertices positions of a the grass the id hash to add local variance to the the last optimization that i can the local position of our top side the performance of our grass is already the position by one half the positions of the grass will go the positions we are creating will fill the same height map as the terrain mesh the same though and that's boring also the solution to this of course though the view of the camera or is a certain there's plenty of techniques for grass this frequency on grass that is taller this general technique is called this grass density looks nice to me so i this improves our performance a great this increases our fps a great deal this involves converting the world space this is the biggest bottleneck of all this is the part of the video where i this isn't actually a problem if your this project there's a link in the this technique is called gpu instancing though having a lot of one thing can be thought about this for a good while and thousand vertices meaning our vertex three meshes so this will result in three separate instancing calls taking a threshold we compute the cosine value throw into the trash as they are to begin we hash the instance id of the to cover this entire plane much more to put this all into perspective we are to set the scene i have here in unity a to simplify this let's flatten our plane to solve with more geometry at the top of has its vertices displaced the triangles that form a quad that samples true for decades um unacceptably bad one of these techniques underscore t unfortunately it doesn't look quite uniformity of the positions next i added unique to an individual object then if unrealistic but that matters to me less use that buffer to find the proper grass usually when you're getting started on a uv coordinates to interpolate the value with a parameterized frequency values and random numbers we end up with variance to the height of the grass with variance to the positions of the grass vertices scaled by the hash id for visual is a good deal visualize both old and young grass the wait what's that you don't want to watch want currently that's two so we multiply want to render hundreds of thousands of way we call triangles in the geometry we could create this massive buffer of we need to calculate some grass we square the cosine wave reduce its we take the thread id of our compute were using to cause height variance to what if we could conveniently when there's not enough grass it feels which i use to turn this vacant plane which is the biggest downside of gpu will look like let's start with an wind we're just going to fake it with a slightly faster frequency with our grass model complete we need to with this effect applied i think it all with this value we also use the vertical won't make my gpu suffer any more than work with that's not a lot even worse we world scenario this is nerd so if would never instantiate this much grass would not be possible at all without the you you don't care please skip ahead to the you might not notice it but when it's younger grass is more green or in our"
  },
  {
    "video_id": "Z_-am00EXIc",
    "title": "The Strange Graphics Of LETHAL COMPANY",
    "publish_date": "2024-01-19T15:23:03Z",
    "comment_count": 0,
    "transcript_text": "1-month trial thanks so much to 1080p I would render it some smaller 16x9 resolution so that it cleanly 180\u00b0 you might be wondering why the 2 released with terrible performance 860 x 520 not 1920 x 1080 like it should API calls which means about half the Advanced On Any Given topic skillshare Blurred helmet visor and will also Counterstrike 2 smoke grenades but first Deferred lighting pass executes all of Focus that's right depth of field lethal Gamer's favorite effect Bloom most I don't get paid nearly enough to Mega final pass called Uber post most of Native resolution for instance I'm at Shader and the frame finishes with Bloom Shader effects all day if we want Shader effects are extremely expensive Shader is in the hidden category so it Shader is posterization filter and it Shader so it ends up not being too a Shader effect this has the added a realistic way and then in a stylized a whole lot of final tweaks into one aberration Bloom application vignetting about those clouds up there oh that's across all disciplines like programming actually low quality it's not faked with actually see color gradients so colors all Gamers love to complain about bloom all the objects in the scene are drawn all the objects in view annoyingly Unity allowed values the more prominent the also why the game is so pixelated and amount of allowed colors to a much and meant to give the best visuals and of course its unique visual style and realistically liveit unity's and then composits the frame with the and we can see the details of each and another example of the bloom blobs anymore this capture takes nearly 20,000 anyways we can Theory craft about these applied before the frame is presented to applying a second layer of volumetric are not being compressed instead lethal aren't chronically online City skylines aren't enough colors to close the aren't even in view which should as a postprocess which answers one of as well as some final color Corrections assume the usual color Corrections like at meaning that the image gets warped atmospheric scattering simulation is back to lethal company if you're backend used by the recently based on the slashes for instance this be if it were rendering at my full be out of focus but since our game be used for realistic Graphics or that before and after though there's clearly before being upscaled to fit the screen beginning the frame starts with drawing being used here to reduce the amount of benefit of making the entire game bloom bleeds onto the Shadows here's bloom is fairly straightforward you blurred with unity's hdrp depth of field both in in the dungeon and on the buffer and one of the color buffer the but it seems to be that edges are only but no if you take a closer look you can but no it stands for geometry buffer but no matter what some quantization is but we don't only have Bloom here Unity by doubling up on their results first in calculating the local maximum contrast calculations immediately and write the camera is not a real camera or eyeball camera or even your real life eye would can use all the same assets like 3D city skylines 2 running so terribly the clearly only using the bloom post clearly worth it as lethal company makes code for all their shaders on GitHub colleagues tend to neglect be sure to color grading post exposure and Gamma come prepackaged with the unity engine comedy company is actually rendered at a very company is doing for one of the edge company is pulling a dastardly trick company is quantizing the volum El company let's start with a simple visual company makes use of unities of absurdly compelling and I hope it can serve as a completely reconstruct the frame by components or calculating some value composited with the image to create a compression artifacts become resulting contrast value is usually calculated controversial City skylines 2 if you correction lethal company is pretty could be a lot of different techniques could use to simulate camera or eyeball deferred forward rendering is how you deferred rendering which is why we are dense fog everything a short distance depending on the monitor you play with depth of field is calculated right after detections but it could technically be difference between neighboring pixels if different from a simple lambers diffuse do all the lighting and coloring does a full GPU memory dump so that we done with anything like color data the drawing edges based on depth and some drawn then Unity draws the Sky Box in during postprocessing we do all of our edges being detected for the effect but that is to be determined next effect that comes next might surprise effects this is surprisingly very useful either fully lit or fully in Shadow with else in view what is a Shader effect we endless but a big one is that lethal essentially this program captures all events to fully draw which is every one in addition Nvidia Insight everything in the Game Dev world has exaggerated but a Rolla what about those executing those same exact API calls in expensive depth of field Shader to blur exposure and Gamma but it's hard to say exposure and maybe the color grading to extremely cheap lowering the target faked but again lethal company gets away familiar with but don't worry everything figure out at least two things ourselves figure out what's going on ourselves but finished let's do a quick recap first first and then it gets stylized meaning first thing you might notice is the for creatives with thousands of classes frame time is spent on the fancy from its low fixed resolution giving it from the camera begins to fade into a from the pack and also makes use of game so that we can see all the details get some idea of what's going on you gradients for some more info on why this handy dandy program to frame capture the has two main Tech trees forward and have a great rest of your day and I'll have some Edge detection going on here have the onew combo of Shader effects hdrp Fancy expensive lighting heavy use of volumetrics as a gameplay hello everyone lethal company is a game horror how convenient this independent how exactly those are being used without how it works great the name of this illustration business music culinary and image it's clearly being upscaled from a important draw call that we don't want in or whatever or we could just use this in our case the image is going to be in the description the first 500 people in these Blobs of color because there information we know that the entire interactions a point appears to be interested though the logic is very interesting must have lots of interesting this is because a ton of interesting this is what lethal company interpret that for you beyond a basic into the G buffer here I would skip to is being used for something so easily is doing the right thing and condensing is going on with the light surface is really useful and not bad actually is so bad is because hdrp isn't really is somewhere in the Shader assembly but is sponsored by skillshare skillshare is isn't anything proprietary either it is isn't just for beginners though the issues even 40 series cards were it themselves and I have to figure out it took me a little bit to figure out it's clearing 100 FPS without any issues it's color data being quantized as usual it's even more obvious if we look at it's instead fully sharp like everything it's part of the hdrp shaders this means just hdp's default physically based lit just like a Skybox yoinked from Google kind of looks like posterization I kind of low quality lastly we have every lab naming convention where the editor learning path I found most interesting led by actual industry professionals let's take a look at this Frame from the lethal company doesn't do this it lethal company frame so you might assume lethal company is using unity's highdef lethal company looks a bit strange it's level I'm just going to assume it's the light but thresholded to create a light simulation then we wouldn't see lighting and not just fake distance fog lighting calculations based on what was lighting data and applying it again like I said earlier there is some like luminance or saturation the answer like the normal vector or anything else like you're used to real-time rendering low quality if you play at 1440p or 4K lower resolution because everything is luminance of the color because that's made it even easier with learning paths made with unity because the names of the make an interesting looking game as make it more saturated after this pass make the graphics of lethal makes them way less expensive anyways man many more skillshare is the perfect meant to have good performance its mechanic mainly for obscuring vision might hear a lot of words you're not mine we see similar artifacts in our models textures and decompiled shaders more homogeneous color obscuring details more information but a Rolla what about more than just posterization we've got move on before we can do lighting Unity my Counterstrike 2 smoke video If you mystery color difference and then native resolution 860 x 520 is a really needs 16,000 API calls to draw the frame needs to do all of its shadow mapping in negotiations as well as building their neighborhood samples one of the depth no gradient or anything in between this no nearly all the Shader effects you see node-based Shader editor the name gives normally something this close to the normally when you posterize something objects have such strange colors instead obvious quantization going on and obvious thing is that something strange obviously on the Rocks here because the obviously this info we write is stuff of a pixel that is the largest of being drawn fully lit and colored of my independent professional of the Native resolution you're playing offer by following the link on screen or oh oh oh on the rocks in the distance then one frame of the game with all that only comparing one of the three order again this particular capture our earlier questions and now we can output to the back buffer deferred parts of the screen this could pass like we were earlier with the path from beginner to intermediate to peak and at the dreaded Shader assembly personal brand which is something many pipeline lethal company's visuals are piping making this legitimate volumetric platform to get started with learning point of inspiration for people that possible hence the name lethal company post-processing which is my specialty posterization Shader is applied next posterization and double edge detection posterization effect the helmet visor is posterization is kind of just another posterization it's going to be easier if posterization pass and would have to potentially be a simple post-processing praised by many for its pre-calculating the lighting then the pre-calculations this takes about 8,000 pretty much anything and they recently probably be fixed but that's not really problem with that though is colors are proper colors but there's one very proprietary Shader tricks involved but proprietary aspect of lethal company's rates a big reason why the performance realistic fog the developer's custom really funny that something so expensive reason so I'll be turning it right side recall from that video this stuff is reduce it to a single value either by rendered when we draw an object then we rendering at a lower Target resolution rendering is a bit different instead rendering pipeline the same rendering rendering which means the developer made renders at a fixed 860 by 520 regardless renders games upside down for whatever resolution after depth of field we we resolution of expensive hdrp shaders runs very fast though on my mid-range PC same method I used to get info about the scene is drawn with realistic lighting screenshots I'm not going to explain how second Edge detection when we take a see in the screenshot if we check out see you next time seeing the data that is being written separate the bright pixels blur them and shaders in each pass follow un's Shader shapes on the border of the frame is the similar to the techniques presented in simplest method of edge detection is by skillshare for sponsoring this video now skylines 2 well the reasons for that are slightly blur held items I think it's small resolution if we take a look at smaller amount the smaller amount of so today let's figure out how you could so why is it so much faster than City some unethical Frankenstein monster of somehow even though we're not outside something a little different this video something called the g-buffer you might sorts of information about it to strange number normally if a game is street view or something I don't know struggling to get real time from frame study of a Leal company screenshot to stylistic path of lethal company but the stylization is the first and only surely a game that looks this surface after Unity has finished take a look at the Shader assembly taken in order to give you the proper thank me over on patreon as usual a huge thank you to all my current patrons thankfully Unity actually has the Shader that I've discussed in previous videos that at this point everything is that could be entirely responsible for that go into how it was rendered the that's about everything we can also that's right lethal company is making the UI is drawn and Gamma correction is the Uber post compute Shader does a the edge here on the cliff but no edges the edges in this past as well and if we the frame at this point is pretty the game for instance when the GPU is the game looks low quality because it's the graphics API calls that were made by the helmet visor which is funny because the largest online learning Community the lighting pass so we can see the the model data in the frame debugger the most of its expensive Shader Effects the objects in frame have their lighting the pixelated aesthetic despite being an the point of this video so let's move on the posterization pass giving us the the screen and we have success Yul drawn the time we'd be out of luck with this the two lethal company does not stray the view details in the profiler it's the volumetric light data is noisy so the volumetric light works if you're then add it back to the original image then it's some sort of factor of the then this lowquality aesthetic is going then we can confirm this is in fact the there's a lot going on so we've got to there's not much else to the main there's this blurry helmet obscuring these God rays in the shadow of the these being lens Distortion chromatic these cones of light the next most these spotlights without the volumetric they have to know Shader programming to think that stands for graphics buffer think these realistic effects can only thinking about what order they are used this Shader effect is one of many things this contrast value exceeds an arbitrary this is how I know lethal company is this is one of the main reasons why this strikes one mystery off the list thought that too but it's actually a three component vectors so we need to threshold then an edge exists there the time is wasted drawing things that to be significantly more pronounced but to miss event 794 draws the helmet we to take the time to rotate the the video to use my link will also get a free to which method lethal company is using told to draw an object then the program try out everything skillshare has to ultimately simple stylized rendering unfamiliar with what a frame capture is up for your viewing convenience you can upscales into my native resolution us a pretty big hint of what's going on used deferred although in reality it's usual thanks for watching I hope you values used to color objects we also very expensive but this expense is visible close to the camera you can see visor of the helmet the player model visor of the player character's helmet volumetric fog this lighting Shader volumetric lighting we see in our warped horizontally to fill the space was for helping Freelancers with price was made with Shader graph unity's way that's why the floor here is noisy we can see that the Shader is doing two we could possibly want for later then we have the low resolution of the entire we know this isn't fake fog because of we swap to a different frame capture wears and it's not faked with a Shader weird squiggly lines on the wall that what I would do beyond the light what's being posterized and how are what's going on here because lethal when it's quantized the noise gets when we draw an object we write all which are curated classes meant to be which is an insanely valuable resource whole lot of effects in one big pass will be explained in detail later the will capture that and then we can will sort the Shader into categories with depth or normals which lethal with it because of the very small render without your support I wouldn't be able won't show up in the unity editor and word for that if we take a look at a would intuitively think a game is would look like without any it stylistic written in the g-buffer mostly you a bit in case you forgot the black you can check out these two videos of you posterize the colors reducing the"
  }
]